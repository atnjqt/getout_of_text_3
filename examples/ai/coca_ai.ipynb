{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873f7746",
   "metadata": {},
   "source": [
    "## Use AI Agent Tools on COCA KWIC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b83f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getout_of_text_3 as got3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8de282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got3.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b55935",
   "metadata": {},
   "source": [
    "### Read local offline COCA corpus into workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802d6b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:   0%|          | 0/8 [00:00<?, ?genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: mag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  12%|█▎        | 1/8 [00:01<00:07,  1.05s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: mag (total files: 30)\n",
      "Processing genre: web\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  25%|██▌       | 2/8 [00:02<00:06,  1.12s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: web (total files: 34)\n",
      "Processing genre: acad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  38%|███▊      | 3/8 [00:03<00:05,  1.14s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: acad (total files: 30)\n",
      "Processing genre: news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  50%|█████     | 4/8 [00:04<00:04,  1.13s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: news (total files: 30)\n",
      "Processing genre: spok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  62%|██████▎   | 5/8 [00:05<00:03,  1.17s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: spok (total files: 30)\n",
      "Processing genre: blog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  75%|███████▌  | 6/8 [00:06<00:02,  1.16s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: blog (total files: 34)\n",
      "Processing genre: fic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  88%|████████▊ | 7/8 [00:07<00:01,  1.10s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: fic (total files: 30)\n",
      "Processing genre: tvm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres: 100%|██████████| 8/8 [00:09<00:00,  1.13s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: tvm (total files: 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coca_corpus = got3.read_corpus('../../data/coca/coca-text/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff84ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Calculating total COCA corpus word count...\n",
      "🎯 TOTAL COCA CORPUS: 1,178,812,039 words\n",
      "🎯 TOTAL COCA CORPUS: 1,178,812,039 words\n"
     ]
    }
   ],
   "source": [
    "# Calculate total word count across all COCA genres and subkeys\n",
    "def count_words_in_text(text):\n",
    "    \"\"\"Count words in a text string.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "# Calculate total word count\n",
    "total_word_count = 0\n",
    "\n",
    "print(\"📊 Calculating total COCA corpus word count...\")\n",
    "\n",
    "for genre, subkeys in coca_corpus.items():\n",
    "    for subkey, dataframe in subkeys.items():\n",
    "        if isinstance(dataframe, pd.DataFrame) and 'text' in dataframe.columns:\n",
    "            # Count words in all text entries for this subkey\n",
    "            subkey_word_count = dataframe['text'].apply(count_words_in_text).sum()\n",
    "            total_word_count += subkey_word_count\n",
    "\n",
    "print(f\"🎯 TOTAL COCA CORPUS: {total_word_count:,} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76a5cf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mag', 'web', 'acad', 'news', 'spok', 'blog', 'fic', 'tvm'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_corpus.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2316f50",
   "metadata": {},
   "source": [
    "\n",
    "____________________________\n",
    "## Search Keyword \n",
    "\n",
    "- using `bovine` as a test keyword across the full COCA corpus\n",
    "- COMPARE YOUR RESULTS TO THE OUTPUT HERE, IF POSSIBLE: https://www.english-corpora.org/coca/\n",
    "  - I get sometimes less and sometimes more hits! TBD and needs review...\n",
    "\n",
    "\n",
    "### Comparing parallel vs non-parallel kwic search\n",
    "\n",
    "- the `n_jobs` parameter will automatically use n-1 cores to use all but one of your CPU cores. This leads to much better performance on large corpora.\n",
    "- i.e. for `bovine` on the full COCA text corpus, I get (10-1=9 CPU cores):\n",
    "  - non-parallel: time elapsed: 0 days 00:01:01.157718\n",
    "  - parallel: time elapsed: 0 days 00:00:22.578978\n",
    "  - almost 3x faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c3ebc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='bovine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56cd4cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword bovine time elapsed: 0 days 00:00:19.759251\n"
     ]
    }
   ],
   "source": [
    "before = pd.Timestamp.now()\n",
    "bovine_kwic = got3.search_keyword_corpus(keyword, coca_corpus, \n",
    "                                            case_sensitive=False,\n",
    "                                            show_context=True, \n",
    "                                            context_words=15,\n",
    "                                            output='json',\n",
    "                                            parallel=True)\n",
    "after = pd.Timestamp.now()\n",
    "print('keyword {} time elapsed:'.format(keyword), after - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa726418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mag_1993', 'mag_1992', 'mag_1990', 'mag_1991', 'mag_1995', 'mag_1994', 'mag_1996', 'mag_1997', 'mag_2008', 'mag_2009', 'mag_2019', 'mag_2018', 'mag_2002', 'mag_2016', 'mag_2017', 'mag_2003', 'mag_2015', 'mag_2001', 'mag_2000', 'mag_2014', 'mag_2010', 'mag_2004', 'mag_2005', 'mag_2011', 'mag_2007', 'mag_2013', 'mag_2012', 'mag_2006', 'mag_1999', 'mag_1998', 'web_13', 'web_07', 'web_06', 'web_12', 'web_04', 'web_10', 'web_11', 'web_05', 'web_29', 'web_01', 'web_15', 'web_14', 'web_28', 'web_16', 'web_02', 'web_03', 'web_17', 'web_32', 'web_26', 'web_27', 'web_33', 'web_25', 'web_31', 'web_19', 'web_18', 'web_30', 'web_24', 'web_08', 'web_20', 'web_34', 'web_21', 'web_09', 'web_23', 'web_22', 'acad_2013', 'acad_2007', 'acad_2006', 'acad_2012', 'acad_2004', 'acad_2010', 'acad_2011', 'acad_2005', 'acad_2001', 'acad_2015', 'acad_2014', 'acad_2000', 'acad_2016', 'acad_2002', 'acad_2003', 'acad_2017', 'acad_1999', 'acad_1998', 'acad_1996', 'acad_1997', 'acad_1995', 'acad_1994', 'acad_1990', 'acad_1991', 'acad_1993', 'acad_1992', 'acad_2019', 'acad_2018', 'acad_2008', 'acad_2009', 'news_2018', 'news_2019', 'news_2009', 'news_2008', 'news_1994', 'news_1995', 'news_1997', 'news_1996', 'news_1992', 'news_1993', 'news_1991', 'news_1990', 'news_1998', 'news_1999', 'news_2011', 'news_2005', 'news_2004', 'news_2010', 'news_2006', 'news_2012', 'news_2013', 'news_2007', 'news_2003', 'news_2017', 'news_2016', 'news_2002', 'news_2014', 'news_2000', 'news_2001', 'news_2015', 'spok_1995', 'spok_1994', 'spok_1996', 'spok_1997', 'spok_1993', 'spok_1992', 'spok_1990', 'spok_1991', 'spok_2019', 'spok_2018', 'spok_2008', 'spok_2009', 'spok_2004', 'spok_2010', 'spok_2011', 'spok_2005', 'spok_2013', 'spok_2007', 'spok_2006', 'spok_2012', 'spok_2016', 'spok_2002', 'spok_2003', 'spok_2017', 'spok_2001', 'spok_2015', 'spok_2014', 'spok_2000', 'spok_1999', 'spok_1998', 'blog_26', 'blog_32', 'blog_33', 'blog_27', 'blog_19', 'blog_31', 'blog_25', 'blog_24', 'blog_30', 'blog_18', 'blog_34', 'blog_20', 'blog_08', 'blog_09', 'blog_21', 'blog_23', 'blog_22', 'blog_07', 'blog_13', 'blog_12', 'blog_06', 'blog_10', 'blog_04', 'blog_05', 'blog_11', 'blog_15', 'blog_01', 'blog_29', 'blog_28', 'blog_14', 'blog_02', 'blog_16', 'blog_17', 'blog_03', 'fic_1998', 'fic_1999', 'fic_2011', 'fic_2005', 'fic_2004', 'fic_2010', 'fic_2006', 'fic_2012', 'fic_2013', 'fic_2007', 'fic_2003', 'fic_2017', 'fic_2016', 'fic_2002', 'fic_2014', 'fic_2000', 'fic_2001', 'fic_2015', 'fic_2018', 'fic_2019', 'fic_2009', 'fic_2008', 'fic_1994', 'fic_1995', 'fic_1997', 'fic_1996', 'fic_1992', 'fic_1993', 'fic_1991', 'fic_1990', 'tvm_1999', 'tvm_1998', 'tvm_2010', 'tvm_2004', 'tvm_2005', 'tvm_2011', 'tvm_2007', 'tvm_2013', 'tvm_2012', 'tvm_2006', 'tvm_2002', 'tvm_2016', 'tvm_2017', 'tvm_2003', 'tvm_2015', 'tvm_2001', 'tvm_2000', 'tvm_2014', 'tvm_2019', 'tvm_2018', 'tvm_2008', 'tvm_2009', 'tvm_1995', 'tvm_1994', 'tvm_1996', 'tvm_1997', 'tvm_1993', 'tvm_1992', 'tvm_1990', 'tvm_1991'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bovine_kwic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244b948",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 445)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:445\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"🧮 Calculating optimal ratios from your AWS Bedrock errors:\")\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# COCA Computational Forensic Linguistics Agent\n",
    "# Adapted from SCOTUS analysis tools for corpus linguistics analysis\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Optional, Type, Dict, Any, Union, List\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class CocaAnalysisInput(BaseModel):\n",
    "    \"\"\"Input for COCA corpus linguistics analysis tool.\"\"\"\n",
    "    keyword: str = Field(description=\"The keyword/phrase to analyze from COCA KWIC results\")\n",
    "    results_json: Union[str, Dict[str, Any]] = Field(\n",
    "        description=\"Pre-filtered COCA KWIC JSON results from got3.search_keyword_corpus\"\n",
    "    )\n",
    "    analysis_focus: Optional[str] = Field(\n",
    "        default=\"forensic_linguistics\", \n",
    "        description=\"Analysis approach: 'forensic_linguistics', 'semantic_variation', 'register_analysis', 'diachronic', 'comparative'\"\n",
    "    )\n",
    "    max_contexts: Optional[int] = Field(\n",
    "        default=None, description=\"DEPRECATED: No longer used. Tool processes all provided contexts.\"\n",
    "    )\n",
    "    return_json: bool = Field(\n",
    "        default=False, description=\"If True, return structured JSON with reasoning and findings\"\n",
    "    )\n",
    "    extraction_strategy: str = Field(\n",
    "        default=\"all\",\n",
    "        description=\"Text extraction: 'first', 'all', or 'raw_json'\"\n",
    "    )\n",
    "    debug: bool = Field(default=False, description=\"Enable debug metrics\")\n",
    "\n",
    "\n",
    "class CocaForensicLinguisticsTool(BaseTool):\n",
    "    \"\"\"\n",
    "    AI tool for computational forensic linguistics analysis of COCA KWIC results.\n",
    "    \n",
    "    Applies systematic data science, legal scholarship, and applied linguistics \n",
    "    methodologies to analyze keyword usage patterns across COCA genres.\n",
    "    \"\"\"\n",
    "    name: str = \"coca_forensic_analysis\"\n",
    "    description: str = (\n",
    "        \"Performs computational forensic linguistics analysis on COCA KWIC results \"\n",
    "        \"using data science and applied linguistics methodologies.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = CocaAnalysisInput\n",
    "    model: Any = Field(exclude=True)\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"forensic_linguistics\",\n",
    "        max_contexts: Optional[int] = None,\n",
    "        return_json: bool = False,\n",
    "        extraction_strategy: str = \"all\",\n",
    "        debug: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        try:\n",
    "            return self._execute(keyword, results_json, analysis_focus, max_contexts, return_json, extraction_strategy, debug)\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            return f\"❌ Error during COCA forensic analysis: {error_str}\"\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"forensic_linguistics\",\n",
    "        max_contexts: Optional[int] = None,\n",
    "        return_json: bool = False,\n",
    "        extraction_strategy: str = \"all\",\n",
    "        debug: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        return self._run(keyword, results_json, analysis_focus, max_contexts, return_json, extraction_strategy, debug)\n",
    "\n",
    "    def _execute(self, keyword, results_json, analysis_focus, max_contexts, return_json, extraction_strategy, debug):\n",
    "        # Parse and validate input\n",
    "        results_dict = self._parse_coca_results(results_json)\n",
    "        stats = self._compute_coca_stats(results_dict, keyword, extraction_strategy)\n",
    "        \n",
    "        # Extract contexts and estimate token usage\n",
    "        contexts = self._extract_contexts(results_dict, max_contexts, extraction_strategy)\n",
    "        \n",
    "        # Debug metrics\n",
    "        if debug:\n",
    "            print(\"✅ Reading COCA results for keyword:\", keyword)\n",
    "            raw_chars = len(json.dumps(results_dict))\n",
    "            extracted_chars = sum(len(c) for c in contexts)\n",
    "            print(f\"🧪 COCA DEBUG: genre_year_keys={len(results_dict)} raw_chars={raw_chars} extracted_chars={extracted_chars} total_contexts={len(contexts)}\")\n",
    "            \n",
    "            # Debug: Show genre distribution in ALL extracted contexts\n",
    "            genre_context_counts = {}\n",
    "            for context in contexts:\n",
    "                if context.startswith('[') and ':' in context:\n",
    "                    genre = context.split(':')[0][1:]  # Extract genre from [genre:year:filename]\n",
    "                    genre_context_counts[genre] = genre_context_counts.get(genre, 0) + 1\n",
    "            print(f\"🎯 All extracted contexts by genre: {genre_context_counts}\")\n",
    "            print(f\"📊 Total contexts extracted: {len(contexts)}\")\n",
    "        \n",
    "        # Build specialized prompt and check token limits\n",
    "        prompt = self._build_coca_prompt(keyword, results_dict, stats, analysis_focus, max_contexts, return_json, extraction_strategy)\n",
    "        # Invoke model\n",
    "        response = self.model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        content = getattr(response, 'content', str(response))\n",
    "        \n",
    "        if return_json:\n",
    "            return self._postprocess_coca_json(content, stats)\n",
    "        return content\n",
    "\n",
    "    def _parse_coca_results(self, results_json: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Parse COCA results JSON - expects genre->subkey->dataframe structure.\"\"\"\n",
    "        if isinstance(results_json, str):\n",
    "            results_dict = json.loads(results_json)\n",
    "        else:\n",
    "            results_dict = results_json\n",
    "        \n",
    "        if not isinstance(results_dict, dict):\n",
    "            raise ValueError(\"COCA results must be a dict with genre keys\")\n",
    "        return results_dict\n",
    "\n",
    "    def _extract_contexts(self, results_dict: Dict[str, Any], max_contexts: Optional[int], strategy: str) -> List[str]:\n",
    "        \"\"\"Extract ALL context strings from COCA results - no sampling, user controls input.\"\"\"\n",
    "        contexts = []\n",
    "        \n",
    "        # Handle COCA JSON structure: {genre_year: {filename_id: text_string}}\n",
    "        for genre_year_key, filename_dict in results_dict.items():\n",
    "            if not isinstance(filename_dict, dict):\n",
    "                continue\n",
    "            \n",
    "            # Split genre_year for labeling\n",
    "            parts = genre_year_key.split('_')\n",
    "            genre = parts[0] if len(parts) >= 1 else 'unknown'\n",
    "            year = parts[1] if len(parts) >= 2 else 'unknown'\n",
    "            \n",
    "            # Extract ALL text content from filename_id -> text_string mappings\n",
    "            for filename_id, text_content in filename_dict.items():\n",
    "                if isinstance(text_content, str) and text_content.strip():\n",
    "                    # Format: [genre:year:filename_id] text_content\n",
    "                    context_label = f\"[{genre}:{year}:{filename_id}]\"\n",
    "                    contexts.append(f\"{context_label} {text_content.strip()}\")\n",
    "                        \n",
    "        return contexts\n",
    "\n",
    "    def _extract_context_from_row(self, row, strategy: str) -> str:\n",
    "        \"\"\"Extract context from a single COCA result row.\"\"\"\n",
    "        text_fields = ['context', 'text', 'kwic', 'content', 'snippet']\n",
    "        \n",
    "        if strategy == 'first':\n",
    "            for field in text_fields:\n",
    "                if hasattr(row, field) and isinstance(getattr(row, field), str):\n",
    "                    return getattr(row, field).strip()\n",
    "        elif strategy == 'all':\n",
    "            parts = []\n",
    "            for field in text_fields:\n",
    "                if hasattr(row, field) and isinstance(getattr(row, field), str):\n",
    "                    parts.append(getattr(row, field).strip())\n",
    "            return ' | '.join(parts) if parts else ''\n",
    "        \n",
    "        return str(row) if strategy == 'raw_json' else ''\n",
    "\n",
    "    def _extract_context_from_item(self, item, strategy: str) -> str:\n",
    "        \"\"\"Extract context from a dict/object item.\"\"\"\n",
    "        if isinstance(item, str):\n",
    "            return item\n",
    "        elif isinstance(item, dict):\n",
    "            text_fields = ['context', 'text', 'kwic', 'content', 'snippet']\n",
    "            if strategy == 'first':\n",
    "                for field in text_fields:\n",
    "                    if field in item and isinstance(item[field], str):\n",
    "                        return item[field].strip()\n",
    "            elif strategy == 'all':\n",
    "                parts = []\n",
    "                for field in text_fields:\n",
    "                    if field in item and isinstance(item[field], str):\n",
    "                        parts.append(item[field].strip())\n",
    "                return ' | '.join(parts) if parts else ''\n",
    "            elif strategy == 'raw_json':\n",
    "                return json.dumps(item)\n",
    "        return str(item)\n",
    "\n",
    "    def _compute_coca_stats(self, results_dict: Dict[str, Any], keyword: str, strategy: str) -> Dict[str, Any]:\n",
    "        \"\"\"Compute statistics about COCA results distribution - handles {genre_year: {filename_id: text_string}} structure.\"\"\"\n",
    "        # Extract genres from genre_year keys\n",
    "        genres = set()\n",
    "        genre_counts = {}\n",
    "        total_contexts = 0\n",
    "        \n",
    "        for genre_year_key, filename_dict in results_dict.items():\n",
    "            if isinstance(filename_dict, dict):\n",
    "                # Split to get genre\n",
    "                parts = genre_year_key.split('_')\n",
    "                if len(parts) >= 1:\n",
    "                    genre = parts[0]\n",
    "                    genres.add(genre)\n",
    "                    \n",
    "                    # Count contexts (filename entries)\n",
    "                    context_count = len(filename_dict)\n",
    "                    total_contexts += context_count\n",
    "                    \n",
    "                    # Aggregate by genre\n",
    "                    if genre not in genre_counts:\n",
    "                        genre_counts[genre] = 0\n",
    "                    genre_counts[genre] += context_count\n",
    "        \n",
    "        return {\n",
    "            'keyword': keyword,\n",
    "            'genres': sorted(list(genres)),\n",
    "            'genre_counts': genre_counts,\n",
    "            'total_contexts': total_contexts,\n",
    "            'extraction_strategy': strategy\n",
    "        }\n",
    "\n",
    "    def _build_coca_prompt(self, keyword: str, results_dict: Dict[str, Any], stats: Dict[str, Any], \n",
    "                          analysis_focus: str, max_contexts: Optional[int], return_json: bool, \n",
    "                          extraction_strategy: str) -> str:\n",
    "        \"\"\"Build specialized prompt for COCA forensic linguistics analysis.\"\"\"\n",
    "        \n",
    "        contexts = self._extract_contexts(results_dict, max_contexts, extraction_strategy)\n",
    "        \n",
    "        # Build genre summary from actual stats, not just what's in contexts\n",
    "        genre_summary = \", \".join([f\"{g}({stats['genre_counts'][g]})\" for g in stats['genres']])\n",
    "        \n",
    "        # Add explicit instruction about complete data inclusion\n",
    "        contexts_section = f\"\"\"COCA KWIC Contexts (ALL {len(contexts)} contexts from provided data):\n",
    "---\n",
    "IMPORTANT: ALL contexts from your provided COCA data are included below: {genre_summary}\n",
    "Each context is labeled [genre:year:filename_id] to show its source.\n",
    "No sampling or filtering was performed - this is your complete dataset.\n",
    "---\n",
    "\"\"\" + \"\\n\".join(contexts) + \"\\n---\\n\"\n",
    "        \n",
    "        focus_instructions = {\n",
    "            \"forensic_linguistics\": \"\"\"\n",
    "            As a computational forensic linguist, perform systematic analysis to identify:\n",
    "            1. **Semantic Range Mapping**: Document all distinct senses/meanings of the keyword\n",
    "            2. **Register Variation**: Compare usage patterns across genres (academic, news, fiction, etc.)\n",
    "            3. **Collocational Profiles**: Identify key collocates and their significance\n",
    "            4. **Frequency Distributions**: Analyze genre-specific frequency patterns\n",
    "            5. **Interpretive Stability**: Assess semantic consistency vs. context-dependency\n",
    "            6. **Forensic Implications**: Note patterns relevant to authorship, text dating, or authenticity\n",
    "            \"\"\",\n",
    "            \"semantic_variation\": \"\"\"\n",
    "            Focus on semantic analysis:\n",
    "            1. Identify polysemy patterns and meaning boundaries\n",
    "            2. Map semantic fields and conceptual domains\n",
    "            3. Analyze metaphorical vs. literal usage\n",
    "            4. Document semantic change indicators across contexts\n",
    "            \"\"\",\n",
    "            \"register_analysis\": \"\"\"\n",
    "            Perform register-specific analysis:\n",
    "            1. Compare formal vs. informal usage patterns\n",
    "            2. Identify genre-specific conventions\n",
    "            3. Analyze technical vs. general usage\n",
    "            4. Map sociolinguistic variation patterns\n",
    "            \"\"\",\n",
    "            \"diachronic\": \"\"\"\n",
    "            Analyze temporal patterns:\n",
    "            1. Identify usage evolution across time periods\n",
    "            2. Map emerging vs. declining meanings\n",
    "            3. Track semantic change trajectories\n",
    "            4. Document historical usage patterns\n",
    "            \"\"\",\n",
    "            \"comparative\": \"\"\"\n",
    "            Perform comparative analysis:\n",
    "            1. Cross-genre pattern comparison\n",
    "            2. Usage frequency analysis\n",
    "            3. Contextual distribution mapping\n",
    "            4. Identify genre-specific markers\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "        base_prompt = f\"\"\"\n",
    "        You are a computational forensic linguistics AI agent analyzing COCA (Contemporary Corpus of American English) data.\n",
    "\n",
    "        METHODOLOGICAL FRAMEWORK:\n",
    "        Apply systematic data science, legal scholarship, and applied linguistics approaches to analyze the keyword \"{keyword}\".\n",
    "\n",
    "        CORPUS DATA SUMMARY:\n",
    "        - Keyword: \"{keyword}\"\n",
    "        - Total Contexts Provided: {stats['total_contexts']:,} across {len(results_dict)} genre_year combinations\n",
    "        - Genre Distribution: {genre_summary}\n",
    "        - Contexts Analyzed: ALL {len(contexts)} contexts (complete dataset, no sampling)\n",
    "        - Extraction Strategy: {extraction_strategy}\n",
    "        \n",
    "        ANALYSIS FOCUS: {analysis_focus}\n",
    "        {focus_instructions.get(analysis_focus, focus_instructions['forensic_linguistics'])}\n",
    "\n",
    "        SYSTEMATIC STEPS:\n",
    "        1. **Data Overview**: Summarize distribution across ALL genres (use the counts provided above)\n",
    "        2. **Pattern Recognition**: Identify recurring usage patterns across different genres\n",
    "        3. **Statistical Analysis**: Note frequency and distribution patterns across ALL genres\n",
    "        4. **Linguistic Analysis**: Analyze syntactic, semantic, and pragmatic features by genre\n",
    "        5. **Forensic Assessment**: Evaluate evidential value for text analysis\n",
    "        6. **Interpretive Framework**: Provide systematic interpretation guidelines\n",
    "\n",
    "        CRITICAL CONSTRAINTS:\n",
    "        - Use ALL the provided COCA contexts (complete dataset as provided by user)\n",
    "        - Apply rigorous linguistic methodology across all provided contexts\n",
    "        - Avoid speculation beyond evidence\n",
    "        - Maintain scientific objectivity\n",
    "        - Analyze the complete distribution of contexts as provided (no sampling performed)\n",
    "\n",
    "        {contexts_section}\n",
    "        \"\"\"\n",
    "        \n",
    "        if return_json:\n",
    "            base_prompt += \"\"\"\n",
    "            Return ONLY valid JSON with this structure:\n",
    "            {\n",
    "              \"keyword\": string,\n",
    "              \"total_contexts\": number,\n",
    "              \"genre_distribution\": object,\n",
    "              \"reasoning_content\": [string, ...],\n",
    "              \"semantic_analysis\": string,\n",
    "              \"register_patterns\": string,\n",
    "              \"forensic_implications\": string,\n",
    "              \"summary\": string,\n",
    "              \"limitations\": string\n",
    "            }\n",
    "            \"\"\"\n",
    "        else:\n",
    "            base_prompt += \"\"\"\n",
    "            Provide structured analysis with these sections:\n",
    "            1. **Corpus Distribution Overview** (use the full genre counts provided)\n",
    "            2. **Semantic Analysis** \n",
    "            3. **Register and Genre Patterns** (analyze patterns across ALL genres)\n",
    "            4. **Collocational Analysis**\n",
    "            5. **Forensic Linguistics Assessment**\n",
    "            6. **Interpretive Guidelines**\n",
    "            7. **Methodological Limitations**\n",
    "            \"\"\"\n",
    "        \n",
    "        return base_prompt.strip()\n",
    "\n",
    "    def _postprocess_coca_json(self, content: str, stats: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Process and validate JSON response from model.\"\"\"\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "        except Exception:\n",
    "            # Try to extract JSON from response\n",
    "            match = re.search(r'{[\\s\\S]*}', content)\n",
    "            if match:\n",
    "                try:\n",
    "                    parsed = json.loads(match.group(0))\n",
    "                except Exception:\n",
    "                    parsed = None\n",
    "            else:\n",
    "                parsed = None\n",
    "        \n",
    "        if not isinstance(parsed, dict):\n",
    "            # Fallback structure\n",
    "            parsed = {\n",
    "                \"keyword\": stats['keyword'],\n",
    "                \"total_contexts\": stats['total_contexts'],\n",
    "                \"genre_distribution\": stats['genre_counts'],\n",
    "                \"reasoning_content\": [\n",
    "                    \"Model did not return valid JSON; content auto-wrapped.\",\n",
    "                    \"Analysis limited by response format issues.\"\n",
    "                ],\n",
    "                \"semantic_analysis\": content if isinstance(content, str) else str(content),\n",
    "                \"register_patterns\": \"Unable to extract due to format issues.\",\n",
    "                \"forensic_implications\": \"Analysis inconclusive due to response parsing failure.\",\n",
    "                \"summary\": \"Response required manual wrapping - review raw content.\",\n",
    "                \"limitations\": \"Auto-wrapped due to invalid JSON from model.\"\n",
    "            }\n",
    "        \n",
    "        # Ensure required fields exist\n",
    "        required_fields = {\n",
    "            \"reasoning_content\": [],\n",
    "            \"semantic_analysis\": \"\",\n",
    "            \"register_patterns\": \"\",\n",
    "            \"forensic_implications\": \"\",\n",
    "            \"summary\": \"\",\n",
    "            \"limitations\": \"\"\n",
    "        }\n",
    "        \n",
    "        for field, default in required_fields.items():\n",
    "            if field not in parsed:\n",
    "                parsed[field] = default\n",
    "        \n",
    "        return parsed\n",
    "    \n",
    "# Markdown export function for COCA analysis\n",
    "def export_coca_markdown(result, keyword: str, filename: str = None):\n",
    "    \"\"\"Export COCA forensic linguistics analysis to markdown with reasoning first.\"\"\"\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    \n",
    "    def _sanitize(name: str) -> str:\n",
    "        return ''.join(c if (c.isalnum() or c in ('-','_')) else '_' for c in name.strip()) or 'analysis'\n",
    "    \n",
    "    safe_keyword = _sanitize(keyword)\n",
    "    outname = filename or f\"coca_forensic_{safe_keyword}.md\"\n",
    "    \n",
    "    lines = [f\"# COCA Forensic Linguistics Analysis: {keyword}\\n\\n\"]\n",
    "    lines.append(f\"*Generated: {datetime.utcnow().isoformat()}Z*\\n\\n\")\n",
    "    \n",
    "    if isinstance(result, dict):\n",
    "        # Extract reasoning content first\n",
    "        reasoning = result.get('reasoning_content', [])\n",
    "        if reasoning:\n",
    "            lines.append(\"## Methodological Framework\\n\\n\")\n",
    "            lines.append(\"```text\\n\")\n",
    "            if isinstance(reasoning, list):\n",
    "                lines.append('\\n'.join(str(r) for r in reasoning))\n",
    "            else:\n",
    "                lines.append(str(reasoning))\n",
    "            lines.append(\"\\n```\\n\\n\")\n",
    "        \n",
    "        # Add structured sections\n",
    "        sections = [\n",
    "            ('semantic_analysis', 'Semantic Analysis'),\n",
    "            ('register_patterns', 'Register and Genre Patterns'),\n",
    "            ('forensic_implications', 'Forensic Linguistics Assessment'),\n",
    "            ('summary', 'Summary'),\n",
    "            ('limitations', 'Limitations')\n",
    "        ]\n",
    "        \n",
    "        for field, title in sections:\n",
    "            if field in result and result[field]:\n",
    "                lines.append(f\"## {title}\\n\\n\")\n",
    "                lines.append(f\"{result[field]}\\n\\n\")\n",
    "        \n",
    "        # Add distribution data if available\n",
    "        if 'genre_distribution' in result:\n",
    "            lines.append(\"## Corpus Distribution\\n\\n\")\n",
    "            lines.append(\"```json\\n\")\n",
    "            lines.append(json.dumps(result['genre_distribution'], indent=2))\n",
    "            lines.append(\"\\n```\\n\\n\")\n",
    "    \n",
    "    else:\n",
    "        lines.append(\"## Analysis\\n\\n\")\n",
    "        lines.append(str(result))\n",
    "    \n",
    "    content = ''.join(lines)\n",
    "    \n",
    "    with open(outname, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    print(f\"📄 COCA forensic analysis exported: {outname} ({len(content)} chars)\")\n",
    "    return outname\n",
    "\n",
    "print(\"✅ COCA Forensic Linguistics Tool loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d54c7",
   "metadata": {},
   "source": [
    "## Setup AWS Bedrock Model for COCA Analysis\n",
    "\n",
    "Initialize the same GPT-OSS-120B model used for SCOTUS analysis, but now tailored for computational forensic linguistics on COCA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "29e32c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AWS Bedrock model initialized: openai.gpt-oss-120b-1:0\n",
      "🔬 COCA Forensic Linguistics Tool ready\n",
      "📊 Available COCA genres: ['mag', 'web', 'acad', 'news', 'spok', 'blog', 'fic', 'tvm']\n"
     ]
    }
   ],
   "source": [
    "# Initialize AWS Bedrock model for COCA forensic linguistics analysis\n",
    "model_id = 'openai.gpt-oss-120b-1:0'  # 128K context window\n",
    "max_tokens = 128000\n",
    "\n",
    "model = init_chat_model(\n",
    "    model_id, \n",
    "    model_provider=\"bedrock_converse\",\n",
    "    credentials_profile_name='atn-developer',  # Adjust to your AWS profile\n",
    "    max_tokens=max_tokens\n",
    ")\n",
    "\n",
    "# Initialize the COCA forensic linguistics tool\n",
    "coca_forensic_tool = CocaForensicLinguisticsTool(model=model)\n",
    "\n",
    "print(f\"✅ AWS Bedrock model initialized: {model_id}\")\n",
    "print(f\"🔬 COCA Forensic Linguistics Tool ready\")\n",
    "print(f\"📊 Available COCA genres: {list(coca_corpus.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447ab1d",
   "metadata": {},
   "source": [
    "## COCA Forensic Linguistics Analysis Demo\n",
    "\n",
    "Let's demonstrate the computational forensic linguistics approach on COCA data using a test keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9e166cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Running COCA KWIC search for JSON analysis: 'vehicle'\n",
      "📊 KWIC JSON search complete!\n",
      "🔍 Found data in genres: ['mag_1993', 'mag_1992', 'mag_1990', 'mag_1991', 'mag_1995', 'mag_1994', 'mag_1996', 'mag_1997', 'mag_2008', 'mag_2009', 'mag_2019', 'mag_2018', 'mag_2002', 'mag_2016', 'mag_2017', 'mag_2003', 'mag_2015', 'mag_2001', 'mag_2000', 'mag_2014', 'mag_2010', 'mag_2004', 'mag_2005', 'mag_2011', 'mag_2007', 'mag_2013', 'mag_2012', 'mag_2006', 'mag_1999', 'mag_1998', 'web_13', 'web_07', 'web_06', 'web_12', 'web_04', 'web_10', 'web_11', 'web_05', 'web_29', 'web_01', 'web_15', 'web_14', 'web_28', 'web_16', 'web_02', 'web_03', 'web_17', 'web_32', 'web_26', 'web_27', 'web_33', 'web_25', 'web_31', 'web_19', 'web_18', 'web_30', 'web_24', 'web_08', 'web_20', 'web_34', 'web_21', 'web_09', 'web_23', 'web_22', 'acad_2013', 'acad_2007', 'acad_2006', 'acad_2012', 'acad_2004', 'acad_2010', 'acad_2011', 'acad_2005', 'acad_2001', 'acad_2015', 'acad_2014', 'acad_2000', 'acad_2016', 'acad_2002', 'acad_2003', 'acad_2017', 'acad_1999', 'acad_1998', 'acad_1996', 'acad_1997', 'acad_1995', 'acad_1994', 'acad_1990', 'acad_1991', 'acad_1993', 'acad_1992', 'acad_2019', 'acad_2018', 'acad_2008', 'acad_2009', 'news_2018', 'news_2019', 'news_2009', 'news_2008', 'news_1994', 'news_1995', 'news_1997', 'news_1996', 'news_1992', 'news_1993', 'news_1991', 'news_1990', 'news_1998', 'news_1999', 'news_2011', 'news_2005', 'news_2004', 'news_2010', 'news_2006', 'news_2012', 'news_2013', 'news_2007', 'news_2003', 'news_2017', 'news_2016', 'news_2002', 'news_2014', 'news_2000', 'news_2001', 'news_2015', 'spok_1995', 'spok_1994', 'spok_1996', 'spok_1997', 'spok_1993', 'spok_1992', 'spok_1990', 'spok_1991', 'spok_2019', 'spok_2018', 'spok_2008', 'spok_2009', 'spok_2004', 'spok_2010', 'spok_2011', 'spok_2005', 'spok_2013', 'spok_2007', 'spok_2006', 'spok_2012', 'spok_2016', 'spok_2002', 'spok_2003', 'spok_2017', 'spok_2001', 'spok_2015', 'spok_2014', 'spok_2000', 'spok_1999', 'spok_1998', 'blog_26', 'blog_32', 'blog_33', 'blog_27', 'blog_19', 'blog_31', 'blog_25', 'blog_24', 'blog_30', 'blog_18', 'blog_34', 'blog_20', 'blog_08', 'blog_09', 'blog_21', 'blog_23', 'blog_22', 'blog_07', 'blog_13', 'blog_12', 'blog_06', 'blog_10', 'blog_04', 'blog_05', 'blog_11', 'blog_15', 'blog_01', 'blog_29', 'blog_28', 'blog_14', 'blog_02', 'blog_16', 'blog_17', 'blog_03', 'fic_1998', 'fic_1999', 'fic_2011', 'fic_2005', 'fic_2004', 'fic_2010', 'fic_2006', 'fic_2012', 'fic_2013', 'fic_2007', 'fic_2003', 'fic_2017', 'fic_2016', 'fic_2002', 'fic_2014', 'fic_2000', 'fic_2001', 'fic_2015', 'fic_2018', 'fic_2019', 'fic_2009', 'fic_2008', 'fic_1994', 'fic_1995', 'fic_1997', 'fic_1996', 'fic_1992', 'fic_1993', 'fic_1991', 'fic_1990', 'tvm_1999', 'tvm_1998', 'tvm_2010', 'tvm_2004', 'tvm_2005', 'tvm_2011', 'tvm_2007', 'tvm_2013', 'tvm_2012', 'tvm_2006', 'tvm_2002', 'tvm_2016', 'tvm_2017', 'tvm_2003', 'tvm_2015', 'tvm_2001', 'tvm_2000', 'tvm_2014', 'tvm_2019', 'tvm_2018', 'tvm_2008', 'tvm_2009', 'tvm_1995', 'tvm_1994', 'tvm_1996', 'tvm_1997', 'tvm_1993', 'tvm_1992', 'tvm_1990', 'tvm_1991']\n"
     ]
    }
   ],
   "source": [
    "# First, ensure we have JSON data for analysis (not just print output)\n",
    "#keyword = \"gabagool\"\n",
    "keyword=\"vehicle\"\n",
    "test_keyword=keyword\n",
    "context_window=5\n",
    "max_tokens=128000\n",
    "ratio_scale_back=1\n",
    "\n",
    "print(f\"🔍 Running COCA KWIC search for JSON analysis: '{keyword}'\")\n",
    "\n",
    "# Re-run the search with output='json' to get structured data for AI analysis\n",
    "bovine_kwic_json = got3.search_keyword_corpus(\n",
    "    keyword, \n",
    "    coca_corpus,\n",
    "    case_sensitive=False,\n",
    "    show_context=True, \n",
    "    context_words=int(context_window * ratio_scale_back),\n",
    "    output='json',  # This is key - we need JSON output for AI analysis\n",
    "    parallel=True\n",
    ")\n",
    "\n",
    "print(f\"📊 KWIC JSON search complete!\")\n",
    "print(f\"🔍 Found data in genres: {list(bovine_kwic_json.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "77a8927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 All genre_year keys found for 'vehicle':\n",
      "============================================================\n",
      "   1. acad_1990 -> 84 hits (genre: acad, year: 1990)\n",
      "   2. acad_1991 -> 80 hits (genre: acad, year: 1991)\n",
      "   3. acad_1992 -> 67 hits (genre: acad, year: 1992)\n",
      "   4. acad_1993 -> 87 hits (genre: acad, year: 1993)\n",
      "   5. acad_1994 -> 91 hits (genre: acad, year: 1994)\n",
      "   6. acad_1995 -> 82 hits (genre: acad, year: 1995)\n",
      "   7. acad_1996 -> 82 hits (genre: acad, year: 1996)\n",
      "   8. acad_1997 -> 73 hits (genre: acad, year: 1997)\n",
      "   9. acad_1998 -> 82 hits (genre: acad, year: 1998)\n",
      "  10. acad_1999 -> 81 hits (genre: acad, year: 1999)\n",
      "  11. acad_2000 -> 79 hits (genre: acad, year: 2000)\n",
      "  12. acad_2001 -> 76 hits (genre: acad, year: 2001)\n",
      "  13. acad_2002 -> 83 hits (genre: acad, year: 2002)\n",
      "  14. acad_2003 -> 83 hits (genre: acad, year: 2003)\n",
      "  15. acad_2004 -> 82 hits (genre: acad, year: 2004)\n",
      "  16. acad_2005 -> 79 hits (genre: acad, year: 2005)\n",
      "  17. acad_2006 -> 74 hits (genre: acad, year: 2006)\n",
      "  18. acad_2007 -> 74 hits (genre: acad, year: 2007)\n",
      "  19. acad_2008 -> 69 hits (genre: acad, year: 2008)\n",
      "  20. acad_2009 -> 55 hits (genre: acad, year: 2009)\n",
      "  21. acad_2010 -> 73 hits (genre: acad, year: 2010)\n",
      "  22. acad_2011 -> 68 hits (genre: acad, year: 2011)\n",
      "  23. acad_2012 -> 53 hits (genre: acad, year: 2012)\n",
      "  24. acad_2013 -> 48 hits (genre: acad, year: 2013)\n",
      "  25. acad_2014 -> 39 hits (genre: acad, year: 2014)\n",
      "  26. acad_2015 -> 31 hits (genre: acad, year: 2015)\n",
      "  27. acad_2016 -> 50 hits (genre: acad, year: 2016)\n",
      "  28. acad_2017 -> 59 hits (genre: acad, year: 2017)\n",
      "  29. acad_2018 -> 38 hits (genre: acad, year: 2018)\n",
      "  30. acad_2019 -> 37 hits (genre: acad, year: 2019)\n",
      "  31. blog_01 -> 79 hits (genre: blog, year: 01)\n",
      "  32. blog_02 -> 78 hits (genre: blog, year: 02)\n",
      "  33. blog_03 -> 62 hits (genre: blog, year: 03)\n",
      "  34. blog_04 -> 73 hits (genre: blog, year: 04)\n",
      "  35. blog_05 -> 81 hits (genre: blog, year: 05)\n",
      "  36. blog_06 -> 74 hits (genre: blog, year: 06)\n",
      "  37. blog_07 -> 60 hits (genre: blog, year: 07)\n",
      "  38. blog_08 -> 72 hits (genre: blog, year: 08)\n",
      "  39. blog_09 -> 65 hits (genre: blog, year: 09)\n",
      "  40. blog_10 -> 88 hits (genre: blog, year: 10)\n",
      "  41. blog_11 -> 92 hits (genre: blog, year: 11)\n",
      "  42. blog_12 -> 83 hits (genre: blog, year: 12)\n",
      "  43. blog_13 -> 66 hits (genre: blog, year: 13)\n",
      "  44. blog_14 -> 70 hits (genre: blog, year: 14)\n",
      "  45. blog_15 -> 71 hits (genre: blog, year: 15)\n",
      "  46. blog_16 -> 74 hits (genre: blog, year: 16)\n",
      "  47. blog_17 -> 71 hits (genre: blog, year: 17)\n",
      "  48. blog_18 -> 69 hits (genre: blog, year: 18)\n",
      "  49. blog_19 -> 76 hits (genre: blog, year: 19)\n",
      "  50. blog_20 -> 82 hits (genre: blog, year: 20)\n",
      "  51. blog_21 -> 65 hits (genre: blog, year: 21)\n",
      "  52. blog_22 -> 71 hits (genre: blog, year: 22)\n",
      "  53. blog_23 -> 71 hits (genre: blog, year: 23)\n",
      "  54. blog_24 -> 86 hits (genre: blog, year: 24)\n",
      "  55. blog_25 -> 77 hits (genre: blog, year: 25)\n",
      "  56. blog_26 -> 81 hits (genre: blog, year: 26)\n",
      "  57. blog_27 -> 77 hits (genre: blog, year: 27)\n",
      "  58. blog_28 -> 79 hits (genre: blog, year: 28)\n",
      "  59. blog_29 -> 63 hits (genre: blog, year: 29)\n",
      "  60. blog_30 -> 71 hits (genre: blog, year: 30)\n",
      "  61. blog_31 -> 82 hits (genre: blog, year: 31)\n",
      "  62. blog_32 -> 84 hits (genre: blog, year: 32)\n",
      "  63. blog_33 -> 43 hits (genre: blog, year: 33)\n",
      "  64. blog_34 -> 51 hits (genre: blog, year: 34)\n",
      "  65. fic_1990 -> 29 hits (genre: fic, year: 1990)\n",
      "  66. fic_1991 -> 34 hits (genre: fic, year: 1991)\n",
      "  67. fic_1992 -> 31 hits (genre: fic, year: 1992)\n",
      "  68. fic_1993 -> 32 hits (genre: fic, year: 1993)\n",
      "  69. fic_1994 -> 40 hits (genre: fic, year: 1994)\n",
      "  70. fic_1995 -> 38 hits (genre: fic, year: 1995)\n",
      "  71. fic_1996 -> 47 hits (genre: fic, year: 1996)\n",
      "  72. fic_1997 -> 41 hits (genre: fic, year: 1997)\n",
      "  73. fic_1998 -> 43 hits (genre: fic, year: 1998)\n",
      "  74. fic_1999 -> 57 hits (genre: fic, year: 1999)\n",
      "  75. fic_2000 -> 50 hits (genre: fic, year: 2000)\n",
      "  76. fic_2001 -> 56 hits (genre: fic, year: 2001)\n",
      "  77. fic_2002 -> 48 hits (genre: fic, year: 2002)\n",
      "  78. fic_2003 -> 58 hits (genre: fic, year: 2003)\n",
      "  79. fic_2004 -> 69 hits (genre: fic, year: 2004)\n",
      "  80. fic_2005 -> 56 hits (genre: fic, year: 2005)\n",
      "  81. fic_2006 -> 68 hits (genre: fic, year: 2006)\n",
      "  82. fic_2007 -> 67 hits (genre: fic, year: 2007)\n",
      "  83. fic_2008 -> 89 hits (genre: fic, year: 2008)\n",
      "  84. fic_2009 -> 82 hits (genre: fic, year: 2009)\n",
      "  85. fic_2010 -> 75 hits (genre: fic, year: 2010)\n",
      "  86. fic_2011 -> 72 hits (genre: fic, year: 2011)\n",
      "  87. fic_2012 -> 74 hits (genre: fic, year: 2012)\n",
      "  88. fic_2013 -> 81 hits (genre: fic, year: 2013)\n",
      "  89. fic_2014 -> 68 hits (genre: fic, year: 2014)\n",
      "  90. fic_2015 -> 101 hits (genre: fic, year: 2015)\n",
      "  91. fic_2016 -> 58 hits (genre: fic, year: 2016)\n",
      "  92. fic_2017 -> 107 hits (genre: fic, year: 2017)\n",
      "  93. fic_2018 -> 57 hits (genre: fic, year: 2018)\n",
      "  94. fic_2019 -> 71 hits (genre: fic, year: 2019)\n",
      "  95. mag_1990 -> 99 hits (genre: mag, year: 1990)\n",
      "  96. mag_1991 -> 95 hits (genre: mag, year: 1991)\n",
      "  97. mag_1992 -> 98 hits (genre: mag, year: 1992)\n",
      "  98. mag_1993 -> 114 hits (genre: mag, year: 1993)\n",
      "  99. mag_1994 -> 106 hits (genre: mag, year: 1994)\n",
      "  100. mag_1995 -> 117 hits (genre: mag, year: 1995)\n",
      "  101. mag_1996 -> 127 hits (genre: mag, year: 1996)\n",
      "  102. mag_1997 -> 108 hits (genre: mag, year: 1997)\n",
      "  103. mag_1998 -> 102 hits (genre: mag, year: 1998)\n",
      "  104. mag_1999 -> 103 hits (genre: mag, year: 1999)\n",
      "  105. mag_2000 -> 97 hits (genre: mag, year: 2000)\n",
      "  106. mag_2001 -> 96 hits (genre: mag, year: 2001)\n",
      "  107. mag_2002 -> 83 hits (genre: mag, year: 2002)\n",
      "  108. mag_2003 -> 97 hits (genre: mag, year: 2003)\n",
      "  109. mag_2004 -> 105 hits (genre: mag, year: 2004)\n",
      "  110. mag_2005 -> 94 hits (genre: mag, year: 2005)\n",
      "  111. mag_2006 -> 108 hits (genre: mag, year: 2006)\n",
      "  112. mag_2007 -> 103 hits (genre: mag, year: 2007)\n",
      "  113. mag_2008 -> 113 hits (genre: mag, year: 2008)\n",
      "  114. mag_2009 -> 97 hits (genre: mag, year: 2009)\n",
      "  115. mag_2010 -> 90 hits (genre: mag, year: 2010)\n",
      "  116. mag_2011 -> 116 hits (genre: mag, year: 2011)\n",
      "  117. mag_2012 -> 102 hits (genre: mag, year: 2012)\n",
      "  118. mag_2013 -> 135 hits (genre: mag, year: 2013)\n",
      "  119. mag_2014 -> 119 hits (genre: mag, year: 2014)\n",
      "  120. mag_2015 -> 112 hits (genre: mag, year: 2015)\n",
      "  121. mag_2016 -> 145 hits (genre: mag, year: 2016)\n",
      "  122. mag_2017 -> 150 hits (genre: mag, year: 2017)\n",
      "  123. mag_2018 -> 192 hits (genre: mag, year: 2018)\n",
      "  124. mag_2019 -> 157 hits (genre: mag, year: 2019)\n",
      "  125. news_1990 -> 97 hits (genre: news, year: 1990)\n",
      "  126. news_1991 -> 107 hits (genre: news, year: 1991)\n",
      "  127. news_1992 -> 102 hits (genre: news, year: 1992)\n",
      "  128. news_1993 -> 108 hits (genre: news, year: 1993)\n",
      "  129. news_1994 -> 98 hits (genre: news, year: 1994)\n",
      "  130. news_1995 -> 106 hits (genre: news, year: 1995)\n",
      "  131. news_1996 -> 100 hits (genre: news, year: 1996)\n",
      "  132. news_1997 -> 140 hits (genre: news, year: 1997)\n",
      "  133. news_1998 -> 132 hits (genre: news, year: 1998)\n",
      "  134. news_1999 -> 143 hits (genre: news, year: 1999)\n",
      "  135. news_2000 -> 100 hits (genre: news, year: 2000)\n",
      "  136. news_2001 -> 125 hits (genre: news, year: 2001)\n",
      "  137. news_2002 -> 94 hits (genre: news, year: 2002)\n",
      "  138. news_2003 -> 139 hits (genre: news, year: 2003)\n",
      "  139. news_2004 -> 115 hits (genre: news, year: 2004)\n",
      "  140. news_2005 -> 127 hits (genre: news, year: 2005)\n",
      "  141. news_2006 -> 123 hits (genre: news, year: 2006)\n",
      "  142. news_2007 -> 133 hits (genre: news, year: 2007)\n",
      "  143. news_2008 -> 113 hits (genre: news, year: 2008)\n",
      "  144. news_2009 -> 125 hits (genre: news, year: 2009)\n",
      "  145. news_2010 -> 97 hits (genre: news, year: 2010)\n",
      "  146. news_2011 -> 143 hits (genre: news, year: 2011)\n",
      "  147. news_2012 -> 126 hits (genre: news, year: 2012)\n",
      "  148. news_2013 -> 139 hits (genre: news, year: 2013)\n",
      "  149. news_2014 -> 146 hits (genre: news, year: 2014)\n",
      "  150. news_2015 -> 197 hits (genre: news, year: 2015)\n",
      "  151. news_2016 -> 275 hits (genre: news, year: 2016)\n",
      "  152. news_2017 -> 309 hits (genre: news, year: 2017)\n",
      "  153. news_2018 -> 247 hits (genre: news, year: 2018)\n",
      "  154. news_2019 -> 285 hits (genre: news, year: 2019)\n",
      "  155. spok_1990 -> 49 hits (genre: spok, year: 1990)\n",
      "  156. spok_1991 -> 42 hits (genre: spok, year: 1991)\n",
      "  157. spok_1992 -> 59 hits (genre: spok, year: 1992)\n",
      "  158. spok_1993 -> 64 hits (genre: spok, year: 1993)\n",
      "  159. spok_1994 -> 55 hits (genre: spok, year: 1994)\n",
      "  160. spok_1995 -> 62 hits (genre: spok, year: 1995)\n",
      "  161. spok_1996 -> 67 hits (genre: spok, year: 1996)\n",
      "  162. spok_1997 -> 45 hits (genre: spok, year: 1997)\n",
      "  163. spok_1998 -> 56 hits (genre: spok, year: 1998)\n",
      "  164. spok_1999 -> 53 hits (genre: spok, year: 1999)\n",
      "  165. spok_2000 -> 73 hits (genre: spok, year: 2000)\n",
      "  166. spok_2001 -> 68 hits (genre: spok, year: 2001)\n",
      "  167. spok_2002 -> 95 hits (genre: spok, year: 2002)\n",
      "  168. spok_2003 -> 121 hits (genre: spok, year: 2003)\n",
      "  169. spok_2004 -> 103 hits (genre: spok, year: 2004)\n",
      "  170. spok_2005 -> 99 hits (genre: spok, year: 2005)\n",
      "  171. spok_2006 -> 115 hits (genre: spok, year: 2006)\n",
      "  172. spok_2007 -> 78 hits (genre: spok, year: 2007)\n",
      "  173. spok_2008 -> 55 hits (genre: spok, year: 2008)\n",
      "  174. spok_2009 -> 77 hits (genre: spok, year: 2009)\n",
      "  175. spok_2010 -> 71 hits (genre: spok, year: 2010)\n",
      "  176. spok_2011 -> 78 hits (genre: spok, year: 2011)\n",
      "  177. spok_2012 -> 73 hits (genre: spok, year: 2012)\n",
      "  178. spok_2013 -> 67 hits (genre: spok, year: 2013)\n",
      "  179. spok_2014 -> 57 hits (genre: spok, year: 2014)\n",
      "  180. spok_2015 -> 63 hits (genre: spok, year: 2015)\n",
      "  181. spok_2016 -> 57 hits (genre: spok, year: 2016)\n",
      "  182. spok_2017 -> 51 hits (genre: spok, year: 2017)\n",
      "  183. spok_2018 -> 56 hits (genre: spok, year: 2018)\n",
      "  184. spok_2019 -> 88 hits (genre: spok, year: 2019)\n",
      "  185. tvm_1990 -> 41 hits (genre: tvm, year: 1990)\n",
      "  186. tvm_1991 -> 35 hits (genre: tvm, year: 1991)\n",
      "  187. tvm_1992 -> 33 hits (genre: tvm, year: 1992)\n",
      "  188. tvm_1993 -> 46 hits (genre: tvm, year: 1993)\n",
      "  189. tvm_1994 -> 72 hits (genre: tvm, year: 1994)\n",
      "  190. tvm_1995 -> 75 hits (genre: tvm, year: 1995)\n",
      "  191. tvm_1996 -> 51 hits (genre: tvm, year: 1996)\n",
      "  192. tvm_1997 -> 56 hits (genre: tvm, year: 1997)\n",
      "  193. tvm_1998 -> 48 hits (genre: tvm, year: 1998)\n",
      "  194. tvm_1999 -> 45 hits (genre: tvm, year: 1999)\n",
      "  195. tvm_2000 -> 34 hits (genre: tvm, year: 2000)\n",
      "  196. tvm_2001 -> 41 hits (genre: tvm, year: 2001)\n",
      "  197. tvm_2002 -> 57 hits (genre: tvm, year: 2002)\n",
      "  198. tvm_2003 -> 64 hits (genre: tvm, year: 2003)\n",
      "  199. tvm_2004 -> 68 hits (genre: tvm, year: 2004)\n",
      "  200. tvm_2005 -> 71 hits (genre: tvm, year: 2005)\n",
      "  201. tvm_2006 -> 66 hits (genre: tvm, year: 2006)\n",
      "  202. tvm_2007 -> 61 hits (genre: tvm, year: 2007)\n",
      "  203. tvm_2008 -> 68 hits (genre: tvm, year: 2008)\n",
      "  204. tvm_2009 -> 63 hits (genre: tvm, year: 2009)\n",
      "  205. tvm_2010 -> 70 hits (genre: tvm, year: 2010)\n",
      "  206. tvm_2011 -> 73 hits (genre: tvm, year: 2011)\n",
      "  207. tvm_2012 -> 67 hits (genre: tvm, year: 2012)\n",
      "  208. tvm_2013 -> 84 hits (genre: tvm, year: 2013)\n",
      "  209. tvm_2014 -> 58 hits (genre: tvm, year: 2014)\n",
      "  210. tvm_2015 -> 56 hits (genre: tvm, year: 2015)\n",
      "  211. tvm_2016 -> 74 hits (genre: tvm, year: 2016)\n",
      "  212. tvm_2017 -> 64 hits (genre: tvm, year: 2017)\n",
      "  213. tvm_2018 -> 78 hits (genre: tvm, year: 2018)\n",
      "  214. tvm_2019 -> 69 hits (genre: tvm, year: 2019)\n",
      "  215. web_01 -> 69 hits (genre: web, year: 01)\n",
      "  216. web_02 -> 67 hits (genre: web, year: 02)\n",
      "  217. web_03 -> 56 hits (genre: web, year: 03)\n",
      "  218. web_04 -> 58 hits (genre: web, year: 04)\n",
      "  219. web_05 -> 73 hits (genre: web, year: 05)\n",
      "  220. web_06 -> 67 hits (genre: web, year: 06)\n",
      "  221. web_07 -> 71 hits (genre: web, year: 07)\n",
      "  222. web_08 -> 74 hits (genre: web, year: 08)\n",
      "  223. web_09 -> 54 hits (genre: web, year: 09)\n",
      "  224. web_10 -> 64 hits (genre: web, year: 10)\n",
      "  225. web_11 -> 52 hits (genre: web, year: 11)\n",
      "  226. web_12 -> 61 hits (genre: web, year: 12)\n",
      "  227. web_13 -> 60 hits (genre: web, year: 13)\n",
      "  228. web_14 -> 59 hits (genre: web, year: 14)\n",
      "  229. web_15 -> 75 hits (genre: web, year: 15)\n",
      "  230. web_16 -> 73 hits (genre: web, year: 16)\n",
      "  231. web_17 -> 69 hits (genre: web, year: 17)\n",
      "  232. web_18 -> 53 hits (genre: web, year: 18)\n",
      "  233. web_19 -> 62 hits (genre: web, year: 19)\n",
      "  234. web_20 -> 64 hits (genre: web, year: 20)\n",
      "  235. web_21 -> 60 hits (genre: web, year: 21)\n",
      "  236. web_22 -> 53 hits (genre: web, year: 22)\n",
      "  237. web_23 -> 77 hits (genre: web, year: 23)\n",
      "  238. web_24 -> 73 hits (genre: web, year: 24)\n",
      "  239. web_25 -> 73 hits (genre: web, year: 25)\n",
      "  240. web_26 -> 75 hits (genre: web, year: 26)\n",
      "  241. web_27 -> 74 hits (genre: web, year: 27)\n",
      "  242. web_28 -> 64 hits (genre: web, year: 28)\n",
      "  243. web_29 -> 72 hits (genre: web, year: 29)\n",
      "  244. web_30 -> 66 hits (genre: web, year: 30)\n",
      "  245. web_31 -> 64 hits (genre: web, year: 31)\n",
      "  246. web_32 -> 70 hits (genre: web, year: 32)\n",
      "  247. web_33 -> 41 hits (genre: web, year: 33)\n",
      "  248. web_34 -> 45 hits (genre: web, year: 34)\n",
      "\n",
      "🎯 Total genre_year combinations: 248\n",
      "📊 Unique genres found: ['acad', 'blog', 'fic', 'mag', 'news', 'spok', 'tvm', 'web']\n",
      "📅 Unique years found: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '20', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34']\n"
     ]
    }
   ],
   "source": [
    "# Debug: Show all genre_year keys returned by the search\n",
    "print(f\"📋 All genre_year keys found for '{keyword}':\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sorted_keys = sorted(bovine_kwic_json.keys())\n",
    "for i, key in enumerate(sorted_keys, 1):\n",
    "    hit_count = len(bovine_kwic_json[key]) if isinstance(bovine_kwic_json[key], dict) else 0\n",
    "    parts = key.split('_')\n",
    "    genre = parts[0] if len(parts) >= 1 else 'unknown'\n",
    "    year = parts[1] if len(parts) >= 2 else 'unknown'\n",
    "    print(f\"  {i:2}. {key} -> {hit_count:,} hits (genre: {genre}, year: {year})\")\n",
    "\n",
    "print(f\"\\n🎯 Total genre_year combinations: {len(sorted_keys)}\")\n",
    "\n",
    "# Show genre and year diversity\n",
    "genres = set()\n",
    "years = set()\n",
    "for key in sorted_keys:\n",
    "    parts = key.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        genres.add(parts[0])\n",
    "        years.add(parts[1])\n",
    "\n",
    "print(f\"📊 Unique genres found: {sorted(genres)}\")\n",
    "print(f\"📅 Unique years found: {sorted(years)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9902c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 COCA 'vehicle' Distribution Analysis\n",
      "==================================================\n",
      "🎯 Total hits: 20,089\n",
      "📋 Total genre_year combinations: 248\n",
      "\n",
      "📈 Hits by GENRE (total across all years):\n",
      "  news: 4,291 hits (21.4%)\n",
      "  mag: 3,380 hits (16.8%)\n",
      "  blog: 2,487 hits (12.4%)\n",
      "  web: 2,188 hits (10.9%)\n",
      "  spok: 2,097 hits (10.4%)\n",
      "  acad: 2,059 hits (10.2%)\n",
      "  fic: 1,799 hits (9.0%)\n",
      "  tvm: 1,788 hits (8.9%)\n",
      "\n",
      "📅 Hits by YEAR (total across all genres):\n",
      "  2017: 740 hits (3.7%)\n",
      "  2019: 707 hits (3.5%)\n",
      "  2018: 668 hits (3.3%)\n",
      "  2016: 659 hits (3.3%)\n",
      "  2003: 562 hits (2.8%)\n",
      "  2015: 560 hits (2.8%)\n",
      "  2013: 554 hits (2.8%)\n",
      "  2006: 554 hits (2.8%)\n",
      "  2011: 550 hits (2.7%)\n",
      "  2004: 542 hits (2.7%)\n",
      "  2005: 526 hits (2.6%)\n",
      "  2007: 516 hits (2.6%)\n",
      "  2008: 507 hits (2.5%)\n",
      "  2009: 499 hits (2.5%)\n",
      "  2012: 495 hits (2.5%)\n",
      "\n",
      "🔥 Top 10 genre_year combinations by hit count:\n",
      "   1. news_2017: 309 hits (genre: news, year: 2017)\n",
      "   2. news_2019: 285 hits (genre: news, year: 2019)\n",
      "   3. news_2016: 275 hits (genre: news, year: 2016)\n",
      "   4. news_2018: 247 hits (genre: news, year: 2018)\n",
      "   5. news_2015: 197 hits (genre: news, year: 2015)\n",
      "   6. mag_2018: 192 hits (genre: mag, year: 2018)\n",
      "   7. mag_2019: 157 hits (genre: mag, year: 2019)\n",
      "   8. mag_2017: 150 hits (genre: mag, year: 2017)\n",
      "   9. news_2014: 146 hits (genre: news, year: 2014)\n",
      "  10. mag_2016: 145 hits (genre: mag, year: 2016)\n",
      "\n",
      "🎲 Random Example Context:\n",
      "==============================\n",
      "Genre_Year Key: web_28\n",
      "  - Genre: web\n",
      "  - Year: 28\n",
      "Filename ID: 790\n",
      "Total hits in this genre_year: 64\n",
      "\n",
      "Sample text content:\n",
      "meals , travel , or **vehicle** allowances , plan , program\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Comprehensive COCA bovine data analysis\n",
    "print(\"📊 COCA '{}' Distribution Analysis\".format(keyword))\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze the structure: {genre_year: {filename_id: text_string}}\n",
    "genre_year_counts = {}\n",
    "total_hits = 0\n",
    "\n",
    "# Count hits per genre_year combination\n",
    "for genre_year_key, filename_dict in bovine_kwic_json.items():\n",
    "    # Count the number of filename entries (each represents a hit)\n",
    "    hit_count = len(filename_dict) if isinstance(filename_dict, dict) else 0\n",
    "    genre_year_counts[genre_year_key] = hit_count\n",
    "    total_hits += hit_count\n",
    "\n",
    "print(f\"🎯 Total hits: {total_hits:,}\")\n",
    "print(f\"📋 Total genre_year combinations: {len(genre_year_counts)}\")\n",
    "\n",
    "# 1. GENRE TOTALS (split on '_' and aggregate by genre [0])\n",
    "print(f\"\\n📈 Hits by GENRE (total across all years):\")\n",
    "genre_totals = {}\n",
    "for genre_year_key, hit_count in genre_year_counts.items():\n",
    "    # Split on '_' and take first part as genre\n",
    "    parts = genre_year_key.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        genre = parts[0]  # First part is genre\n",
    "        if genre not in genre_totals:\n",
    "            genre_totals[genre] = 0\n",
    "        genre_totals[genre] += hit_count\n",
    "\n",
    "for genre, total in sorted(genre_totals.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = (total / total_hits * 100) if total_hits > 0 else 0\n",
    "    print(f\"  {genre}: {total:,} hits ({percentage:.1f}%)\")\n",
    "\n",
    "# 2. YEAR TOTALS (split on '_' and aggregate by year [1])\n",
    "print(f\"\\n📅 Hits by YEAR (total across all genres):\")\n",
    "year_totals = {}\n",
    "for genre_year_key, hit_count in genre_year_counts.items():\n",
    "    # Split on '_' and take second part as year\n",
    "    parts = genre_year_key.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        year = parts[1]  # Second part is year\n",
    "        if year not in year_totals:\n",
    "            year_totals[year] = 0\n",
    "        year_totals[year] += hit_count\n",
    "\n",
    "# Sort years by hit count (top 15)\n",
    "for year, total in sorted(year_totals.items(), key=lambda x: x[1], reverse=True)[:15]:\n",
    "    percentage = (total / total_hits * 100) if total_hits > 0 else 0\n",
    "    print(f\"  {year}: {total:,} hits ({percentage:.1f}%)\")\n",
    "\n",
    "# 3. TOP 10 GENRE_YEAR combinations by hit count\n",
    "print(f\"\\n🔥 Top 10 genre_year combinations by hit count:\")\n",
    "sorted_counts = sorted(genre_year_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (genre_year_key, count) in enumerate(sorted_counts[:10], 1):\n",
    "    parts = genre_year_key.split('_')\n",
    "    genre = parts[0] if len(parts) >= 1 else 'unknown'\n",
    "    year = parts[1] if len(parts) >= 2 else 'unknown'\n",
    "    print(f\"  {i:2}. {genre_year_key}: {count:,} hits (genre: {genre}, year: {year})\")\n",
    "\n",
    "# 4. Random example for inspection\n",
    "print(f\"\\n🎲 Random Example Context:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Only select from genre_year combinations that have actual data\n",
    "non_empty_keys = [key for key, filename_dict in bovine_kwic_json.items() \n",
    "                  if isinstance(filename_dict, dict) and len(filename_dict) > 0]\n",
    "\n",
    "if non_empty_keys:\n",
    "    random_genre_year = random.choice(non_empty_keys)\n",
    "    random_filename_id = random.choice(list(bovine_kwic_json[random_genre_year].keys()))\n",
    "    random_text = bovine_kwic_json[random_genre_year][random_filename_id]\n",
    "\n",
    "    parts = random_genre_year.split('_')\n",
    "    genre = parts[0] if len(parts) >= 1 else 'unknown'\n",
    "    year = parts[1] if len(parts) >= 2 else 'unknown'\n",
    "\n",
    "    print(f\"Genre_Year Key: {random_genre_year}\")\n",
    "    print(f\"  - Genre: {genre}\")\n",
    "    print(f\"  - Year: {year}\")\n",
    "    print(f\"Filename ID: {random_filename_id}\")\n",
    "    print(f\"Total hits in this genre_year: {genre_year_counts.get(random_genre_year, 0):,}\")\n",
    "    print(f\"\\nSample text content:\")\n",
    "    print(f\"{str(random_text)[:200]}...\" if len(str(random_text)) > 200 else str(random_text))\n",
    "else:\n",
    "    print(\"❌ No genre_year combinations contain actual hit data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a0b48462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found data in genres: ['mag_1993', 'mag_1992', 'mag_1990', 'mag_1991', 'mag_1995', 'mag_1994', 'mag_1996', 'mag_1997', 'mag_2008', 'mag_2009', 'mag_2019', 'mag_2018', 'mag_2002', 'mag_2016', 'mag_2017', 'mag_2003', 'mag_2015', 'mag_2001', 'mag_2000', 'mag_2014', 'mag_2010', 'mag_2004', 'mag_2005', 'mag_2011', 'mag_2007', 'mag_2013', 'mag_2012', 'mag_2006', 'mag_1999', 'mag_1998', 'web_13', 'web_07', 'web_06', 'web_12', 'web_04', 'web_10', 'web_11', 'web_05', 'web_29', 'web_01', 'web_15', 'web_14', 'web_28', 'web_16', 'web_02', 'web_03', 'web_17', 'web_32', 'web_26', 'web_27', 'web_33', 'web_25', 'web_31', 'web_19', 'web_18', 'web_30', 'web_24', 'web_08', 'web_20', 'web_34', 'web_21', 'web_09', 'web_23', 'web_22', 'acad_2013', 'acad_2007', 'acad_2006', 'acad_2012', 'acad_2004', 'acad_2010', 'acad_2011', 'acad_2005', 'acad_2001', 'acad_2015', 'acad_2014', 'acad_2000', 'acad_2016', 'acad_2002', 'acad_2003', 'acad_2017', 'acad_1999', 'acad_1998', 'acad_1996', 'acad_1997', 'acad_1995', 'acad_1994', 'acad_1990', 'acad_1991', 'acad_1993', 'acad_1992', 'acad_2019', 'acad_2018', 'acad_2008', 'acad_2009', 'news_2018', 'news_2019', 'news_2009', 'news_2008', 'news_1994', 'news_1995', 'news_1997', 'news_1996', 'news_1992', 'news_1993', 'news_1991', 'news_1990', 'news_1998', 'news_1999', 'news_2011', 'news_2005', 'news_2004', 'news_2010', 'news_2006', 'news_2012', 'news_2013', 'news_2007', 'news_2003', 'news_2017', 'news_2016', 'news_2002', 'news_2014', 'news_2000', 'news_2001', 'news_2015', 'spok_1995', 'spok_1994', 'spok_1996', 'spok_1997', 'spok_1993', 'spok_1992', 'spok_1990', 'spok_1991', 'spok_2019', 'spok_2018', 'spok_2008', 'spok_2009', 'spok_2004', 'spok_2010', 'spok_2011', 'spok_2005', 'spok_2013', 'spok_2007', 'spok_2006', 'spok_2012', 'spok_2016', 'spok_2002', 'spok_2003', 'spok_2017', 'spok_2001', 'spok_2015', 'spok_2014', 'spok_2000', 'spok_1999', 'spok_1998', 'blog_26', 'blog_32', 'blog_33', 'blog_27', 'blog_19', 'blog_31', 'blog_25', 'blog_24', 'blog_30', 'blog_18', 'blog_34', 'blog_20', 'blog_08', 'blog_09', 'blog_21', 'blog_23', 'blog_22', 'blog_07', 'blog_13', 'blog_12', 'blog_06', 'blog_10', 'blog_04', 'blog_05', 'blog_11', 'blog_15', 'blog_01', 'blog_29', 'blog_28', 'blog_14', 'blog_02', 'blog_16', 'blog_17', 'blog_03', 'fic_1998', 'fic_1999', 'fic_2011', 'fic_2005', 'fic_2004', 'fic_2010', 'fic_2006', 'fic_2012', 'fic_2013', 'fic_2007', 'fic_2003', 'fic_2017', 'fic_2016', 'fic_2002', 'fic_2014', 'fic_2000', 'fic_2001', 'fic_2015', 'fic_2018', 'fic_2019', 'fic_2009', 'fic_2008', 'fic_1994', 'fic_1995', 'fic_1997', 'fic_1996', 'fic_1992', 'fic_1993', 'fic_1991', 'fic_1990', 'tvm_1999', 'tvm_1998', 'tvm_2010', 'tvm_2004', 'tvm_2005', 'tvm_2011', 'tvm_2007', 'tvm_2013', 'tvm_2012', 'tvm_2006', 'tvm_2002', 'tvm_2016', 'tvm_2017', 'tvm_2003', 'tvm_2015', 'tvm_2001', 'tvm_2000', 'tvm_2014', 'tvm_2019', 'tvm_2018', 'tvm_2008', 'tvm_2009', 'tvm_1995', 'tvm_1994', 'tvm_1996', 'tvm_1997', 'tvm_1993', 'tvm_1992', 'tvm_1990', 'tvm_1991']\n"
     ]
    }
   ],
   "source": [
    "print(f\"🔍 Found data in genres: {list(bovine_kwic_json.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d3e6b",
   "metadata": {},
   "source": [
    "### For a keyword like `vehicle` where there are MANY hits in COCA, strategies include:\n",
    "\n",
    "- filter on a smaller context window\n",
    "- randomly sample from the full set of hits, as to preserve all genre_year combos with at least one hit but then cull others (which could lead to over-representation of certain genre_year combos with few hits, but for the sake of demo, this is acceptable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "41afd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_down_ratio=0.28\n",
    "\n",
    "len(bovine_kwic_json)\n",
    "bovine_kwic_json.keys()\n",
    "# for each key, let's keep 25% of the data randomly to reduce input size\n",
    "import random\n",
    "reduced_bovine_kwic_json = {}\n",
    "for genre_year_key, filename_dict in bovine_kwic_json.items():\n",
    "    if isinstance(filename_dict, dict):\n",
    "        filenames = list(filename_dict.keys())\n",
    "        sample_size = max(1, int(len(filenames) * sample_down_ratio))  # Ensure at least one entry\n",
    "        sampled_filenames = random.sample(filenames, sample_size)\n",
    "        reduced_bovine_kwic_json[genre_year_key] = {fn: filename_dict[fn] for fn in sampled_filenames}\n",
    "    else:\n",
    "        reduced_bovine_kwic_json[genre_year_key] = filename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c308a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Running COCA forensic linguistics analysis...\n",
      "✅ Reading COCA results for keyword: vehicle\n",
      "🧪 COCA DEBUG: genre_year_keys=248 raw_chars=408132 extracted_chars=426663 total_contexts=5496\n",
      "🎯 All extracted contexts by genre: {'mag': 931, 'web': 594, 'acad': 561, 'news': 1190, 'spok': 568, 'blog': 678, 'fic': 489, 'tvm': 485}\n",
      "📊 Total contexts extracted: 5496\n",
      "\n",
      "✅ Analysis complete!\n",
      "Result type: <class 'list'>\n",
      "Got 2 result blocks\n",
      "Block 1: <class 'dict'> - {'type': 'reasoning_content', 'reasoning_content': {'text': 'We need to produce a structured analysi...\n",
      "Block 2: <class 'dict'> - {'type': 'text', 'text': '**COCA‑Vehicle (keyword\\u202f“vehicle”) – Forensic‑Linguistic Report**  \\n...\n",
      "\n",
      "✅ Analysis complete!\n",
      "Result type: <class 'list'>\n",
      "Got 2 result blocks\n",
      "Block 1: <class 'dict'> - {'type': 'reasoning_content', 'reasoning_content': {'text': 'We need to produce a structured analysi...\n",
      "Block 2: <class 'dict'> - {'type': 'text', 'text': '**COCA‑Vehicle (keyword\\u202f“vehicle”) – Forensic‑Linguistic Report**  \\n...\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🔬 Running COCA forensic linguistics analysis...\")\n",
    "    \n",
    "analysis_result = coca_forensic_tool._run(\n",
    "    keyword=test_keyword,\n",
    "    results_json=reduced_bovine_kwic_json,  # Use the JSON data\n",
    "    analysis_focus=\"forensic_linguistics\",\n",
    "    #max_contexts=50,  # Limit for demo\n",
    "    return_json=False,\n",
    "    extraction_strategy=\"all\",\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Analysis complete!\")\n",
    "print(f\"Result type: {type(analysis_result)}\")\n",
    "\n",
    "if isinstance(analysis_result, str):\n",
    "    print(f\"\\n{analysis_result[:]}...\")\n",
    "elif isinstance(analysis_result, list):\n",
    "    print(f\"Got {len(analysis_result)} result blocks\")\n",
    "    for i, block in enumerate(analysis_result[:2]):  # Show first 2 blocks\n",
    "        print(f\"Block {i+1}: {type(block)} - {str(block)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "07b97536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 Calculating optimal ratios from your AWS Bedrock errors:\n",
      "============================================================\n",
      "Ratio 1.00 → overage 340,508 tokens\n",
      "  → Optimal ratio: 0.2595\n",
      "  → Estimated tokens: 121,600\n",
      "  → Token utilization: 95.0%\n",
      "\n",
      "Ratio 0.50 → overage 103,739 tokens\n",
      "  → Optimal ratio: 0.2624\n",
      "  → Estimated tokens: 121,600\n",
      "  → Token utilization: 95.0%\n",
      "\n",
      "Ratio 0.30 → overage 8,010 tokens\n",
      "  → Optimal ratio: 0.2682\n",
      "  → Estimated tokens: 121,600\n",
      "  → Token utilization: 95.0%\n",
      "\n",
      "🎯 For your current case:\n",
      "Current ratio: 0.3\n",
      "Current overage: 8,010 tokens\n",
      "Optimal ratio: 0.2682\n",
      "Expected tokens: 121,600 / 128,000 (95.0%)\n",
      "Since 0.27 worked, the calculation is accurate! (0.2682 ≈ 0.27)\n",
      "\n",
      "🔧 Testing automatic error parsing:\n",
      "Error: max_tokens must be at least 1, got -340508.\n",
      "  → Auto-calculated optimal ratio: 0.2595\n",
      "  → Expected utilization: 95.0%\n",
      "Error: max_tokens must be at least 1, got -103739.\n",
      "  → Auto-calculated optimal ratio: 0.2624\n",
      "  → Expected utilization: 95.0%\n",
      "Error: max_tokens must be at least 1, got -8010.\n",
      "  → Auto-calculated optimal ratio: 0.2682\n",
      "  → Expected utilization: 95.0%\n",
      "🧮 Calculating optimal ratios from your AWS Bedrock errors:\n",
      "============================================================\n",
      "Ratio 1.00 → overage 340,508 tokens\n",
      "  → Optimal ratio: 0.2595\n",
      "  → Estimated tokens: 121,600\n",
      "  → Token utilization: 95.0%\n",
      "\n",
      "Ratio 0.50 → overage 103,739 tokens\n",
      "  → Optimal ratio: 0.2624\n",
      "  → Estimated tokens: 121,600\n",
      "  → Token utilization: 95.0%\n",
      "\n",
      "Ratio 0.30 → overage 8,010 tokens\n",
      "  → Optimal ratio: 0.2682\n",
      "  → Estimated tokens: 121,600\n",
      "  → Token utilization: 95.0%\n",
      "\n",
      "🎯 For your current case:\n",
      "Current ratio: 0.3\n",
      "Current overage: 8,010 tokens\n",
      "Optimal ratio: 0.2682\n",
      "Expected tokens: 121,600 / 128,000 (95.0%)\n",
      "Since 0.27 worked, the calculation is accurate! (0.2682 ≈ 0.27)\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate optimal sample ratio from AWS Bedrock token overage\n",
    "def calculate_optimal_ratio(current_ratio, token_overage, max_tokens=128000):\n",
    "    \"\"\"\n",
    "    Calculate the optimal sampling ratio to get as close as possible to max token count.\n",
    "    \n",
    "    Args:\n",
    "        current_ratio: The ratio that caused the overage (e.g., 0.3)\n",
    "        token_overage: Positive number of tokens over the limit (e.g., 8010)\n",
    "        max_tokens: Model's maximum token limit (default 128000)\n",
    "    \n",
    "    Returns:\n",
    "        optimal_ratio: Suggested ratio to use\n",
    "        estimated_tokens: Expected token count with optimal ratio\n",
    "    \"\"\"\n",
    "    # Current estimated tokens = max_tokens + overage\n",
    "    current_estimated_tokens = max_tokens + token_overage\n",
    "    \n",
    "    # Calculate the ratio needed to fit within max_tokens\n",
    "    # We want: current_estimated_tokens * scale_factor = max_tokens\n",
    "    scale_factor = max_tokens / current_estimated_tokens\n",
    "    \n",
    "    # Apply scale factor to current ratio\n",
    "    optimal_ratio = current_ratio * scale_factor\n",
    "    \n",
    "    # Add small buffer (reduce by 5%) to ensure we stay under limit\n",
    "    optimal_ratio_with_buffer = optimal_ratio * 0.95\n",
    "    \n",
    "    estimated_tokens = current_estimated_tokens * scale_factor * 0.95\n",
    "    \n",
    "    return optimal_ratio_with_buffer, estimated_tokens\n",
    "\n",
    "def extract_token_overage_from_error(error_str):\n",
    "    \"\"\"Extract token overage from AWS Bedrock error message.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'got (-?\\d+)', error_str)\n",
    "    if match:\n",
    "        negative_tokens = int(match.group(1))\n",
    "        return abs(negative_tokens)  # Convert negative to positive overage\n",
    "    return None\n",
    "\n",
    "def auto_calculate_ratio_from_error(error_str, current_ratio):\n",
    "    \"\"\"Automatically calculate optimal ratio from AWS Bedrock error.\"\"\"\n",
    "    overage = extract_token_overage_from_error(error_str)\n",
    "    if overage:\n",
    "        optimal, estimated = calculate_optimal_ratio(current_ratio, overage)\n",
    "        return {\n",
    "            'current_ratio': current_ratio,\n",
    "            'token_overage': overage,\n",
    "            'optimal_ratio': optimal,\n",
    "            'estimated_tokens': estimated,\n",
    "            'utilization_percent': estimated/128000*100\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Example calculations based on your data\n",
    "print(\"🧮 Calculating optimal ratios from your AWS Bedrock errors:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "examples = [\n",
    "    (1.0, 340508),\n",
    "    (0.5, 103739), \n",
    "    (0.3, 8010)\n",
    "]\n",
    "\n",
    "for ratio, overage in examples:\n",
    "    optimal, estimated = calculate_optimal_ratio(ratio, overage)\n",
    "    print(f\"Ratio {ratio:.2f} → overage {overage:,} tokens\")\n",
    "    print(f\"  → Optimal ratio: {optimal:.4f}\")\n",
    "    print(f\"  → Estimated tokens: {estimated:,.0f}\")\n",
    "    print(f\"  → Token utilization: {estimated/128000*100:.1f}%\")\n",
    "    print()\n",
    "\n",
    "# Quick calculator for your current case\n",
    "current_ratio = 0.3\n",
    "current_overage = 8010\n",
    "optimal, estimated = calculate_optimal_ratio(current_ratio, current_overage)\n",
    "\n",
    "print(f\"🎯 For your current case:\")\n",
    "print(f\"Current ratio: {current_ratio}\")\n",
    "print(f\"Current overage: {current_overage:,} tokens\")\n",
    "print(f\"Optimal ratio: {optimal:.4f}\")\n",
    "print(f\"Expected tokens: {estimated:,.0f} / 128,000 ({estimated/128000*100:.1f}%)\")\n",
    "print(f\"Since 0.27 worked, the calculation is accurate! ({optimal:.4f} ≈ 0.27)\")\n",
    "\n",
    "# Test the error parsing function\n",
    "test_errors = [\n",
    "    \"max_tokens must be at least 1, got -340508.\",\n",
    "    \"max_tokens must be at least 1, got -103739.\", \n",
    "    \"max_tokens must be at least 1, got -8010.\"\n",
    "]\n",
    "\n",
    "print(f\"\\n🔧 Testing automatic error parsing:\")\n",
    "for i, error in enumerate(test_errors):\n",
    "    ratio = [1.0, 0.5, 0.3][i]\n",
    "    result = auto_calculate_ratio_from_error(error, ratio)\n",
    "    if result:\n",
    "        print(f\"Error: {error}\")\n",
    "        print(f\"  → Auto-calculated optimal ratio: {result['optimal_ratio']:.4f}\")\n",
    "        print(f\"  → Expected utilization: {result['utilization_percent']:.1f}%\")# Function to calculate optimal sample ratio from AWS Bedrock token overage\n",
    "def calculate_optimal_ratio(current_ratio, token_overage, max_tokens=128000):\n",
    "    \"\"\"\n",
    "    Calculate the optimal sampling ratio to get as close as possible to max token count.\n",
    "    \n",
    "    Args:\n",
    "        current_ratio: The ratio that caused the overage (e.g., 0.3)\n",
    "        token_overage: Positive number of tokens over the limit (e.g., 8010)\n",
    "        max_tokens: Model's maximum token limit (default 128000)\n",
    "    \n",
    "    Returns:\n",
    "        optimal_ratio: Suggested ratio to use\n",
    "        estimated_tokens: Expected token count with optimal ratio\n",
    "    \"\"\"\n",
    "    # Current estimated tokens = max_tokens + overage\n",
    "    current_estimated_tokens = max_tokens + token_overage\n",
    "    \n",
    "    # Calculate the ratio needed to fit within max_tokens\n",
    "    # We want: current_estimated_tokens * scale_factor = max_tokens\n",
    "    scale_factor = max_tokens / current_estimated_tokens\n",
    "    \n",
    "    # Apply scale factor to current ratio\n",
    "    optimal_ratio = current_ratio * scale_factor\n",
    "    \n",
    "    # Add small buffer (reduce by 5%) to ensure we stay under limit\n",
    "    optimal_ratio_with_buffer = optimal_ratio * 0.95\n",
    "    \n",
    "    estimated_tokens = current_estimated_tokens * scale_factor * 0.95\n",
    "    \n",
    "    return optimal_ratio_with_buffer, estimated_tokens\n",
    "\n",
    "# Example calculations based on your data\n",
    "print(\"🧮 Calculating optimal ratios from your AWS Bedrock errors:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "examples = [\n",
    "    (1.0, 340508),\n",
    "    (0.5, 103739), \n",
    "    (0.3, 8010)\n",
    "]\n",
    "\n",
    "for ratio, overage in examples:\n",
    "    optimal, estimated = calculate_optimal_ratio(ratio, overage)\n",
    "    print(f\"Ratio {ratio:.2f} → overage {overage:,} tokens\")\n",
    "    print(f\"  → Optimal ratio: {optimal:.4f}\")\n",
    "    print(f\"  → Estimated tokens: {estimated:,.0f}\")\n",
    "    print(f\"  → Token utilization: {estimated/128000*100:.1f}%\")\n",
    "    print()\n",
    "\n",
    "# Quick calculator for your current case\n",
    "current_ratio = 0.3\n",
    "current_overage = 8010\n",
    "optimal, estimated = calculate_optimal_ratio(current_ratio, current_overage)\n",
    "\n",
    "print(f\"🎯 For your current case:\")\n",
    "print(f\"Current ratio: {current_ratio}\")\n",
    "print(f\"Current overage: {current_overage:,} tokens\")\n",
    "print(f\"Optimal ratio: {optimal:.4f}\")\n",
    "print(f\"Expected tokens: {estimated:,.0f} / 128,000 ({estimated/128000*100:.1f}%)\")\n",
    "print(f\"Since 0.27 worked, the calculation is accurate! ({optimal:.4f} ≈ 0.27)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7765a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Enhanced COCA forensic analysis exported: coca_forensic_vehicle_blocks.md (6160 chars)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coca_forensic_vehicle_blocks.md'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_coca_markdown_blocks(analysis_result, test_keyword)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26610d38",
   "metadata": {},
   "source": [
    "## Major Questions Doctrine\n",
    "\n",
    "In West Virginia v EPA, the Supreme Court invoked the \"major questions doctrine\" to limit the EPA's authority under the Clean Air Act. The Court ruled that significant regulatory actions require clear congressional authorization. This decision has implications for administrative law and the balance of power between agencies and Congress.\n",
    "\n",
    "Justice Kagan mentions \"get-out-of-text-free card\" on page 28 (), with a footnote #8\n",
    "\n",
    "> *8. \"The majority opinion at least addresses the statute’s text, though overstating its ambiguity and approaching the action taken under it with unwarranted “skepticism.” Ante, at 28; see ante, at 28–31. The concurrence, by contrast, concludes that the Clean Air Act does not clearly enough authorize EPA’s Plan without ever citing the statutory text. See ante, at 13–16. **Nowhere will you find the concurrence ask: What does the phrase “best system of emission reduction” mean? §7411(a)(1). So much for “begin[ning], as we must, with a careful examination of the statutory text.”** Henson v. Santander Consumer USA Inc., 582 U. S. 79,___ (2017) (slip op., at 3).\"*\n",
    "\n",
    "\n",
    "From the Clean Air Act, here is the relevant text for `\"best system of emission reduction\"`:\n",
    "\n",
    "> #### [42 U.S. Code § 7411 - Standards of performance for new stationary sources](https://www.law.cornell.edu/uscode/text/42/7411)\n",
    "> (a)Definitions\n",
    "> - For purposes of this section:\n",
    "> - (1)The term “standard of performance” means a standard for emissions of air pollutants which reflects the degree of emission limitation achievable through the application of the best system of emission reduction which (taking into account the cost of achieving such reduction and any nonair quality health and environmental impact and energy requirements) the Administrator determines has been adequately demonstrated.\n",
    "\n",
    "### Using COCA, we might attempt to answer Justice Kagan's question!\n",
    "\n",
    "- Think about `best system` & `emission reduction` in context of COCA usage. In theory you could get AI Agent tools to give you a statistical linguistic answer based on COCA usage of these terms, and use a secondary agent to take the summaries and attempt to answer the question!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca536d",
   "metadata": {},
   "source": [
    "### JSON Mode Analysis\n",
    "\n",
    "Now let's try the structured JSON mode for systematic data extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "237519c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No bovine_kwic data available for JSON analysis.\n"
     ]
    }
   ],
   "source": [
    "# JSON mode analysis for structured data extraction\n",
    "if 'bovine_kwic' in locals() and bovine_kwic:\n",
    "    json_analysis = coca_forensic_tool._run(\n",
    "        keyword=test_keyword,\n",
    "        results_json=bovine_kwic,\n",
    "        analysis_focus=\"semantic_variation\",  # Try different focus\n",
    "        max_contexts=50,\n",
    "        return_json=True,  # Request structured JSON\n",
    "        extraction_strategy=\"all\",\n",
    "        debug=False\n",
    "    )\n",
    "    \n",
    "    print(\"📊 Structured JSON Analysis Results:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if isinstance(json_analysis, dict):\n",
    "        for key, value in json_analysis.items():\n",
    "            if key == 'reasoning_content' and isinstance(value, list):\n",
    "                print(f\"{key}: {len(value)} reasoning steps\")\n",
    "                for i, step in enumerate(value[:3], 1):  # Show first 3 steps\n",
    "                    print(f\"  {i}. {step[:100]}...\")\n",
    "            elif isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"{key}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "        \n",
    "        # Export JSON analysis too\n",
    "        export_coca_markdown(json_analysis, f\"{test_keyword}_json\")\n",
    "    else:\n",
    "        print(\"Unexpected result format:\", type(json_analysis))\n",
    "        print(json_analysis)\n",
    "else:\n",
    "    print(\"❌ No bovine_kwic data available for JSON analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa1d4d",
   "metadata": {},
   "source": [
    "### Multiple Analysis Focus Modes\n",
    "\n",
    "The COCA forensic linguistics tool supports different analysis approaches:\n",
    "\n",
    "- **`forensic_linguistics`**: Comprehensive forensic analysis including semantic range, register variation, collocational profiles\n",
    "- **`semantic_variation`**: Focus on polysemy, meaning boundaries, metaphorical vs literal usage  \n",
    "- **`register_analysis`**: Compare formal vs informal usage, genre-specific conventions\n",
    "- **`diachronic`**: Analyze temporal patterns and semantic change (when time data available)\n",
    "- **`comparative`**: Cross-genre comparative analysis\n",
    "\n",
    "### Custom Analysis Example\n",
    "\n",
    "Let's try a register analysis to see how the keyword varies across COCA genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf67f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 COCA Analysis: 0 contexts across 248 genres | focus=register_analysis\n",
      "📝 Register Analysis Results (first 800 chars):\n",
      "============================================================\n",
      "[{'type': 'reasoning_content', 'reasoning_content': {'text': 'The user provides a request: \"You are a computational forensic linguistics AI agent analyzing COCA data. ... Provide structured analysis ... Use ONLY the provided COCA contexts\". However, the contexts list is empty: total contexts 0, and the KWIC contexts show none. So we need to handle that: no data available. We should explain that analysis cannot be performed because there\\'s no data, but can discuss methodology and limitations. Provide structured sections as requested, but note emptiness.\\n\\nWe must comply with policy: no disallowed content. It\\'s fine. Provide a thorough answer acknowledging lack of data and explaining what could be done if data were present, and the limitations.\\n\\nWe must not fabricate data. So provide analysis based on zero occurrences, which implies that the word \"bovine\" does not appear in any of the listed genres/years in this dataset. This itself is a finding: its absence.\\n\\nWe can discuss implications: maybe rare, technical term, likely appears in scientific literature not captured, etc.\\n\\nProceed to craft answer with sections.', 'signature': ''}}, {'type': 'text', 'text': '**FORENSIC LINGUISTIC ANALYSIS OF THE COCA KEYWORD “BOVINE”**  \\n*Prepared under the methodological constraints supplied by the user.*\\n\\n---\\n\\n## 1. Corpus Distribution Overview  \\n\\n| **Genre / Sub‑corpus** | **Number of Tokens of “bovine”** |\\n|------------------------|-----------------------------------|\\n| Magazine (1990‑2019)   | 0 |\\n| Web (1990‑2019)        | 0 |\\n| Academic (1990‑2019)   | 0 |\\n| News (1990‑2019)       | 0 |\\n| Spoken (1990‑2019)     | 0 |\\n| Blog (1990‑2019)       | 0 |\\n| Fiction (1990‑2019)    | 0 |\\n| Television/Movie (1990‑2019) | 0 |\\n| **TOTAL**              | **0** |\\n\\n*Interpretation:* Within the entire COCA sample (all 20\\u202f+ sub‑corpora, covering roughly three decades), the lexical item **“bovine”** does **not occur** even once. Consequently, any register‑specific, collocational, or statistical inference must be based on the **absence of evidence**, not on observed usage patterns.\\n\\n---\\n\\n## 2. Semantic Analysis  \\n\\nBecause no token of “bovine” is present, we cannot extract **in‑corpus semantic contexts** (e.g., literal vs. figurative senses, metaphorical extensions, or domain‑specific meanings). The term is known outside the corpus to denote *pertaining to cattle* (adjective) or *a member of the cattle family* (noun). The lack of attestation in COCOA suggests that:\\n\\n* The word is **lexically low‑frequency** in the public‑facing registers covered by COCA (news, magazines, blogs, spoken conversation, fiction, etc.).\\n* Its primary domains of use—**veterinary science, animal husbandry, biomedical research, and technical agricultural literature**—are largely **under‑represented** in COCA’s balanced sampling.\\n\\n---\\n\\n## 3. Register and Genre Patterns  \\n\\n### 3.1 Formal vs. Informal Registers  \\n*No data* → No empirical evidence of a preference for formal or informal contexts.\\n\\n### 3.2 Genre‑Specific Conventions  \\n* No instances in **magazine**, **news**, **blog**, **spoken**, or **fiction** registers.\\n* The absence across **academic** and **web** sub‑corpora also indicates that the term is not prevalent even in scholarly writing that is captured by COCA (which leans toward the humanities and social sciences rather than the natural sciences).\\n\\n### 3.3 Technical vs. General Usage  \\n*The zero count* implies that “bovine” is **exclusively technical** in the corpora that COCA samples, and those technical domains (e.g., veterinary journals, animal‑science conference proceedings) are **outside the scope** of the present data set.\\n\\n### 3.4 Sociolinguistic Variation  \\n*No contexts* → No basis for mapping variation by speaker demographics (age, gender, region, education) or by audience.\\n\\n---\\n\\n## 4. Collocational Analysis  \\n\\nBecause collocation extraction requires at least one token, **no valid collocates** can be reported. Typical collocates observed in external corpora (e.g., “bovine spongiform encephalopathy,” “bovine serum albumin,” “bovine herd,” “bovine growth hormone”) are **not present** here and therefore cannot be used as forensic evidence within this COCA slice.\\n\\n---\\n\\n## 5. Forensic Linguistics Assessment  \\n\\n| **Forensic Relevance** | **Finding** |\\n|------------------------|-------------|\\n| **Authorship profiling** | Impossible – no token to anchor lexical idiosyncrasies. |\\n| **Text authenticity / provenance** | Absence of “bovine” does not support or refute authenticity; it simply reflects the low‑frequency nature of the term in mainstream American English. |\\n| **Domain‑specific relevance** | The term’s non‑appearance suggests that any document containing “bovine” likely originates from a **specialized, non‑COCA‑sampled domain** (e.g., scientific research, industry reports). This can be a useful negative indicator when evaluating whether a disputed text is *intended* for a general public audience. |\\n| **Disputed meaning** | No contextual evidence to adjudicate between literal and figurative senses. |\\n\\n**Evidential Value:** *Negligible* within COCA; however, the *absence* itself can be a modest piece of circumstantial evidence that a text is **outside the mainstream registers** captured by COCA.\\n\\n---\\n\\n## 6. Interpretive Guidelines  \\n\\n1. **Do not infer usage patterns** (frequency, register preference, collocations) from the absence of data.  \\n2. When evaluating a target text that contains “bovine,” treat the term as **highly domain‑specific** and **unlikely** to be found in everyday genre samples.  \\n3. Consider supplementing COCA analysis with **specialized corpora** (e.g., PubMed, AGRICOLA, or proprietary veterinary journals) to obtain a reliable picture of the term’s lexical behavior.  \\n4. Use the zero‑frequency result as a **baseline indicator**: any occurrence of “bovine” in a document meant to resemble typical news, blog, or spoken discourse may signal *deliberate technical borrowing* or *stylistic embellishment*.\\n\\n---\\n\\n## 7. Methodological Limitations  \\n\\n| **Limitation** | **Impact on Findings** |\\n|----------------|------------------------|\\n| **Zero token count** | Prevents any quantitative or qualitative linguistic analysis; all reported patterns are **null**. |\\n| **Corpus coverage** | COCA balances across **general‑purpose** registers; it **under‑samples** technical scientific literature where “bovine” is expected to appear. |\\n| **Temporal granularity** | Although the data span 1990‑2019, no token appears in any year; any hypothesized diachronic trend cannot be examined. |\\n| **Genre granularity** | Sub‑genre differences (e.g., health news vs. agricultural news) cannot be distinguished because the term never occurs. |\\n| **External validity** | Conclusions drawn from this dataset cannot be generalized to **specialized corpora** or to **non‑American English** varieties. |\\n| **Forensic utility** | The evidentiary weight of a negative result is limited; it should be combined with other linguistic markers when forming forensic judgments. |\\n\\n---\\n\\n### Bottom‑Line Summary  \\n\\n- The keyword **“bovine”** is **absent** from every genre and sub‑corpus listed in the supplied COCA extraction.  \\n- Consequently, **no register‑specific, collocational, or semantic patterns** can be empirically described from this data.  \\n- The absence itself signals that “bovine” is a **low‑frequency, technically‑oriented term** not represented in mainstream American English corpora.  \\n- For any forensic or analytical task that hinges on the behavior of “bovine,” analysts must consult **domain‑specific corpora** beyond COCA and treat the current findings as a null baseline.'}]\n",
      "\n",
      "[Analysis continues...]\n",
      "📄 COCA forensic analysis exported: coca_forensic_bovine_register.md (7870 chars)\n",
      "📝 Register Analysis Results (first 800 chars):\n",
      "============================================================\n",
      "[{'type': 'reasoning_content', 'reasoning_content': {'text': 'The user provides a request: \"You are a computational forensic linguistics AI agent analyzing COCA data. ... Provide structured analysis ... Use ONLY the provided COCA contexts\". However, the contexts list is empty: total contexts 0, and the KWIC contexts show none. So we need to handle that: no data available. We should explain that analysis cannot be performed because there\\'s no data, but can discuss methodology and limitations. Provide structured sections as requested, but note emptiness.\\n\\nWe must comply with policy: no disallowed content. It\\'s fine. Provide a thorough answer acknowledging lack of data and explaining what could be done if data were present, and the limitations.\\n\\nWe must not fabricate data. So provide analysis based on zero occurrences, which implies that the word \"bovine\" does not appear in any of the listed genres/years in this dataset. This itself is a finding: its absence.\\n\\nWe can discuss implications: maybe rare, technical term, likely appears in scientific literature not captured, etc.\\n\\nProceed to craft answer with sections.', 'signature': ''}}, {'type': 'text', 'text': '**FORENSIC LINGUISTIC ANALYSIS OF THE COCA KEYWORD “BOVINE”**  \\n*Prepared under the methodological constraints supplied by the user.*\\n\\n---\\n\\n## 1. Corpus Distribution Overview  \\n\\n| **Genre / Sub‑corpus** | **Number of Tokens of “bovine”** |\\n|------------------------|-----------------------------------|\\n| Magazine (1990‑2019)   | 0 |\\n| Web (1990‑2019)        | 0 |\\n| Academic (1990‑2019)   | 0 |\\n| News (1990‑2019)       | 0 |\\n| Spoken (1990‑2019)     | 0 |\\n| Blog (1990‑2019)       | 0 |\\n| Fiction (1990‑2019)    | 0 |\\n| Television/Movie (1990‑2019) | 0 |\\n| **TOTAL**              | **0** |\\n\\n*Interpretation:* Within the entire COCA sample (all 20\\u202f+ sub‑corpora, covering roughly three decades), the lexical item **“bovine”** does **not occur** even once. Consequently, any register‑specific, collocational, or statistical inference must be based on the **absence of evidence**, not on observed usage patterns.\\n\\n---\\n\\n## 2. Semantic Analysis  \\n\\nBecause no token of “bovine” is present, we cannot extract **in‑corpus semantic contexts** (e.g., literal vs. figurative senses, metaphorical extensions, or domain‑specific meanings). The term is known outside the corpus to denote *pertaining to cattle* (adjective) or *a member of the cattle family* (noun). The lack of attestation in COCOA suggests that:\\n\\n* The word is **lexically low‑frequency** in the public‑facing registers covered by COCA (news, magazines, blogs, spoken conversation, fiction, etc.).\\n* Its primary domains of use—**veterinary science, animal husbandry, biomedical research, and technical agricultural literature**—are largely **under‑represented** in COCA’s balanced sampling.\\n\\n---\\n\\n## 3. Register and Genre Patterns  \\n\\n### 3.1 Formal vs. Informal Registers  \\n*No data* → No empirical evidence of a preference for formal or informal contexts.\\n\\n### 3.2 Genre‑Specific Conventions  \\n* No instances in **magazine**, **news**, **blog**, **spoken**, or **fiction** registers.\\n* The absence across **academic** and **web** sub‑corpora also indicates that the term is not prevalent even in scholarly writing that is captured by COCA (which leans toward the humanities and social sciences rather than the natural sciences).\\n\\n### 3.3 Technical vs. General Usage  \\n*The zero count* implies that “bovine” is **exclusively technical** in the corpora that COCA samples, and those technical domains (e.g., veterinary journals, animal‑science conference proceedings) are **outside the scope** of the present data set.\\n\\n### 3.4 Sociolinguistic Variation  \\n*No contexts* → No basis for mapping variation by speaker demographics (age, gender, region, education) or by audience.\\n\\n---\\n\\n## 4. Collocational Analysis  \\n\\nBecause collocation extraction requires at least one token, **no valid collocates** can be reported. Typical collocates observed in external corpora (e.g., “bovine spongiform encephalopathy,” “bovine serum albumin,” “bovine herd,” “bovine growth hormone”) are **not present** here and therefore cannot be used as forensic evidence within this COCA slice.\\n\\n---\\n\\n## 5. Forensic Linguistics Assessment  \\n\\n| **Forensic Relevance** | **Finding** |\\n|------------------------|-------------|\\n| **Authorship profiling** | Impossible – no token to anchor lexical idiosyncrasies. |\\n| **Text authenticity / provenance** | Absence of “bovine” does not support or refute authenticity; it simply reflects the low‑frequency nature of the term in mainstream American English. |\\n| **Domain‑specific relevance** | The term’s non‑appearance suggests that any document containing “bovine” likely originates from a **specialized, non‑COCA‑sampled domain** (e.g., scientific research, industry reports). This can be a useful negative indicator when evaluating whether a disputed text is *intended* for a general public audience. |\\n| **Disputed meaning** | No contextual evidence to adjudicate between literal and figurative senses. |\\n\\n**Evidential Value:** *Negligible* within COCA; however, the *absence* itself can be a modest piece of circumstantial evidence that a text is **outside the mainstream registers** captured by COCA.\\n\\n---\\n\\n## 6. Interpretive Guidelines  \\n\\n1. **Do not infer usage patterns** (frequency, register preference, collocations) from the absence of data.  \\n2. When evaluating a target text that contains “bovine,” treat the term as **highly domain‑specific** and **unlikely** to be found in everyday genre samples.  \\n3. Consider supplementing COCA analysis with **specialized corpora** (e.g., PubMed, AGRICOLA, or proprietary veterinary journals) to obtain a reliable picture of the term’s lexical behavior.  \\n4. Use the zero‑frequency result as a **baseline indicator**: any occurrence of “bovine” in a document meant to resemble typical news, blog, or spoken discourse may signal *deliberate technical borrowing* or *stylistic embellishment*.\\n\\n---\\n\\n## 7. Methodological Limitations  \\n\\n| **Limitation** | **Impact on Findings** |\\n|----------------|------------------------|\\n| **Zero token count** | Prevents any quantitative or qualitative linguistic analysis; all reported patterns are **null**. |\\n| **Corpus coverage** | COCA balances across **general‑purpose** registers; it **under‑samples** technical scientific literature where “bovine” is expected to appear. |\\n| **Temporal granularity** | Although the data span 1990‑2019, no token appears in any year; any hypothesized diachronic trend cannot be examined. |\\n| **Genre granularity** | Sub‑genre differences (e.g., health news vs. agricultural news) cannot be distinguished because the term never occurs. |\\n| **External validity** | Conclusions drawn from this dataset cannot be generalized to **specialized corpora** or to **non‑American English** varieties. |\\n| **Forensic utility** | The evidentiary weight of a negative result is limited; it should be combined with other linguistic markers when forming forensic judgments. |\\n\\n---\\n\\n### Bottom‑Line Summary  \\n\\n- The keyword **“bovine”** is **absent** from every genre and sub‑corpus listed in the supplied COCA extraction.  \\n- Consequently, **no register‑specific, collocational, or semantic patterns** can be empirically described from this data.  \\n- The absence itself signals that “bovine” is a **low‑frequency, technically‑oriented term** not represented in mainstream American English corpora.  \\n- For any forensic or analytical task that hinges on the behavior of “bovine,” analysts must consult **domain‑specific corpora** beyond COCA and treat the current findings as a null baseline.'}]\n",
      "\n",
      "[Analysis continues...]\n",
      "📄 COCA forensic analysis exported: coca_forensic_bovine_register.md (7870 chars)\n"
     ]
    }
   ],
   "source": [
    "# Register analysis example\n",
    "if 'bovine_kwic' in locals() and bovine_kwic:\n",
    "    register_analysis = coca_forensic_tool._run(\n",
    "        keyword=test_keyword,\n",
    "        results_json=bovine_kwic,\n",
    "        analysis_focus=\"register_analysis\",\n",
    "        max_contexts=40,\n",
    "        return_json=False,\n",
    "        extraction_strategy=\"all\"\n",
    "    )\n",
    "    \n",
    "    print(\"📝 Register Analysis Results (first 800 chars):\")\n",
    "    print(\"=\"*60)\n",
    "    print(register_analysis[:800])\n",
    "    print(\"\\n[Analysis continues...]\")\n",
    "    \n",
    "    # Export this analysis\n",
    "    export_coca_markdown(register_analysis, f\"{test_keyword}_register\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Need bovine_kwic data for register analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641f023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No register_analysis variable found to re-export\n"
     ]
    }
   ],
   "source": [
    "# Enhanced COCA markdown export function to handle structured block responses\n",
    "def export_coca_markdown_blocks(result, keyword: str, filename: str = None):\n",
    "    \"\"\"\n",
    "    Export COCA forensic linguistics analysis to markdown, handling both dict and list formats.\n",
    "    \n",
    "    This function can process:\n",
    "    - Dictionary results (JSON mode)\n",
    "    - List of blocks (typical LangChain/Bedrock response format)\n",
    "    - Simple string results\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    \n",
    "    def _sanitize(name: str) -> str:\n",
    "        return ''.join(c if (c.isalnum() or c in ('-','_')) else '_' for c in name.strip()) or 'analysis'\n",
    "    \n",
    "    safe_keyword = _sanitize(keyword)\n",
    "    outname = filename or f\"coca_forensic_{safe_keyword}_blocks.md\"\n",
    "    \n",
    "    lines = [f\"# COCA Forensic Linguistics Analysis: {keyword}\\n\\n\"]\n",
    "    lines.append(f\"*Generated: {datetime.utcnow().isoformat()}Z*\\n\\n\")\n",
    "    \n",
    "    # Handle different result formats\n",
    "    if isinstance(result, list):\n",
    "        # Extract reasoning content and main text from blocks\n",
    "        reasoning_parts = []\n",
    "        main_text_parts = []\n",
    "        \n",
    "        for block in result:\n",
    "            if isinstance(block, dict):\n",
    "                # Check for reasoning content\n",
    "                if block.get('type') == 'reasoning_content':\n",
    "                    rc = block.get('reasoning_content', {})\n",
    "                    if isinstance(rc, dict) and 'text' in rc:\n",
    "                        reasoning_parts.append(rc['text'])\n",
    "                    elif isinstance(rc, str):\n",
    "                        reasoning_parts.append(rc)\n",
    "                \n",
    "                # Check for main text content\n",
    "                if block.get('type') == 'text' and 'text' in block:\n",
    "                    main_text_parts.append(block['text'])\n",
    "                elif 'text' in block and block.get('type') != 'reasoning_content':\n",
    "                    main_text_parts.append(block['text'])\n",
    "            elif isinstance(block, str):\n",
    "                main_text_parts.append(block)\n",
    "        \n",
    "        # Add reasoning framework if found\n",
    "        if reasoning_parts:\n",
    "            lines.append(\"## Methodological Framework\\n\\n\")\n",
    "            lines.append(\"```text\\n\")\n",
    "            lines.append('\\n\\n'.join(reasoning_parts))\n",
    "            lines.append(\"\\n```\\n\\n\")\n",
    "        \n",
    "        # Add main analysis\n",
    "        if main_text_parts:\n",
    "            lines.append(\"## Analysis\\n\\n\")\n",
    "            lines.append('\\n\\n'.join(main_text_parts))\n",
    "            lines.append(\"\\n\\n\")\n",
    "    \n",
    "    elif isinstance(result, dict):\n",
    "        # Handle dictionary format (existing logic)\n",
    "        reasoning = result.get('reasoning_content', [])\n",
    "        if reasoning:\n",
    "            lines.append(\"## Methodological Framework\\n\\n\")\n",
    "            lines.append(\"```text\\n\")\n",
    "            if isinstance(reasoning, list):\n",
    "                lines.append('\\n'.join(str(r) for r in reasoning))\n",
    "            else:\n",
    "                lines.append(str(reasoning))\n",
    "            lines.append(\"\\n```\\n\\n\")\n",
    "        \n",
    "        # Add structured sections\n",
    "        sections = [\n",
    "            ('semantic_analysis', 'Semantic Analysis'),\n",
    "            ('register_patterns', 'Register and Genre Patterns'),\n",
    "            ('forensic_implications', 'Forensic Linguistics Assessment'),\n",
    "            ('summary', 'Summary'),\n",
    "            ('limitations', 'Limitations')\n",
    "        ]\n",
    "        \n",
    "        for field, title in sections:\n",
    "            if field in result and result[field]:\n",
    "                lines.append(f\"## {title}\\n\\n\")\n",
    "                lines.append(f\"{result[field]}\\n\\n\")\n",
    "        \n",
    "        # Add distribution data if available\n",
    "        if 'genre_distribution' in result:\n",
    "            lines.append(\"## Corpus Distribution\\n\\n\")\n",
    "            lines.append(\"```json\\n\")\n",
    "            lines.append(json.dumps(result['genre_distribution'], indent=2))\n",
    "            lines.append(\"\\n```\\n\\n\")\n",
    "    \n",
    "    else:\n",
    "        # Handle simple string format\n",
    "        lines.append(\"## Analysis\\n\\n\")\n",
    "        lines.append(str(result))\n",
    "        lines.append(\"\\n\\n\")\n",
    "    \n",
    "    # Add metadata footer\n",
    "    lines.append(\"---\\n\\n\")\n",
    "    lines.append(f\"*Analysis completed using COCA Forensic Linguistics Tool*\\n\")\n",
    "    lines.append(f\"*Keyword: {keyword} | Export timestamp: {datetime.utcnow().isoformat()}Z*\\n\")\n",
    "    \n",
    "    content = ''.join(lines)\n",
    "    \n",
    "    with open(outname, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    print(f\"📄 Enhanced COCA forensic analysis exported: {outname} ({len(content)} chars)\")\n",
    "    return outname\n",
    "\n",
    "# Re-export the register analysis with the enhanced function\n",
    "if 'register_analysis' in locals():\n",
    "    print(\"🔄 Re-exporting register analysis with enhanced block parser...\")\n",
    "    export_coca_markdown_blocks(register_analysis, f\"{test_keyword}_register_fixed\")\n",
    "else:\n",
    "    print(\"❌ No register_analysis variable found to re-export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e589e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-export all previous analyses with the enhanced block parser\n",
    "if 'analysis_result' in locals():\n",
    "    print(\"🔄 Re-exporting main forensic linguistics analysis...\")\n",
    "    export_coca_markdown_blocks(analysis_result, f\"{test_keyword}_forensic_fixed\")\n",
    "\n",
    "if 'json_analysis' in locals():\n",
    "    print(\"🔄 Re-exporting JSON analysis...\")\n",
    "    export_coca_markdown_blocks(json_analysis, f\"{test_keyword}_json_fixed\")\n",
    "\n",
    "print(\"\\n✅ All COCA analyses re-exported with proper block formatting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the improved context extraction with balanced genre sampling\n",
    "print(f\"🔧 Testing improved COCA forensic linguistics analysis with genre-balanced sampling...\")\n",
    "    \n",
    "test_analysis = coca_forensic_tool._run(\n",
    "    keyword=test_keyword,\n",
    "    results_json=bovine_kwic_json,  # Use the JSON data\n",
    "    analysis_focus=\"forensic_linguistics\",\n",
    "    max_contexts=100,  # Limit to 100 for testing, but ensure balanced across genres\n",
    "    return_json=False,\n",
    "    extraction_strategy=\"all\",\n",
    "    debug=True  # Enable debug to see genre distribution\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Improved analysis complete!\")\n",
    "print(f\"Result type: {type(test_analysis)}\")\n",
    "\n",
    "if isinstance(test_analysis, str):\n",
    "    # Look for evidence that all genres are being recognized\n",
    "    genre_mentions = {}\n",
    "    for genre in ['acad', 'blog', 'fic', 'mag', 'news', 'spok', 'tvm', 'web']:\n",
    "        if genre.lower() in test_analysis.lower():\n",
    "            genre_mentions[genre] = test_analysis.lower().count(genre.lower())\n",
    "    \n",
    "    print(f\"📊 Genre mentions in analysis: {genre_mentions}\")\n",
    "    print(f\"First 800 characters:\\n{test_analysis[:800]}...\")\n",
    "elif isinstance(test_analysis, list):\n",
    "    print(f\"Got {len(test_analysis)} result blocks\")\n",
    "    for i, block in enumerate(test_analysis[:2]):  # Show first 2 blocks\n",
    "        print(f\"Block {i+1}: {type(block)} - {str(block)[:100]}...\")\n",
    "\n",
    "# Export this improved analysis\n",
    "export_coca_markdown_blocks(test_analysis, f\"{test_keyword}_improved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a705c5",
   "metadata": {},
   "source": [
    "## Token Limit Handling\n",
    "\n",
    "The improved COCA forensic linguistics tool now includes smart token limit detection and ratio suggestions. When your dataset is too large, it will:\n",
    "\n",
    "1. **Estimate token usage** before sending to the model\n",
    "2. **Calculate suggested ratios** for data reduction  \n",
    "3. **Provide specific filtering recommendations**\n",
    "4. **Handle AWS Bedrock token limit errors gracefully**\n",
    "\n",
    "This prevents failed runs and gives you actionable steps to optimize your dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the token limit detection and ratio suggestion\n",
    "print(f\"🧪 Testing token limit handling with full 'dictionary' dataset...\")\n",
    "print(f\"📊 Dataset size: {len(bovine_kwic_json)} genre_year combinations\")\n",
    "\n",
    "# This should trigger the token limit detection and provide a suggested ratio\n",
    "large_dataset_result = coca_forensic_tool._run(\n",
    "    keyword=test_keyword,\n",
    "    results_json=bovine_kwic_json,  # Full dataset - likely to exceed token limits\n",
    "    analysis_focus=\"forensic_linguistics\",\n",
    "    return_json=True,  # Get structured response with ratio info\n",
    "    extraction_strategy=\"all\",\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 Result type: {type(large_dataset_result)}\")\n",
    "\n",
    "if isinstance(large_dataset_result, dict) and \"error\" in large_dataset_result:\n",
    "    print(f\"✅ Token limit detection worked!\")\n",
    "    if \"suggested_ratio\" in large_dataset_result:\n",
    "        ratio = large_dataset_result[\"suggested_ratio\"]\n",
    "        print(f\"📏 Suggested ratio: {ratio:.3f}\")\n",
    "        print(f\"💡 This means reduce your dataset to ~{ratio*100:.1f}% of current size\")\n",
    "    else:\n",
    "        print(\"ℹ️ Error detected but no ratio calculated (likely AWS Bedrock specific error)\")\n",
    "elif isinstance(large_dataset_result, str) and \"Token Limit\" in large_dataset_result:\n",
    "    print(f\"✅ Token limit detection worked! (string response)\")\n",
    "else:\n",
    "    print(f\"🤔 Unexpected result - either dataset was small enough or error handling needs adjustment\")\n",
    "    if isinstance(large_dataset_result, dict):\n",
    "        for key, value in large_dataset_result.items():\n",
    "            print(f\"  {key}: {str(value)[:100]}...\")\n",
    "    else:\n",
    "        print(f\"  Content preview: {str(large_dataset_result)[:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
