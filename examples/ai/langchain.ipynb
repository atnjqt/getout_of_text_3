{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2282fd",
   "metadata": {},
   "source": [
    "## Langchain Demo: AI Agents on AWS Bedrock\n",
    "\n",
    "This notebook demonstrates a proof of concept for an Agentic & Tool approach for integrating AI services with the `getout_of_text3` module.\n",
    "\n",
    "\n",
    "It's easy to leverage [`langchain`](https://python.langchain.com/docs/tutorials/agents/) in python for creating AI agents with tools, and provides support across various cloud providers.\n",
    "- On this notebook, we leverage [AWS Bedrock](https://aws.amazon.com/bedrock/) for access to the OpenAI open-sourced GPT model [`gpt-oss-120b`](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-openai.html) and \n",
    "- We bind [tools](https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html) to our AWS Bedrock model to invoke custom workflows, namely *to summarize KWIC filtered hits from our DIY SCOTUS Corpus*.\n",
    "- Make sure to configure your **AWS named profile** in `~/.aws/credentials` file with IAM permissions to invoke models on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ccd30d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your AWS credentials are configured\n",
    "import langchain\n",
    "from langchain.chat_models import init_chat_model\n",
    "import pandas as pd\n",
    "import getout_of_text_3 as got3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc07369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id='us.deepseek.r1-v1:0' # does not work with tools implementation\n",
    "#model_id='us.meta.llama4-maverick-17b-instruct-v1:0' # 1M\n",
    "#model_id='global.anthropic.claude-sonnet-4-5-20250929-v1:0' # 200K\n",
    "#max_tokens=64000 # for anthropic.claude-sonnet-4-5-20250929-v1:0\n",
    "#model_id='amazon.nova-pro-v1:0'\n",
    "#max_tokens=10000\n",
    "#model_id='us.amazon.nova-premier-v1:0'\n",
    "#max_tokens=32000\n",
    "model_id='openai.gpt-oss-120b-1:0' # 128,000 max token limit\n",
    "max_tokens=128000 # for openai.gpt-oss-120b-1:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88d5ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model_id, \n",
    "                        model_provider=\"bedrock_converse\",\n",
    "                        credentials_profile_name='atn-developer',\n",
    "                        max_tokens=max_tokens # maximum for bedrock converse\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d95f8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Portugal is **Lisbon**.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hi! What is the capital of Portugal?\"\n",
    "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "response.text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f7429",
   "metadata": {},
   "source": [
    "## DIY SCOTUS Corpus Query Tool & Example\n",
    "\n",
    "- Using `got3` to filter on keywords in a DIY SCOTUS Corpus, via extracting text in PDFs downloaded from **Library of Congress** collection on the [United States Reports](https://www.loc.gov/collections/united-states-reports/).\n",
    "- Corpus is stored as a **dictionary** of **dataframes**, where each key is a **volume number** and each dataframe contains the cases in that volume.\n",
    "    - the `case_id` is a concatenated volume and page number (i.e. `329001` is volume 329, page 1). This is also a schema for saving PDF downloads locally. See details at [the U.S. Report page](https://www.supremecourt.gov/opinions/USReports.aspx).\n",
    "\n",
    "        ```json\n",
    "        {\"329\": {DataFrame}, \n",
    "        \"330\": {DataFrame}, ..., \n",
    "        \"570\": {DataFrame}\n",
    "        }\n",
    "        ```\n",
    "        ```text\n",
    "        case_id\ttext\n",
    "        0\t570729\tOCTOBER \\nTERM, 2012 \\n729 \\nSyllabus \\nSEKHAR...\n",
    "        1\t570338\t338 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nUNIVER...\n",
    "        2\t570099\tOCTOBER \\nTERM, 2012 \\n99 \\nSyllabus \\nALLEYNE...\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36df068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pdf scotus files\n",
    "df = pd.read_json(\"loc_gov.json\", lines=True)\n",
    "\n",
    "df['key'] = df['filename'].apply(lambda x: x.split('usrep')[1][:3])\n",
    "df['subkey'] = df['filename'].apply(lambda x: x.split('usrep')[1].split('.pdf')[0])\n",
    "\n",
    "# Create a dictionary to hold the DataFrame contents\n",
    "df_dict = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if row['key'] not in df_dict:\n",
    "        df_dict[row['key']] = {}\n",
    "    df_dict[row['key']][row['subkey']] = row['content']\n",
    "\n",
    "# format scotus data for getout_of_text_3, similar to COCA keyword results\n",
    "db_dict_formatted = {}\n",
    "for volume, cases in df_dict.items():\n",
    "    # Create a DataFrame for each volume with case text\n",
    "    case_data = []\n",
    "    for case_id, case_text in cases.items():\n",
    "        case_data.append({'case_id': case_id, 'text': case_text})\n",
    "    db_dict_formatted[volume] = pd.DataFrame(case_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bbae1f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570729</td>\n",
       "      <td>OCTOBER \\nTERM, 2012 \\n729 \\nSyllabus \\nSEKHAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570338</td>\n",
       "      <td>338 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nUNIVER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570099</td>\n",
       "      <td>OCTOBER \\nTERM, 2012 \\n99 \\nSyllabus \\nALLEYNE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570529</td>\n",
       "      <td>OCTOBER \\nTERM, 2012 \\n529 \\nSyllabus \\nSHELBY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570048</td>\n",
       "      <td>48 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nMARACIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id                                               text\n",
       "0  570729  OCTOBER \\nTERM, 2012 \\n729 \\nSyllabus \\nSEKHAR...\n",
       "1  570338  338 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nUNIVER...\n",
       "2  570099  OCTOBER \\nTERM, 2012 \\n99 \\nSyllabus \\nALLEYNE...\n",
       "3  570529  OCTOBER \\nTERM, 2012 \\n529 \\nSyllabus \\nSHELBY...\n",
       "4  570048  48 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nMARACIC..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_keys = sorted(db_dict_formatted.keys(), key=lambda x: int(x), reverse=False)\n",
    "print(sorted_keys)\n",
    "db_dict_formatted['570'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bd340",
   "metadata": {},
   "source": [
    "## Creating Tools for AI Agents\n",
    "\n",
    "The following cell outlines two custom toolsets for the `got3` project. Neither is a definitive or factual summary of course, however this conceptual approach aims to:\n",
    "- leverage the latest trend in AI technologies, moving beyond generic chatbots to an **agentic approach**.\n",
    "\n",
    "### Tool Summary\n",
    "\n",
    "1. `ScotusAnalysisTool` which takes a keyword as an argument and attempts to filter local corpus files, and then invoke a model tool with the results.\n",
    "2. `ScotusFilteredAnalysisTool` which allows the user to provide the filtered local corpus extract (helpful to remove stopwords, false positive KWIC hits, etc) to then invoke a model tool with the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd8ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, Type, Dict, Any, Union, List\n",
    "import json\n",
    "import asyncio\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# =========================a===================================================\n",
    "# ORIGINAL live-search tool (now simplified for notebook-friendly execution)\n",
    "# ============================================================================\n",
    "class ScotusAnalysisInput(BaseModel):\n",
    "    \"\"\"Input for SCOTUS case analysis tool (performs a fresh keyword search).\"\"\"\n",
    "    keyword: str = Field(description=\"The keyword to search for and analyze in SCOTUS cases\")\n",
    "    analysis_focus: Optional[str] = Field(\n",
    "    default=\"general\", \n",
    "    description=\"Focus of analysis: 'general', 'evolution', 'judicial_philosophy', or 'custom'\"\n",
    "    )\n",
    "\n",
    "class ScotusAnalysisTool(BaseTool):\n",
    "    \"\"\"Tool that SEARCHES the SCOTUS corpus then analyzes.\n",
    "    NOTE: For pre-filtered JSON results, use ScotusFilteredAnalysisTool instead.\n",
    "\n",
    "    Implementation note (merged sync/async):\n",
    "    - We removed the prior _sync_run/_arun split + nest_asyncio hack.\n",
    "    - _run always works in notebooks (Jupyter event loop) using the sync model.invoke.\n",
    "    - A lightweight _arun delegator is kept for LangChain compatibility but just calls the sync core.\n",
    "    \"\"\"\n",
    "    name: str = \"scotus_analysis\"\n",
    "    description: str = (\n",
    "        \"Analyzes SCOTUS cases for a given keyword after performing an internal search. \"\n",
    "        \"Do NOT provide pre-filtered results to this tool.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ScotusAnalysisInput\n",
    "    model: Any = Field(exclude=True)\n",
    "    db_dict_formatted: Any = Field(exclude=True)\n",
    "\n",
    "    def __init__(self, model, db_dict_formatted, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "        self.db_dict_formatted = db_dict_formatted\n",
    "\n",
    "    # Public entry point (sync) ------------------------------------------------\n",
    "    def _run(self, keyword: str, analysis_focus: str = \"general\") -> str:  # noqa: D401\n",
    "        try:\n",
    "            return self._execute(keyword, analysis_focus)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error analyzing SCOTUS results: {e}\"\n",
    "            print(f\"❌ TOOL(search): {error_msg}\")\n",
    "            return error_msg\n",
    "\n",
    "    # Async compatibility (simply defers to sync to avoid loop issues in notebooks)\n",
    "    async def _arun(self, keyword: str, analysis_focus: str = \"general\") -> str:  # noqa: D401\n",
    "        return self._run(keyword, analysis_focus)\n",
    "\n",
    "    # Internal core (shared) --------------------------------------------------\n",
    "    def _execute(self, keyword: str, analysis_focus: str) -> str:\n",
    "        print(f\"🔍 TOOL(search): Searching SCOTUS database for keyword: '{keyword}'\")\n",
    "        import getout_of_text_3 as got3\n",
    "        # Dynamic context window that auto-shrinks if prompt would exceed max_tokens\n",
    "        base_context_words = 20\n",
    "        context_words = base_context_words\n",
    "        attempts = 0\n",
    "        final_prompt = None\n",
    "        results_dict = None\n",
    "        volumes = []\n",
    "        total_cases = 0\n",
    "        while True:\n",
    "            search_results = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=self.db_dict_formatted,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=context_words,\n",
    "                output=\"json\"\n",
    "            )\n",
    "            results_dict = {k: v for k, v in sorted(search_results.items(), key=lambda item: int(item[0])) if v}\n",
    "            if not results_dict:\n",
    "                return f\"No results found for keyword '{keyword}' in the SCOTUS database.\"\n",
    "            total_cases = sum(len(cases) for cases in results_dict.values())\n",
    "            volumes = list(results_dict.keys())\n",
    "            prompt = self._build_prompt(results_dict, keyword, analysis_focus, volumes, total_cases)\n",
    "            if len(prompt) <= max_tokens or context_words <= 5:\n",
    "                final_prompt = prompt\n",
    "                break\n",
    "            # Need to shrink\n",
    "            attempts += 1\n",
    "            ratio = max_tokens / len(prompt)\n",
    "            new_context_words = max(5, int(context_words * ratio * 0.9))  # 0.9 safety margin\n",
    "            if new_context_words >= context_words:\n",
    "                # No further shrink possible; accept risk of truncation\n",
    "                print(f\"⚠️ AUTO-SHRINK: Unable to further reduce context (floor reached or no progress). Using context_words={context_words}.\")\n",
    "                final_prompt = prompt\n",
    "                break\n",
    "            print(f\"🪄 AUTO-SHRINK: prompt {len(prompt)} > max_tokens {max_tokens}. context_words {context_words} -> {new_context_words} (ratio {ratio:.3f}). Retrying...\")\n",
    "            context_words = new_context_words\n",
    "        print(f\"📊 TOOL(search): Found {total_cases} cases across {len(volumes)} volumes | context_words_used={context_words} | shrink_attempts={attempts}\")\n",
    "        print(f\"🤖 TOOL(search): Sending {len(final_prompt)} characters to AI model for analysis\")\n",
    "        try:\n",
    "            if len(final_prompt) > max_tokens:\n",
    "                print(f\"⚠️ TOOL(search): Prompt length {len(final_prompt)} still > max_tokens {max_tokens}; model/provider may truncate.\")\n",
    "            response = self.model.invoke([{\"role\": \"user\", \"content\": final_prompt}])\n",
    "            content = getattr(response, 'content', str(response))\n",
    "            print(f\"✅ TOOL(search): Analysis complete, returning {len(content)} characters\")\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Model invocation failed: {e}\")\n",
    "\n",
    "    def _build_prompt(self, results_dict, keyword, analysis_focus, volumes, total_cases) -> str:\n",
    "        analysis_prompts = {\n",
    "            \"general\": f\"\"\"\n",
    "            Instructions:\n",
    "            You are an AI Agent inside the open-source forensic linguistic tool `getout_of_text_3`.\n",
    "            Analyze these SCOTUS case search results for the keyword \\\"{keyword}\\\" ONLY using the provided data.\n",
    "            Data summary:\n",
    "            - Volumes: {', '.join(sorted(volumes, key=int))}\n",
    "            - Total case occurrences: {total_cases}\n",
    "            Provide insights on:\n",
    "            1. Temporal evolution\n",
    "            2. Contextual variation\n",
    "            3. Notable intra-dataset patterns (do NOT import outside knowledge)\n",
    "            4. Interpretive themes relevant to ordinary meaning\n",
    "            Results (truncated JSON): {json.dumps(results_dict, indent=2)}...\n",
    "            \"\"\",\n",
    "            \"evolution\": f\"Focus on change over volumes for '{keyword}'.\\nData: {json.dumps(results_dict, indent=2)}...\",\n",
    "            \"judicial_philosophy\": f\"Assess patterns of usage that may hint at differing interpretive approaches for '{keyword}'. Use ONLY provided texts. Data: {json.dumps(results_dict, indent=2)}...\",\n",
    "            \"custom\": f\"Comprehensive analysis for '{keyword}'. Use ONLY provided dataset. Data: {json.dumps(results_dict, indent=2)}...\"\n",
    "        }\n",
    "        return analysis_prompts.get(analysis_focus, analysis_prompts[\"general\"]).strip()\n",
    "\n",
    "# ============================================================================\n",
    "# Pre-filtered JSON analysis tool (enhanced: extraction strategies + debug metrics + token preflight)\n",
    "# ============================================================================\n",
    "class ScotusFilteredAnalysisInput(BaseModel):\n",
    "    \"\"\"Input for analyzing an already-filtered SCOTUS keyword JSON result set.\"\"\"\n",
    "    keyword: str = Field(description=\"Keyword being analyzed (for labeling only, not for searching).\")\n",
    "    results_json: Union[str, Dict[str, Any]] = Field(\n",
    "        description=\"Pre-filtered JSON (or dict) output from got3.search_keyword_corpus AFTER user filtering.\"\n",
    "    )\n",
    "    analysis_focus: Optional[str] = Field(\n",
    "        default=\"general\", description=\"'general', 'evolution', 'judicial_philosophy', or 'custom'\"\n",
    "    )\n",
    "    max_contexts: Optional[int] = Field(\n",
    "        default=None, description=\"OPTIONAL cap on number of context snippets. If None/0 => include ALL.\"\n",
    "    )\n",
    "    return_json: bool = Field(\n",
    "        default=False, description=\"If True, attempt to return structured JSON with reasoning_content, summary, etc.\"\n",
    "    )\n",
    "    extraction_strategy: str = Field(\n",
    "        default=\"first\",\n",
    "        description=\"How to extract text from each occurrence: 'first' (first matching field), 'all' (all matching fields), 'raw_json' (embed entire JSON).\"\n",
    "    )\n",
    "    debug: bool = Field(\n",
    "        default=False, description=\"If True, prints and embeds debug metrics about extraction & token estimates.\"\n",
    "    )\n",
    "\n",
    "class ScotusFilteredAnalysisTool(BaseTool):\n",
    "    \"\"\"Analyze ONLY the supplied pre-filtered SCOTUS keyword result JSON.\n",
    "\n",
    "    Enhanced with:\n",
    "    - extraction_strategy (first|all|raw_json)\n",
    "    - debug metrics (raw vs extracted char counts, estimated tokens)\n",
    "    - token preflight rejection (early fail if would exceed model max_tokens)\n",
    "    Simplified for notebooks (single sync execution core). Async call just delegates.\n",
    "    \"\"\"\n",
    "    name: str = \"scotus_filtered_analysis\"\n",
    "    description: str = (\n",
    "        \"Analyzes pre-filtered SCOTUS keyword search JSON (from got3) without performing any new retrieval.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ScotusFilteredAnalysisInput\n",
    "    model: Any = Field(exclude=True)\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    # Normalization helper ----------------------------------------------------\n",
    "    def _normalize_model_content(self, raw: Any) -> str:\n",
    "        if isinstance(raw, str):\n",
    "            return raw\n",
    "        if isinstance(raw, list):\n",
    "            parts = []\n",
    "            for block in raw:\n",
    "                if isinstance(block, str):\n",
    "                    parts.append(block)\n",
    "                elif isinstance(block, dict):\n",
    "                    for key in (\"text\", \"content\", \"value\", \"message\"):\n",
    "                        val = block.get(key)\n",
    "                        if isinstance(val, str):\n",
    "                            parts.append(val)\n",
    "                            break\n",
    "                    else:\n",
    "                        parts.append(str(block))\n",
    "                else:\n",
    "                    parts.append(str(block))\n",
    "            return \"\\n\".join(parts)\n",
    "        if isinstance(raw, dict):\n",
    "            for key in (\"text\", \"content\", \"value\"):\n",
    "                if key in raw and isinstance(raw[key], str):\n",
    "                    return raw[key]\n",
    "            return json.dumps(raw)\n",
    "        return str(raw)\n",
    "\n",
    "    # Public sync entry -------------------------------------------------------\n",
    "    def _run(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"general\",\n",
    "        max_contexts: Optional[int] = None,\n",
    "        return_json: bool = False,\n",
    "        extraction_strategy: str = \"first\",\n",
    "        debug: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        try:\n",
    "            return self._execute(keyword, results_json, analysis_focus, max_contexts, return_json, extraction_strategy, debug)\n",
    "        except Exception as e:\n",
    "            msg = f\"Error (filtered analysis): {e}\"\n",
    "            print(msg)\n",
    "            return {\"error\": msg} if return_json else msg\n",
    "\n",
    "    # Async delegator ---------------------------------------------------------\n",
    "    async def _arun(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"general\",\n",
    "        max_contexts: Optional[int] = None,\n",
    "        return_json: bool = False,\n",
    "        extraction_strategy: str = \"first\",\n",
    "        debug: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        return self._run(keyword, results_json, analysis_focus, max_contexts, return_json, extraction_strategy, debug)\n",
    "\n",
    "    # Core logic --------------------------------------------------------------\n",
    "    def _execute(self, keyword, results_json, analysis_focus, max_contexts, return_json, extraction_strategy, debug):\n",
    "        if extraction_strategy not in {\"first\", \"all\", \"raw_json\"}:\n",
    "            raise ValueError(\"extraction_strategy must be one of: 'first','all','raw_json'\")\n",
    "        results_dict = self._coerce_results(results_json)\n",
    "        stats = self._compute_stats(results_dict, keyword, extraction_strategy)\n",
    "\n",
    "        # Debug & metrics ------------------------------------------------------\n",
    "        raw_json_str = json.dumps(results_dict, sort_keys=True)\n",
    "        raw_chars = len(raw_json_str)\n",
    "        # For metrics we still collect contexts unless raw_json mode\n",
    "        if extraction_strategy == 'raw_json':\n",
    "            extracted_contexts_for_metrics = self._sample_contexts(results_dict, max_contexts, 'all')\n",
    "        else:\n",
    "            extracted_contexts_for_metrics = self._sample_contexts(results_dict, max_contexts, extraction_strategy)\n",
    "        extracted_chars = sum(len(c) for c in extracted_contexts_for_metrics)\n",
    "        approx_tokens_raw = raw_chars / 4\n",
    "        approx_tokens_extracted = extracted_chars / 4\n",
    "        reduction_ratio = (extracted_chars / raw_chars) if raw_chars else 0\n",
    "        if debug:\n",
    "            print(f\"🧪 DEBUG(filtered): raw_chars={raw_chars} extracted_chars={extracted_chars} reduction_ratio={reduction_ratio:.3f} raw≈{approx_tokens_raw:.0f}tok extracted≈{approx_tokens_extracted:.0f}tok strategy={extraction_strategy} limit={max_contexts}\")\n",
    "\n",
    "        # Build prompt ----------------------------------------------------------\n",
    "        prompt = self._build_prompt(keyword, results_dict, stats, analysis_focus, max_contexts, return_json, extraction_strategy, debug, {\n",
    "            'raw_chars': raw_chars,\n",
    "            'extracted_chars': extracted_chars,\n",
    "            'approx_tokens_raw': approx_tokens_raw,\n",
    "            'approx_tokens_extracted': approx_tokens_extracted,\n",
    "            'reduction_ratio': reduction_ratio,\n",
    "            'extraction_strategy': extraction_strategy,\n",
    "        })\n",
    "        # Token preflight (char/4 heuristic) -----------------------------------\n",
    "        approx_prompt_tokens = len(prompt) / 4\n",
    "        if approx_prompt_tokens > max_tokens:\n",
    "            msg = (f\"Preflight rejection: prompt would exceed model max_tokens. approx_prompt_tokens={approx_prompt_tokens:.0f} > max_tokens={max_tokens}. \"\n",
    "                   f\"Strategy='{extraction_strategy}' raw_tokens≈{approx_tokens_raw:.0f} extracted_tokens≈{approx_tokens_extracted:.0f}. Consider: lower max_contexts, switch to 'first', or filter upstream.\")\n",
    "            print(f\"⚠️ {msg}\")\n",
    "            if return_json:\n",
    "                return {\n",
    "                    \"error\": \"prompt_too_large\",\n",
    "                    \"message\": msg,\n",
    "                    \"keyword\": keyword,\n",
    "                    \"total_contexts\": stats['total_contexts'],\n",
    "                    \"extraction_strategy\": extraction_strategy,\n",
    "                    \"raw_chars\": raw_chars,\n",
    "                    \"extracted_chars\": extracted_chars,\n",
    "                    \"approx_tokens_prompt\": approx_prompt_tokens,\n",
    "                }\n",
    "            return msg\n",
    "\n",
    "        print(f\"🤖 TOOL(filtered): Sending {len(prompt)} chars (≈{approx_prompt_tokens:.0f} tok) to model (contexts: {stats['total_contexts']}) | strategy={extraction_strategy} return_json={return_json}\")\n",
    "        response = self.model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        raw = getattr(response, 'content', None)\n",
    "        if raw is None and hasattr(response, 'text'):\n",
    "            try:\n",
    "                raw = response.text()\n",
    "            except Exception:\n",
    "                raw = response.text\n",
    "        content = self._normalize_model_content(raw)\n",
    "        if return_json:\n",
    "            return self._postprocess_json(content, results_dict, stats)\n",
    "        return content\n",
    "\n",
    "    # ---------------- Internal helpers ----------------\n",
    "    def _coerce_results(self, results_json: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        if isinstance(results_json, str):\n",
    "            results_dict = json.loads(results_json)\n",
    "        else:\n",
    "            results_dict = results_json\n",
    "        if not isinstance(results_dict, dict) or not results_dict:\n",
    "            raise ValueError(\"results_json must be a non-empty dict or JSON string\")\n",
    "        return results_dict\n",
    "\n",
    "    def _extract_contexts_from_case(self, occs, extraction_strategy: str) -> List[str]:\n",
    "        contexts: List[str] = []\n",
    "        if isinstance(occs, str):\n",
    "            contexts.append(occs)\n",
    "        elif isinstance(occs, dict):\n",
    "            keys_to_check = (\"context\", \"text\", \"snippet\", \"kwic\", \"content\", \"full_text\", \"body\")\n",
    "            if extraction_strategy == 'first':\n",
    "                for k in keys_to_check:\n",
    "                    if k in occs and isinstance(occs[k], str):\n",
    "                        contexts.append(occs[k])\n",
    "                        break\n",
    "            else:  # 'all' or 'raw_json' (raw_json uses entire JSON elsewhere but for metrics we gather all)\n",
    "                for k in keys_to_check:\n",
    "                    v = occs.get(k)\n",
    "                    if isinstance(v, str):\n",
    "                        contexts.append(v)\n",
    "        elif isinstance(occs, list):\n",
    "            for o in occs:\n",
    "                contexts.extend(self._extract_contexts_from_case(o, extraction_strategy))\n",
    "        return contexts\n",
    "\n",
    "    def _compute_stats(self, results_dict: Dict[str, Any], keyword: str, extraction_strategy: str) -> Dict[str, Any]:\n",
    "        volumes = sorted(results_dict.keys(), key=lambda x: int(x) if str(x).isdigit() else str(x))\n",
    "        case_counts = {}\n",
    "        total_contexts = 0\n",
    "        occurrences_per_case = []\n",
    "        for vol, cases in results_dict.items():\n",
    "            if not isinstance(cases, dict):\n",
    "                continue\n",
    "            case_counts[vol] = len(cases)\n",
    "            for case_id, occs in cases.items():\n",
    "                contexts = self._extract_contexts_from_case(occs, extraction_strategy)\n",
    "                occ_count = len(contexts)\n",
    "                total_contexts += occ_count\n",
    "                occurrences_per_case.append({\"volume\": vol, \"case_id\": case_id, \"occurrences\": occ_count})\n",
    "        return {\n",
    "            \"volumes\": volumes,\n",
    "            \"case_counts\": case_counts,\n",
    "            \"total_cases\": sum(case_counts.values()),\n",
    "            \"total_contexts\": total_contexts,\n",
    "            \"occurrences_per_case\": occurrences_per_case,\n",
    "            \"keyword\": keyword,\n",
    "        }\n",
    "\n",
    "    def _sample_contexts(self, results_dict: Dict[str, Any], max_contexts: Optional[int], extraction_strategy: str) -> List[str]:\n",
    "        # If max_contexts is None/0/negative: include ALL contexts (no truncation)\n",
    "        limit = max_contexts if isinstance(max_contexts, int) and max_contexts > 0 else None\n",
    "        samples: List[str] = []\n",
    "        if extraction_strategy == 'raw_json':\n",
    "            return samples  # handled separately (we embed full JSON)\n",
    "        for vol in sorted(results_dict.keys(), key=lambda x: int(x) if str(x).isdigit() else str(x)):\n",
    "            cases = results_dict[vol]\n",
    "            if not isinstance(cases, dict):\n",
    "                continue\n",
    "            for case_id, occs in cases.items():\n",
    "                contexts = self._extract_contexts_from_case(occs, extraction_strategy)\n",
    "                for ctx in contexts:\n",
    "                    cleaned = ' '.join(ctx.split())  # no clipping\n",
    "                    samples.append(f'[{vol}:{case_id}] {cleaned}')\n",
    "                    if limit and len(samples) >= limit:\n",
    "                        return samples\n",
    "        return samples\n",
    "\n",
    "    def _build_prompt(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_dict: Dict[str, Any],\n",
    "        stats: Dict[str, Any],\n",
    "        analysis_focus: str,\n",
    "        max_contexts: Optional[int],\n",
    "        return_json: bool,\n",
    "        extraction_strategy: str,\n",
    "        debug: bool,\n",
    "        metrics: Dict[str, Any],\n",
    "    ) -> str:\n",
    "        if extraction_strategy == 'raw_json':\n",
    "            raw_json_block = json.dumps(results_dict, indent=2)\n",
    "            # Provide a short note, then raw JSON. Model must rely ONLY on raw JSON.\n",
    "            contexts_section = (\n",
    "                f\"RAW_JSON_MODE: Entire filtered JSON provided below. Size chars={metrics['raw_chars']} approx_tokens={metrics['approx_tokens_raw']:.0f}.\\n\"\n",
    "                \"Do NOT hallucinate beyond this data.\\n---\\n\" + raw_json_block + \"\\n---\\n\"\n",
    "            )\n",
    "            sample_contexts = []\n",
    "        else:\n",
    "            sample_contexts = self._sample_contexts(results_dict, max_contexts, extraction_strategy)\n",
    "            if not sample_contexts:\n",
    "                sample_contexts = [\"(No context strings extracted — verify input JSON structure)\"]\n",
    "            contexts_section = (\n",
    "                f\"Sample Contexts ({len(sample_contexts)}) strategy={extraction_strategy} (max_contexts={max_contexts}):\\n---\\n\"\n",
    "                + \"\\n\".join(sample_contexts) + \"\\n---\\n\"\n",
    "            )\n",
    "\n",
    "        focus_instructions = {\n",
    "            \"general\": \"Provide an overview of usage patterns, semantic ranges, and any interpretive variability.\",\n",
    "            \"evolution\": \"Describe shifts across volumes (treat volume ordering as temporal proxy if applicable).\",\n",
    "            \"judicial_philosophy\": \"Identify internal patterns that might hint at differing interpretive strategies (ONLY within provided data).\",\n",
    "            \"custom\": \"Provide a comprehensive structured analysis (frequency, contextual clusters, potential senses).\",\n",
    "        }\n",
    "        occ_lines = sorted(\n",
    "            [f\"{o['volume']}:{o['case_id']}={o['occurrences']}\" for o in stats[\"occurrences_per_case\"]],\n",
    "            key=lambda x: x\n",
    "        )[:80]\n",
    "\n",
    "        debug_block = \"\"\n",
    "        if debug:\n",
    "            debug_block = (\n",
    "                \"DEBUG METRICS (for transparency, do NOT just repeat):\\n\"\n",
    "                f\"raw_chars={metrics['raw_chars']} extracted_chars={metrics['extracted_chars']} reduction_ratio={metrics['reduction_ratio']:.3f}\\n\"\n",
    "                f\"approx_tokens_raw={metrics['approx_tokens_raw']:.0f} approx_tokens_extracted={metrics['approx_tokens_extracted']:.0f} strategy={metrics['extraction_strategy']}\\n\"\n",
    "            )\n",
    "\n",
    "        base = f\"\"\"\n",
    "            You are an AI analysis component of `getout_of_text_3`.\n",
    "            STRICT RULE: Use ONLY the provided contexts / JSON. DO NOT introduce external cases, doctrines, or speculative references.\n",
    "            Keyword: \"{keyword}\"\n",
    "            Volumes: {', '.join(stats['volumes'])}\n",
    "            Total Cases: {stats['total_cases']} | Total Context Snippets (computed with strategy='{extraction_strategy}'): {stats['total_contexts']}\n",
    "            Occurrences Per Case (sample): {'; '.join(occ_lines)}\n",
    "            Analysis Focus: {analysis_focus} → {focus_instructions.get(analysis_focus, focus_instructions['general'])}\n",
    "            {debug_block}\n",
    "            {contexts_section}\n",
    "        \"\"\"\n",
    "        if return_json:\n",
    "            base += (\n",
    "                \"Return ONLY valid JSON with this exact top-level structure (no extra prose):\\n\"\n",
    "                \"{\\n\"\n",
    "                \"  \\\"keyword\\\": string,\\n\"\n",
    "                \"  \\\"total_contexts\\\": number,\\n\"\n",
    "                \"  \\\"occurrences_summary\\\": string,\\n\"\n",
    "                \"  \\\"reasoning_content\\\": [string, ...],\\n\"\n",
    "                \"  \\\"summary\\\": string,\\n\"\n",
    "                \"  \\\"limitations\\\": string\\n\"\n",
    "                \"}\\n\"\n",
    "                \"Populate reasoning_content with a short step-by-step (3-6 bullets).\\n\"\n",
    "                \"If only one occurrence, reasoning_content should note insufficient data for variation.\"\n",
    "            )\n",
    "        else:\n",
    "            base += (\n",
    "                \"Required Output Sections:\\n1. Usage Summary\\n2. Contextual Patterns / Proto-senses\\n3. Frequency & Distribution Observations\\n4. Interpretability Notes (ordinary meaning indicators)\\n5. Open Questions / Ambiguities\\nGround all claims ONLY in the contexts above.\"\n",
    "            )\n",
    "        if stats['total_contexts'] == 1:\n",
    "            base += \"\\nNOTE: Only one occurrence detected.\"\n",
    "        return base.strip()\n",
    "\n",
    "    def _postprocess_json(self, content: str, results_dict: Dict[str, Any], stats: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        parsed = None\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "        except Exception:\n",
    "            if isinstance(content, str):\n",
    "                match = re.search(r'{[\\s\\S]*}', content)\n",
    "                if match:\n",
    "                    try:\n",
    "                        parsed = json.loads(match.group(0))\n",
    "                    except Exception:\n",
    "                        parsed = None\n",
    "        if not isinstance(parsed, dict):\n",
    "            parsed = {\n",
    "                \"keyword\": stats['keyword'],\n",
    "                \"total_contexts\": stats['total_contexts'],\n",
    "                \"occurrences_summary\": f\"{stats['total_contexts']} context snippet(s) across {stats['total_cases']} case(s)\",\n",
    "                \"reasoning_content\": [\n",
    "                    \"Model did not return valid JSON; wrapped raw text.\",\n",
    "                    \"Single occurrence limits distributional inference.\" if stats['total_contexts']==1 else \"Multiple contexts allow limited comparative analysis.\"\n",
    "                ],\n",
    "                \"summary\": content[:4000] if isinstance(content, str) else str(content)[:4000],\n",
    "                \"limitations\": \"Auto-wrapped due to invalid JSON from model.\"\n",
    "            }\n",
    "        for k, default in [\n",
    "            (\"reasoning_content\", []),\n",
    "            (\"summary\", \"\"),\n",
    "            (\"occurrences_summary\", f\"{stats['total_contexts']} snippet(s) across {stats['total_cases']} case(s)\"),\n",
    "            (\"limitations\", \"\")\n",
    "        ]:\n",
    "            if k not in parsed:\n",
    "                parsed[k] = default\n",
    "        return parsed\n",
    "\n",
    "# Helper: format result so reasoning_content appears LAST under a heading\n",
    "def format_result_output(result):\n",
    "    \"\"\"Return a single string with main answer first and reasoning_content appended at end.\n",
    "    Format:\n",
    "    <answer text>\n",
    "\n",
    "    ## reasoning content\n",
    "    ```text\n",
    "    <reasoning>\n",
    "    ```\n",
    "    Handles several possible shapes returned by Bedrock / LangChain tool binding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(result, str):\n",
    "            return result\n",
    "        if isinstance(result, dict):\n",
    "            reasoning = []\n",
    "            rc = result.get(\"reasoning_content\")\n",
    "            if isinstance(rc, list):\n",
    "                reasoning.append(\"\\n\".join(str(x) for x in rc))\n",
    "            elif isinstance(rc, str):\n",
    "                reasoning.append(rc)\n",
    "            elif isinstance(rc, dict) and \"text\" in rc:\n",
    "                reasoning.append(rc[\"text\"])\n",
    "            main_parts = []\n",
    "            for key in (\"summary\", \"text\", \"content\"):\n",
    "                if key in result and isinstance(result[key], str):\n",
    "                    main_parts.append(result[key])\n",
    "            main_text = \"\\n\\n\".join(p for p in main_parts if p and p.strip())\n",
    "            reasoning_text = \"\\n\\n\".join(r for r in reasoning if r and r.strip())\n",
    "            if reasoning_text:\n",
    "                return f\"{main_text}\\n\\n## reasoning content\\n```text\\n{reasoning_text}\\n```\" if main_text else f\"## reasoning content\\n```text\\n{reasoning_text}\\n```\"\n",
    "            return main_text or str(result)\n",
    "        if isinstance(result, list):\n",
    "            reasoning_segments = []\n",
    "            answer_segments = []\n",
    "            for block in result:\n",
    "                if not isinstance(block, dict):\n",
    "                    continue\n",
    "                rc = block.get(\"reasoning_content\")\n",
    "                if isinstance(rc, dict) and \"text\" in rc and rc[\"text\"].strip():\n",
    "                    reasoning_segments.append(rc[\"text\"].strip())\n",
    "                elif isinstance(rc, str) and rc.strip():\n",
    "                    reasoning_segments.append(rc.strip())\n",
    "                if \"text\" in block and isinstance(block[\"text\"], str) and block[\"text\"].strip():\n",
    "                    answer_segments.append(block[\"text\"].strip())\n",
    "            main_answer = \"\\n\\n\".join(answer_segments) if answer_segments else \"\"\n",
    "            reasoning_text = \"\\n\\n\".join(reasoning_segments)\n",
    "            if reasoning_text:\n",
    "                return f\"{main_answer}\\n\\n## reasoning content\\n```text\\n{reasoning_text}\\n```\" if main_answer else f\"## reasoning content\\n```text\\n{reasoning_text}\\n```\"\n",
    "            return main_answer or str(result)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"(Formatting error: {e})\\n{result}\"\n",
    "    \n",
    "def export_markdown(result_text, keyword):\n",
    "    \"\"\"\n",
    "    Export unified analysis (answer + reasoning content at end) to ONE markdown file.\n",
    "    \"\"\"\n",
    "    safe_keyword = \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in keyword.strip()) or \"analysis_output\"\n",
    "    formatted_output = format_result_output(result_text)\n",
    "    outfile = f\"{safe_keyword}.md\"\n",
    "    with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(formatted_output)\n",
    "    print(f\"Wrote combined analysis + reasoning to {outfile} (length={len(formatted_output)} chars)\")\n",
    "    return outfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365cfdfd",
   "metadata": {},
   "source": [
    "## Create the agent by binging the tools and the model together\n",
    "\n",
    "Updated: We now have two tools bound:\n",
    "1. `scotus_analysis` performs an internal search.\n",
    "2. `scotus_filtered_analysis` ONLY analyzes pre-filtered JSON you already produced (no new search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "22099eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined: ScotusAnalysisTool (searching) & ScotusFilteredAnalysisTool (pre-filtered with flexible parsing + optional JSON mode, normalized content)\n",
      " ✅ Tools bound to model: ['scotus_analysis', 'scotus_filtered_analysis']\n",
      " 👨‍⚖️ SCOTUS database has 242 volumes\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tools\n",
    "scotus_tool = ScotusAnalysisTool(model=model, db_dict_formatted=db_dict_formatted)\n",
    "filtered_scotus_tool = ScotusFilteredAnalysisTool(model=model)\n",
    "\n",
    "tools = [scotus_tool, filtered_scotus_tool]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "print(\"Defined: ScotusAnalysisTool (searching) & ScotusFilteredAnalysisTool (pre-filtered with flexible parsing + optional JSON mode, normalized content)\")\n",
    "print(f\" ✅ Tools bound to model: {[tool.name for tool in tools]}\")\n",
    "print(f\" 👨‍⚖️ SCOTUS database has {len(db_dict_formatted)} volumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1a0ae",
   "metadata": {},
   "source": [
    "### Compare extraction strategies (`first`, `all`, `raw_json`) with debug metrics\n",
    "The next cell will:\n",
    "1. Run a search for a moderately frequent keyword.\n",
    "2. Invoke `scotus_filtered_analysis` three times with different `extraction_strategy` values.\n",
    "3. Show debug metrics (raw vs extracted char counts, token estimates, reduction ratio).\n",
    "4. Demonstrate preflight rejection if the raw JSON would exceed token limit (you can artificially force this by choosing a very frequent term or increasing context window upstream).\n",
    "\n",
    "NOTE: `raw_json` embeds the entire JSON (can be huge) — use sparingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d12964",
   "metadata": {},
   "outputs": [],
   "source": [
    "_demo_keyword = 'vehicle'  # adjust to test token scaling\n",
    "print(f\"[DEMO] Building pre-filtered results for '{_demo_keyword}' (context_words=30)\")\n",
    "_demo_results = got3.search_keyword_corpus(\n",
    "    keyword=_demo_keyword,\n",
    "    db_dict=db_dict_formatted,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=30,\n",
    "    output='json'\n",
    ")\n",
    "# prune empties & sort\n",
    "_demo_results = {k: v for k, v in sorted(_demo_results.items(), key=lambda item: int(item[0])) if v}\n",
    "_demo_json = json.dumps(_demo_results)\n",
    "print(f\"Volumes with hits: {list(_demo_results.keys())[:8]} ... total_vols={len(_demo_results)}\")\n",
    "\n",
    "for strategy in ['first','all','raw_json']:\n",
    "    print(\"\\n============================\")\n",
    "    print(f\"[DEMO] Strategy='{strategy}' (max_contexts=None, debug=True)\")\n",
    "    try:\n",
    "        out = filtered_scotus_tool._run(\n",
    "            keyword=_demo_keyword,\n",
    "            results_json=_demo_json,\n",
    "            analysis_focus='general',\n",
    "            max_contexts=None,  # unlimited\n",
    "            return_json=False,\n",
    "            extraction_strategy=strategy,\n",
    "            debug=True\n",
    "        )\n",
    "        # Only print a small slice to avoid flooding\n",
    "        print(out[:600] + ('...' if len(out)>600 else ''))\n",
    "    except Exception as e:\n",
    "        print(f\"(Error strategy={strategy}: {e})\")\n",
    "print(\"\\n[DEMO] Extraction strategy comparison complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc087c",
   "metadata": {},
   "source": [
    "## 1st tool: AI will search the corpus for you and analyze results\n",
    "\n",
    "- for terms in the corpora that are very frequent, you'll almost certainly hit the `max_token` restriction (it's also frustrating that AWS Bedrock has limitations on the actual max tokens you can invoke versus what they publish is the maximum). To solve this, some recommendations:\n",
    "    - batch the requests into multiple parts\n",
    "    - lower the KWIC context window so you are sending less tokens\n",
    "    - randomly drop some values\n",
    "    - filter out stop words to cut down on char count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4ca2f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword=\"bovine\"\n",
    "#keyword=\"dictionary\"\n",
    "#keyword=\"etienne\"\n",
    "#keyword=\"ordinary meaning\"\n",
    "#keyword=\"bank\"\n",
    "keyword=\"vehicle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b99f71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEMO] Running scotus_analysis (live search) for keyword='vehicle' focus='general'\n",
      "🔍 TOOL(search): Searching SCOTUS database for keyword: 'vehicle'\n",
      "🪄 AUTO-SHRINK: prompt 246322 > max_tokens 128000. context_words 20 -> 9 (ratio 0.520). Retrying...\n",
      "📊 TOOL(search): Found 903 cases across 231 volumes | context_words_used=9 | shrink_attempts=1\n",
      "🤖 TOOL(search): Sending 125359 characters to AI model for analysis\n",
      "✅ TOOL(search): Analysis complete, returning 2 characters\n",
      "\n",
      "[DEMO] Runtime: 37.27s | Raw result type: list\n",
      "Wrote combined analysis + reasoning to scotus_analysis_vehicle.md (length=13522 chars)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'scotus_analysis_vehicle.md'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "search_keyword = keyword  # reuse previous, or set explicitly like: search_keyword = \"dictionary\"\n",
    "analysis_focus = \"general\"  # options: general | evolution | judicial_philosophy | custom\n",
    "\n",
    "print(f\"[DEMO] Running scotus_analysis (live search) for keyword='{search_keyword}' focus='{analysis_focus}'\")\n",
    "start_time = time()\n",
    "result_text = scotus_tool._run(keyword=search_keyword, analysis_focus=analysis_focus)\n",
    "elapsed = time() - start_time\n",
    "\n",
    "print(f\"\\n[DEMO] Runtime: {elapsed:.2f}s | Raw result type: {type(result_text).__name__}\")\n",
    "export_markdown(result_text, f\"scotus_analysis_{search_keyword}\")\n",
    "# ============================================================================\n",
    "# Unified formatted output (reasoning last)\n",
    "#formatted = format_result_output(result_text)\n",
    "#print(\"\\n=== FORMATTED OUTPUT (reasoning at end) ===\\n\")\n",
    "#print(formatted[:120])  # safety slice to avoid flooding notebook; adjust if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cc781",
   "metadata": {},
   "source": [
    "### Preview Markdown Report of AI summary\n",
    "\n",
    "saved as `{keyword}.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851cce1",
   "metadata": {},
   "source": [
    "## 2nd tool: Passing pre-filtered JSON results to the filtered analysis tool\n",
    "\n",
    "- for greater control on the keyword samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9b916",
   "metadata": {},
   "source": [
    "#### New parameters for `scotus_filtered_analysis`\n",
    "- `extraction_strategy`: `first` (default) chooses first matching field among context/text/snippet/kwic/content/full_text/body; `all` concatenates all; `raw_json` embeds entire JSON (largest).\n",
    "- `debug=True` adds transparency metrics (raw/extracted char counts, token estimates, reduction ratio) to stdout and prompt.\n",
    "- Early preflight rejection triggers if the prompt's char/4 heuristic exceeds `max_tokens`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e6027102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 TOOL(filtered): Sending 303280 chars (≈75820 tok) to model (contexts: 1964) | strategy=first return_json=False\n"
     ]
    }
   ],
   "source": [
    "keyword='bank'\n",
    "loc_results = got3.search_keyword_corpus(\n",
    "    keyword=keyword,\n",
    "    db_dict=db_dict_formatted,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=12,\n",
    "    output=\"json\"\n",
    ")\n",
    "# Drop keys with empty dicts and sort by keys (as integers)\n",
    "filtered_sorted_results = {k: v for k, v in sorted(loc_results.items(), key=lambda item: int(item[0])) if v}\n",
    "filtered_json_str = json.dumps(filtered_sorted_results)\n",
    "# Plain text (narrative) mode\n",
    "filtered_result_text = filtered_scotus_tool._run(\n",
    "    keyword=keyword,\n",
    "    results_json=filtered_json_str,\n",
    "    analysis_focus='general',\n",
    "    #max_contexts=40,\n",
    "    return_json=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "35d5fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'reasoning_content', 'reasoning_content': {'text': 'We need to produce analysis of \"bank\" usage across many contexts. Provide sections. Base on snippets. Identify usage: noun meaning financial institution; also \"bank\" as riverbank; also \"bank\" as pool bank (bank of the pool); also \"bank\" as verb bank (to rely). Also \"bank\" in phrase \"bankrupt\" with hyphen? but focus \"bank\". Also \"bank\" as shelf, \"bank\" of a river, \"bank\" as \"bank (finance)\" vs other senses. Provide summary, patterns, frequency distribution (counts approximate). Provide interpretability notes and open questions.\\n\\nWe must only use contexts provided; no external knowledge. So we can infer senses from examples.\\n\\nLet\\'s craft answer.', 'signature': ''}}\n",
      "**1. Usage Summary**  \n",
      "The 1 966 citations that contain the token **bank** fall overwhelmingly into two broad semantic families:  \n",
      "\n",
      "| Sense (proto‑type) | Typical lexical environment (from the sample excerpts) | Rough share of total citations* |\n",
      "|--------------------|--------------------------------------------------------|--------------------------------|\n",
      "| **A. Financial institution** – a depository / lending entity, often preceded or followed by modifiers such as *National, Federal Reserve, First, Commercial, Savings, Trust, Credit, Mortgage, etc.* | “Continental **Bank** v. Chicago…”, “Chase National **Bank**…”, “United States v. **Bank** of New York”, “bank‑rupt ‑ cy”, “bank‑robbery”, “bank‑account”, “bank‑loan”, “bank‑secrecy Act”, “bank‑holding company”, “bank‑director”, “bank‑trust”, “bank‑fees”, “bank‑records”, “bank‑deposit”, “bank‑interest”, “bank‑loan”, “bank‑securities”, “bank‑regulation”, “bank‑note”, “bank‑check”, “bank‑statement”, “bank‑paper”, “bank‑depositors”, “bank‑credit”, “bank‑shares”, “bank‑savings”, “bank‑business” | ≈ 80 % |\n",
      "| **B. Geographic feature** – the side or shore of a river, lake, or other watercourse; also “bank of a river”, “west bank of the Mississippi”, “east bank of the river”, “bank of the river”, “bank of a tributary”, “bank‑full” | “the bank of the river”, “west **bank** of the Mississippi”, “river’s **bank**”, “the bank of a lake”, “river‑bank”, “low‑tide **bank**”, “bank of the canal”, “bank of the West”, “bank of the river‑bed”, “the **bank** of a reservoir”, “the bank of the river‑basin”, “the bank of the dike” | ≈ 8 % |\n",
      "| **C. Specific institutional contexts not strictly financial** – e.g., *World Bank*, *Bank of England* (central‑bank‑type institutions), *Bank of the United Nations*, *Bank of the United States* (historical government‑owned bank), *Bank of the Army* (data‑bank) | “World **Bank**”, “Bank of England”, “Bank of the United States v. …”, “Bank of the Army data‑bank”, “Bank of the United Nations” | ≈ 6 % |\n",
      "| **D. Metaphorical / figurative uses** – “bank on” (rely), “bank‑rupt” (derived from “bank”), “bank‑full” (hydrological), “bank of ideas”, “bank of evidence”, “bank of the river” used poetically, “bank‑rupt ‑ cy” as procedural term, “bank‑roll” (slang for money) | “I will go to the **bank**”, “It would be a **bank**‑ruptcy”, “the **bank**‑full of the river”, “We must **bank** on the testimony”, “a **bank** of data” | ≈ 6 % |\n",
      "\n",
      "\\*These percentages are approximate, derived by scanning the 1 966 excerpt lines and noting the dominant lexical cues (e.g., “bank‑account”, “bank‑loan”, “bank‑rupt”, “river **bank**”, “World **Bank**”). Exact counts are not supplied in the dataset, but the visual inspection shows a clear majority of financial‑institution citations.\n",
      "\n",
      "---\n",
      "\n",
      "**2. Contextual Patterns / Proto‑senses**\n",
      "\n",
      "| Proto‑sense | Core lexical pattern(s) | Representative excerpts |\n",
      "|-------------|------------------------|--------------------------|\n",
      "| **Financial‑institution noun** | *[Adjective] **Bank*** (National, First, Federal Reserve, Savings, Trust, Commercial, etc.) <br> *bank‑* compounds (bank‑account, bank‑loan, bank‑secrecy, bank‑ruptcy, bank‑robbery, bank‑fees, bank‑records) <br> Verbal context “deposited in a **bank**”, “paid to the **bank**”, “checked by the **bank**” | “[329:3] … *Continental **Bank*** v. Chicago …”, “[331:19] … *Chase National **Bank*** …”, “[340:30] … *First Union Trust & Savings **Bank*** …”, “[354:17] … *bank robbery*”, “[365:12] … *deposit in a **bank** account*”, “[410:2] … *Federal **Bank** Robbery Act*” |\n",
      "| **River‑bank (geographic)** | *bank of the …* (river, canal, lake, tributary) <br> *west/east **bank***, *low‑tide **bank***, *bank‑full* | “[397:1] … *west **bank** of the Mississippi River*”, “[405:4] … *bank of the canal*”, “[497:13] … *low‑tide **bank***”, “[511:12] … *bank of the river*”, “[509:27] … *bank of the West*” |\n",
      "| **International/central bank** | *World **Bank***, *Bank of England*, *Bank of the United States*, *Bank of the United Nations* | “[429:30] … *World **Bank***”, “[414:43] … *Bank of England*”, “[421:0] … *Bank of the United States*” |\n",
      "| **Metaphorical / derived verb** | *bank on* (rely), *bank‑rupt* (legal status), *bank‑full* (hydrology), *bank of (data/evidence)*, *bank‑roll* (money) | “[365:30] … *“We’ll go to the **bank**,”* (colloquial), “[336:6] … *bank‑ruptcy court*”, “[378:1] … *bank‑full of the river*”, “[538:6] … *data **bank***”, “[549:30] … *bank‑roll*” |\n",
      "\n",
      "*Note:* The “bank‑rupt” form appears both as a suffix in *bank‑ruptcy* (legal‑process sense) and as part of the phrase “bank‑rupt ‑ cy” in the dataset. The hyphenated spelling indicates a derived noun rather than the financial institution.\n",
      "\n",
      "---\n",
      "\n",
      "**3. Frequency & Distribution Observations**\n",
      "\n",
      "| Observation | Evidence from the excerpts |\n",
      "|--------------|----------------------------|\n",
      "| **Dominance of the financial‑institution sense** – Nearly every citation mentions a proper‑name (*First National **Bank***, *Chase National **Bank***, *Federal Reserve **Bank***), a transaction (*deposit*, *loan*, *check*), or a statutory reference (*Bankruptcy Act*, *Bank Secrecy Act*). | Hundreds of lines with “*Bank* v.” or “*bank*‑account”, e.g., “[329:6]”, “[331:7]”, “[340:22]”, “[354:17]”, “[400:6]”, “[440:1]”. |\n",
      "| **River‑bank sense is a clear minority** – The phrase “*bank of the …*” occurs far less often, typically in geographic or environmental contexts (river navigation, land‑use, flood control). | Examples: “[397:1] … *west **bank** of the Mississippi*”, “[410:20] … *bank of the river*”, “[509:27] … *bank of the West*”. |\n",
      "| **Institutional “Bank of …”** (World, England, United States) clusters in mid‑century to modern‑day citations dealing with sovereign or multilateral finance, but still far fewer than commercial‑bank citations. | “[429:30] … *World **Bank***”, “[414:43] … *Bank of England*”, “[421:0] … *Bank of the United States*”. |\n",
      "| **Metaphorical/derived uses** – Appear mainly in criminal‑law contexts (*bank robbery*), procedural contexts (*bank‑ruptcy*), or idiomatic speech (“go to the **bank**”). Their frequency is low relative to the core financial sense. | “[354:17] *bank robbery*”, “[336:6] *bank‑rupt‑cy*”, “[365:30] *go to the **bank***”. |\n",
      "| **Hyphenated forms** (*bank‑rupt*, *bank‑full*, *bank‑secrecy*) are used consistently when “bank” functions as a lexical stem attached to a suffix, indicating a derived concept rather than the noun itself. | “[336:9] *bank‑rupt‑cy*”, “[378:1] *bank‑full*”, “[341:35] *Bank‑rupt* Act”. |\n",
      "| **Case‑law citations** – The token appears most often within the formal citation format “*X v. Y*” where *X* or *Y* is a bank, confirming the predominance of the institution sense in appellate and Supreme Court jurisprudence. | “[329:3] … *Continental **Bank*** v. Chicago”, “[331:21] … *Central **Bank*** v. United States”, “[354:17] … *Bank‑rupt*”. |\n",
      "\n",
      "---\n",
      "\n",
      "**4. Interpretability Notes (ordinary‑meaning indicators)**  \n",
      "\n",
      "* **Capitalisation** – “**Bank**” almost always appears capitalised when it is part of a proper name (e.g., *First National **Bank***). This signals the financial‑institution sense. Lower‑case “bank” (e.g., “the **bank** of the river”) signals the geographic sense.  \n",
      "* **Morphological markers** – The presence of a suffix (*‑ruptcy*, *‑robbery*, *‑full*, *‑secrecy*) or a preceding adjective (*National*, *Federal*, *World*) disambiguates meaning without needing extra context.  \n",
      "* **Co‑occurring legal terminology** – Words like *chapter*, *petition*, *trust*, *liability*, *credit*, *deposit* strongly cue the financial sense. Words like *river*, *tributary*, *low‑tide*, *flood* cue the geographic sense.  \n",
      "* **Verb constructions** – “*to **bank** on*” (reliance) shows a verb sense distinct from the noun; the dataset contains very few such occurrences, so it is a peripheral sense.  \n",
      "* **Domain markers** – References to statutes (e.g., *Bankruptcy Act*, *Bank Secrecy Act*), agencies (e.g., *Federal Reserve Board*), or procedural terms (*bank‑ruptcy court*) imply a specialized legal‑financial sense.  \n",
      "\n",
      "Overall, the orthographic and lexical context provides a reliable cue to the intended sense in > 95 % of the citations.\n",
      "\n",
      "---\n",
      "\n",
      "**5. Open Questions / Ambiguities**\n",
      "\n",
      "| Issue | Why it is ambiguous from the supplied data |\n",
      "|-------|-------------------------------------------|\n",
      "| **Bank vs. river‑bank overlap** – Some citations contain “*bank*” with a capital B but no obvious modifier (e.g., “*the bank* of the river” vs. “*the Bank* of the United States”). Without the full sentence it can be hard to tell whether the author is using a proper name or a generic geographic term. | The excerpts are often fragmentary (single‑sentence snippets) and do not always include the surrounding context that would clarify whether “Bank” is a title or a common noun. |\n",
      "| **Metonymic uses** – Phrases like “*the Bank* decided” could refer to a specific financial institution, a central bank, or even the banking sector as a whole. The dataset mixes citations from different jurisdictions, making it unclear whether “the Bank” is a shorthand for a particular entity. | No explicit antecedent is provided in many excerpts (e.g., “[382:41] … *the Bank of the United States* v. Deveaux” vs. “[382:0] … *the Bank* is an ...”); the token alone does not reveal the referent. |\n",
      "| **Hyphenated compound ambiguity** – “*bank‑full*” could be interpreted either as a hydrological term (river condition) or figuratively (e.g., “bank‑full of evidence”). The dataset contains both literal and figurative uses, but the snippets do not always make the distinction obvious. | The snippet “[378:1] … *bank‑full*” does not show surrounding adjectives or nouns that would confirm the domain (hydrology vs. metaphor). |\n",
      "| **International vs. domestic institution** – “*World Bank*” and “*Bank of England*” are sovereign or multilateral entities, but the dataset sometimes truncates the name (e.g., “*Bank* of the United Nations”) leaving it uncertain whether the reference is to a central bank, a development bank, or a different body. | The excerpt “[414:27] … *Bank of England*” is clear, but other lines like “[421:0] … *Bank of the United States*” could be historic, and the context (time period, jurisdiction) is missing. |\n",
      "| **Verb “to bank”** – The dataset includes a handful of idiomatic uses (“*go to the bank*”, “*bank on*”), but it is not possible to ascertain how widespread this verbal sense is relative to the noun senses. | No frequency count is provided for the verb sense, and the examples are sparse, making it difficult to gauge its significance. |\n",
      "\n",
      "These ambiguities could be resolved with a larger window of surrounding text or with metadata such as the case’s jurisdiction, date, and subject‑matter tag. Nevertheless, the bulk of the evidence points to a highly predictable pattern: capitalised, proper‑name forms denote financial institutions; uncapitalised “bank of …” denotes a river bank; hyphenated compounds signal derived legal or technical concepts.\n",
      "Wrote combined analysis + reasoning to scotus_filtered_analysis_bank_text.md (length=11741 chars)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'scotus_filtered_analysis_bank_text.md'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(filtered_result_text)\n",
    "export_markdown(filtered_result_text, f\"scotus_filtered_analysis_{keyword}_text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc19b4e",
   "metadata": {},
   "source": [
    "______________________\n",
    "\n",
    "## Conclusion 🐄 🐍 🧑‍⚖️\n",
    "\n",
    "### AWS Bedrock + LangChain + `got3` + SCOTUS Corpus Analysis\n",
    "\n",
    "This demo illustrated how to build custom AI‑powered analysis tools over a specialized legal text corpus using LangChain and AWS Bedrock. By combining dynamic keyword search with focused AI synthesis, we can rapidly explore judicial reasoning patterns in Supreme Court opinions.\n",
    "\n",
    "### AWS Cost Explorer -- Monitoring Bedrock Costs\n",
    "\n",
    "Useful `jq` filters for your AWS Cost Explorer output:\n",
    "\n",
    "> notably costs won't show up immediately, so you may need to wait a day or two after incurring costs to see them reflected in Cost Explorer.\n",
    "\n",
    "```bash\n",
    "# Filter for Bedrock services specifically from all services with costs\n",
    "named_profile=atn-developer\n",
    "region=us-east-1\n",
    "start_date=$(date +%Y-%m-01)\n",
    "end_date=$(date +%Y-%m-%d)\n",
    "\n",
    "aws ce get-cost-and-usage --time-period Start=$start_date,End=$end_date --granularity DAILY --metrics \"BlendedCost\" --group-by Type=DIMENSION,Key=SERVICE --region $region --profile=$named_profile | jq '.ResultsByTime[].Groups[] | select(.Keys[0] | test(\"Bedrock\"; \"i\")) | {service: .Keys[0], cost: .Metrics.BlendedCost.Amount}'\n",
    "```\n",
    "\n",
    "#### Cost of AWS Bedrock\n",
    "\n",
    "- on 10/01/2025 this was: `\"cost\": \"0.03760425\"` -- check tomorrow to see the costs from my testing runs today.\n",
    "- okay various runs cost just about $0.10 `  \"cost\": \"0.10061025\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b7d6c9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.10061025\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.04100085\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.0412656\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.21341396\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Filter for Bedrock services specifically from all services with costs\n",
    "!aws ce get-cost-and-usage --time-period Start=2025-09-30,End=2025-10-05 --granularity DAILY --metrics \"BlendedCost\" --group-by Type=DIMENSION,Key=SERVICE --region us-east-1 --profile=atn-developer | jq '.ResultsByTime[].Groups[] | select(.Keys[0] | test(\"Bedrock\"; \"i\")) | {service: .Keys[0], cost: .Metrics.BlendedCost.Amount}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcde40",
   "metadata": {},
   "source": [
    "## SCOTUS Analysis Tools (LangChain + `getout_of_text_3`)\n",
    "\n",
    "This section documents two complementary LangChain Tool implementations for exploratory forensic / statutory‐interpretation analysis over a locally prepared SCOTUS corpus.\n",
    "\n",
    "### 1. Purpose\n",
    "You can (a) execute an on‑the‑fly keyword search + AI analysis, or (b) feed in *already filtered* JSON results for reproducible, cost‑controlled, deterministic re‑analysis with AI tools. This is for exploratory and demonstrative purposes only; do **NOT** rely on these tools for authoritative legal research or advice.\n",
    "\n",
    "### 2. Tool Inventory\n",
    "| Tool Name | Class | Performs Corpus Search? | Input Content Source | Best For | Cost / Token Control | Notes |\n",
    "|-----------|-------|-------------------------|----------------------|----------|----------------------|-------|\n",
    "| `scotus_analysis` | `ScotusAnalysisTool` | YES (internal `got3.search_keyword_corpus`) | Raw SCOTUS corpus dict (`db_dict_formatted`) | Quick ad‑hoc exploration, first look | Lower control (dynamic result size) | Returns free‑form model text. Not suited for strict reproducibility. |\n",
    "| `scotus_filtered_analysis` | `ScotusFilteredAnalysisTool` | NO (analysis only) | Pre‑filtered JSON (already produced elsewhere) | Stable reports, batching, auditing, caching | High control (you decide slice + cap contexts) | Optional structured JSON output (`return_json=True`). |\n",
    "\n",
    "### 3. Input Schemas (Pydantic)\n",
    "1. `ScotusAnalysisInput`:\n",
    "   - `keyword: str` – term/phrase to search.\n",
    "   - `analysis_focus: str = 'general'` – one of: `general`, `evolution`, `judicial_philosophy`, `custom`.\n",
    "2. `ScotusFilteredAnalysisInput`:\n",
    "   - `keyword: str` – label only (no searching performed).\n",
    "   - `results_json: str | dict` – JSON/dict from a *previous* `got3.search_keyword_corpus` call (after any manual filtering).\n",
    "   - `analysis_focus: str = 'general'` – same options as above.\n",
    "   - `max_contexts: int | None = None` – OPTIONAL cap; if None, 0, or <1 then ALL contexts are included (assumes you pre-trimmed).\n",
    "   - `return_json: bool = False` – if `True` the prompt instructs the model to emit **strict JSON** (post‑validated / auto‑repaired if malformed).\n",
    "\n",
    "### 4. Typical Workflow Patterns\n",
    "| Scenario | Recommended Flow |\n",
    "|----------|------------------|\n",
    "| Rapid hypothesis check | Use `scotus_analysis` with a single keyword, review summary. |\n",
    "| Iterative refinement / human curation | Run raw search once, manually prune / cluster results, then pass curated JSON to `scotus_filtered_analysis`. |\n",
    "| Batch reporting (multiple keywords) | Precompute & persist each keyword’s JSON → loop over `scotus_filtered_analysis` with `return_json=True`. |\n",
    "| Cost‑sensitive environment | Always pre‑filter & throttle with `max_contexts` (e.g. 40–80). |\n",
    "| Need structured downstream ingestion | Use `return_json=True` and parse validated keys (`reasoning_content`, `summary`, etc.). |\n",
    "\n",
    "### 5. Prompt Design Overview\n",
    "Both tools:\n",
    "- Enforce an “ONLY use supplied contexts” constraint (mitigates hallucination beyond current slice).\n",
    "- Provide distribution metadata (volumes, counts, occurrence sample) to steer higher‑level synthesis.\n",
    "- Offer `analysis_focus` to narrow stylistic / topical emphasis.\n",
    "\n",
    "`scotus_analysis` additionally:\n",
    "- Embeds a truncated JSON of search hits (first N characters) directly after retrieval.\n",
    "\n",
    "`scotus_filtered_analysis` adds:\n",
    "- Multi‑shape normalization for result structures: strings, lists, objects with `context`/`text` fields.\n",
    "- Optional context sampling cap (set `max_contexts` > 0). If no cap is provided ALL contexts (full length) are included — no 240‑char clipping.\n",
    "- Optional strict JSON response contract.\n",
    "\n",
    "### 6. Output Shapes\n",
    "| Mode | Example (abridged) |\n",
    "|------|--------------------|\n",
    "| `scotus_analysis` (text) | \"Usage Summary... Contextual Patterns...\" |\n",
    "| `scotus_filtered_analysis` (`return_json=False`) | Same narrative section headings as above. |\n",
    "| `scotus_filtered_analysis` (`return_json=True`) | `{ \"keyword\": \"ordinary meaning\", \"total_contexts\": 217, \"occurrences_summary\": \"217 snippet(s)...\", \"reasoning_content\": [\"...\"], \"summary\": \"...\", \"limitations\": \"...\" }` |\n",
    "\n",
    "### 7. Reliability & Error Handling\n",
    "- Async safety: attempts event‑loop reuse; falls back to sync if needed.\n",
    "- JSON robustness: if model returns malformed JSON, a salvage regex pass wraps content into a valid fallback structure.\n",
    "- Single‑occurrence safeguard: explicitly flags low‑evidence situations (e.g., only 1 context) to prevent over‑extrapolation.\n",
    "\n",
    "### 8. Performance & Cost Notes\n",
    "| Driver | Effect | Mitigation |\n",
    "|--------|--------|------------|\n",
    "| Large keyword result sets | Longer prompt → higher tokens | Pre‑filter & lower `max_contexts` |\n",
    "| Very common terms (e.g., \"the\", functional words) | Noise / inflated contexts | Encourage user to refine / phrase search |\n",
    "| High `max_contexts` + JSON mode | Larger instructions + response | Tune to 30–80; rarely need >100 contexts |\n",
    "| Duplicate or near‑duplicate contexts | Redundant token usage | Consider de‑dupe preprocessing before passing JSON |\n",
    "\n",
    "### 9. When NOT to Use These Tools\n",
    "- You need full‑text semantic retrieval (vector / embedding) across the corpus → integrate an embedding + retriever pipeline instead.\n",
    "- You require authoritative legal interpretation beyond provided snippets → domain attorney review required.\n",
    "- You want cross‑corpus comparative linguistics (e.g., COCA vs SCOTUS) in one call → design a composite prompt / multi‑tool pipeline.\n",
    "\n",
    "### 10. Minimal Usage Examples\n",
    "Live search (exploratory):\n",
    "```python\n",
    "result_text = scotus_tool._run(keyword=\"textualism\", analysis_focus=\"judicial_philosophy\")\n",
    "print(result_text[:800])\n",
    "```\n",
    "Pre‑filtered (deterministic):\n",
    "```python\n",
    "raw_results = got3.search_keyword_corpus(\n",
    "    keyword=\"ordinary meaning\",\n",
    "    db_dict=db_dict_formatted,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=30,\n",
    "    output=\"json\"\n",
    ")\n",
    "filtered = {k: v for k, v in raw_results.items() if v}  # prune empties\n",
    "json_str = json.dumps(filtered)\n",
    "analysis = filtered_scotus_tool._run(\n",
    "    keyword=\"ordinary meaning\",\n",
    "    results_json=json_str,\n",
    "    analysis_focus=\"general\",\n",
    "    max_contexts=50,\n",
    "    return_json=True\n",
    ")\n",
    "analysis[\"summary\"][:500]\n",
    "```\n",
    "\n",
    "### 11. Interpreting Structured JSON (Key Semantics)\n",
    "| Key | Meaning | Typical Consumer Action |\n",
    "|-----|---------|-------------------------|\n",
    "| `keyword` | Echo label for downstream grouping | Index in dataframe / vector store |\n",
    "| `total_contexts` | Sampled context count (post‑cap) | Assess evidence density |\n",
    "| `occurrences_summary` | Human‑readable distribution summary | Display directly in UI |\n",
    "| `reasoning_content` | Stepwise internal analysis (chain‑of‑thought lite) | Optional trust / audit pane |\n",
    "| `summary` | Main synthesized narrative | Persist / compare across keywords |\n",
    "| `limitations` | Self‑reported caveats (and JSON salvage note if any) | Flag for review / quality scoring |\n",
    "\n",
    "### 12. Extension Ideas (Future Work)\n",
    "- Add semantic clustering (MiniLM embeddings) before sampling to maximize diversity.\n",
    "- Integrate rate limiting & token accounting dashboards.\n",
    "- Provide a deterministic hash of the input JSON slice for reproducibility tracking.\n",
    "- Optional KWIC alignment / colorized keyword highlighting inside samples.\n",
    "\n",
    "### 13. Quick Decision Guide\n",
    "> If you can already see and trust the filtered JSON you want analyzed, **use `scotus_filtered_analysis`**. Otherwise, start with `scotus_analysis` to discover whether the keyword is even worth a curated run.\n",
    "\n",
    "---\n",
    "**Reminder:** Both tools operate strictly over *your supplied corpus slice*. They intentionally do **NOT** fetch external case law or enrich with outside doctrinal knowledge. This keeps analyses auditable and grounded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac1d47",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
