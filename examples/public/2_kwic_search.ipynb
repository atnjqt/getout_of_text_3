{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d0b18d",
   "metadata": {},
   "source": [
    "## 2. Perform KWIC Searches using `getout_of_text_3` on COCA, GloWbE, and EcoLexicon\n",
    "\n",
    "- Author: [Etienne P Jacquot](mailto:etienne.jacquot@asc.upenn.edu) (11/14/2025)\n",
    "\n",
    "### Corpora\n",
    "\n",
    "Both COCA and GloWbE now use **consistent nested structure**:\n",
    "\n",
    "- **`corpus_name='coca'`** (default): `{genre: {year_or_id: DataFrame}}`\n",
    "  - Example: `coca['acad']['2009']` â†’ DataFrame\n",
    "  \n",
    "- **`corpus_name='glowbe'`**: `{country_code: {file_id: DataFrame}}`\n",
    "  - Example: `glowbe['us']['g19']` â†’ DataFrame\n",
    "  \n",
    "- **`corpus_name='EcoLexicon'`**: \n",
    "  - Manual CSV downloads from Sketch-Engine EcoLexicon\n",
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c523f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U getout_of_text_3 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa46aa",
   "metadata": {},
   "source": [
    "## Run Imports\n",
    "\n",
    "To use the latest code changes (including reading COCA & GloWbE offline licensed files from English-Corpora.org), import the module after installation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852821a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getout_of_text_3 as got3\n",
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "print(\"getout_of_text_3 version:\",  got3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bf797",
   "metadata": {},
   "source": [
    "## Read Local Corpus Data into Notebook\n",
    "\n",
    "- the `corpus_name` parameter specifies which corpus format to use (`'coca'` or `'glowbe'`), as each have different directory structures and file naming conventions.\n",
    "\n",
    "    > Note: The module will automatically fall back to the COCA formatting if an unrecognized corpus name is provided. If you are using a English-Corpora.org corpus that is not supported (i.e. have a different structure) please create an issue on GitHub bringing this to the attention of the maintainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory of your local English-Corpora.org offline files\n",
    "data_directory = '../../data/english-corpora.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCA corpus\n",
    "coca_corpus = got3.read_corpus(dir_of_text_files='{}/coca/'.format(data_directory), \n",
    "                               corpus_name='coca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d08855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloWbE corpus\n",
    "glowbe_corpus = got3.read_corpus(dir_of_text_files='{}/glowbe/'.format(data_directory), \n",
    "                                 corpus_name='glowbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee355ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually download CSVs from Sketch Engine and load into a format compatible with getout_of_text_3\n",
    "ecolexicon_corpus = {}\n",
    "\n",
    "for csv_file in [file for file in os.listdir('../../data/sketch-engine/') if file.endswith('.csv')]:\n",
    "    \n",
    "    # read your Sketch-Engine exported CSV file, skipping the first 4 rows of metadata\n",
    "    df = pd.read_csv('../../data/sketch-engine/{}'.format(csv_file), skiprows=4)\n",
    "\n",
    "    # add a 'text' column combining Left, KWIC, and Right context (i.e. the original concordance lines)\n",
    "    df['text']= df['Left']+' '+df['KWIC']+' '+df['Right']\n",
    "\n",
    "    # store the dataframe in the ecolexicon_corpus dictionary, using a placeholder genre value 'eco_text's\n",
    "    ecolexicon_corpus[csv_file] = {'eco_text': df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e3040",
   "metadata": {},
   "source": [
    "___________________\n",
    "## Perform Word Count Totals for Each Corpus\n",
    "\n",
    "This step is to verify that the corpora have been read in correctly by checking total word counts against known values from English-Corpora.org documentation.\n",
    "\n",
    "- **COCA**: 1.1 billion words\n",
    "- **GloWbE**: 1.9 billion words\n",
    "- **EcoLexicon**: 23.1 million words (*ignoring given we do not have the full database locally*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total word count across all COCA genres and subkeys\n",
    "def count_words_in_text(text):\n",
    "    \"\"\"Count words in a text string.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "#\n",
    "def calculate_total_word_count(corpus):\n",
    "    total_word_count = 0\n",
    "    start_time=pd.Timestamp.now()\n",
    "    for genre, subkeys in corpus.items():\n",
    "        for subkey, dataframe in subkeys.items():\n",
    "            if isinstance(dataframe, pd.DataFrame) and 'text' in dataframe.columns:\n",
    "                # Count words in all text entries for this subkey\n",
    "                subkey_word_count = dataframe['text'].apply(count_words_in_text).sum()\n",
    "                total_word_count += subkey_word_count\n",
    "\n",
    "    end_time=pd.Timestamp.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"â±ï¸ Elapsed time: {elapsed_time}\")\n",
    "    print(f\"ðŸŽ¯ TOTAL GLOWBE CORPUS: {total_word_count:,} words\")\n",
    "    return total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_word_count = calculate_total_word_count(coca_corpus)\n",
    "glowbe_word_count = calculate_total_word_count(glowbe_corpus)\n",
    "ecolexicon_word_count = 23100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0f4e1",
   "metadata": {},
   "source": [
    "_____________________\n",
    "## Running Query Searches Across English-Corpora `COCA`\n",
    "\n",
    "- **Corpus of Contemporary American English (COCA)**\n",
    "    - See the public corpus here: https://www.english-corpora.org/coca\n",
    "    - Run for the terms:\n",
    "        - `best system`\n",
    "        - `best method`\n",
    "        - `national system`\n",
    "        - `industry standard`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='best system'\n",
    "corpus_name='coca'\n",
    "best_system_kwic_coca = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=coca_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "# drop empty results\n",
    "best_system_kwic_coca = {k: v for k, v in best_system_kwic_coca.items() if v}\n",
    "# get total count\n",
    "best_system_total_kwic_coca = sum(len(v) for v in best_system_kwic_coca.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012df0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='best method'\n",
    "corpus_name='coca'\n",
    "best_method_kwic_coca = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=coca_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "best_method_kwic_coca = {k: v for k, v in best_method_kwic_coca.items() if v}\n",
    "best_method_total_kwic_coca = sum(len(v) for v in best_method_kwic_coca.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='national system'\n",
    "corpus_name='coca'\n",
    "national_system_kwic_coca = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=coca_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "national_system_kwic_coca = {k: v for k, v in national_system_kwic_coca.items() if v}\n",
    "national_system_total_kwic_coca = sum(len(v) for v in national_system_kwic_coca.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='industry standard'\n",
    "corpus_name='coca'\n",
    "industry_standard_kwic_coca = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=coca_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "industry_standard_kwic_coca = {k: v for k, v in industry_standard_kwic_coca.items() if v}\n",
    "industry_standard_total_kwic_coca = sum(len(v) for v in industry_standard_kwic_coca.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c3f72",
   "metadata": {},
   "source": [
    "_____________________\n",
    "## Running Query Searches Across English-Corpora `GloWbE`\n",
    "\n",
    "- **Corpus of Global Web-Based English (GloWbE)**\n",
    "    - See the public corpus here: https://www.english-corpora.org/glowbe\n",
    "    - Run for the terms:\n",
    "        - `best system`\n",
    "        - `best method`\n",
    "        - `national system`\n",
    "        - `industry standard`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='best system'\n",
    "corpus_name='glowbe'\n",
    "best_system_kwic_glowbe = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=glowbe_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "best_system_kwic_glowbe = {k: v for k, v in best_system_kwic_glowbe.items() if v}\n",
    "best_system_total_kwic_glowbe = sum(len(v) for v in best_system_kwic_glowbe.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='best method'\n",
    "corpus_name='glowbe'\n",
    "best_method_kwic_glowbe = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=glowbe_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "best_method_kwic_glowbe = {k: v for k, v in best_method_kwic_glowbe.items() if v}\n",
    "best_method_total_kwic_glowbe = sum(len(v) for v in best_method_kwic_glowbe.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd54701",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='national system'\n",
    "corpus_name='glowbe'\n",
    "national_system_kwic_glowbe = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=glowbe_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "national_system_kwic_glowbe = {k: v for k, v in national_system_kwic_glowbe.items() if v}\n",
    "national_system_total_kwic_glowbe = sum(len(v) for v in national_system_kwic_glowbe.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='industry standard'\n",
    "corpus_name='glowbe'\n",
    "industry_standard_kwic_glowbe = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=glowbe_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "industry_standard_kwic_glowbe = {k: v for k, v in industry_standard_kwic_glowbe.items() if v}\n",
    "industry_standard_total_kwic_glowbe = sum(len(v) for v in industry_standard_kwic_glowbe.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08b4de",
   "metadata": {},
   "source": [
    "_____________________\n",
    "## Running Query Searches Across Sketch Engine `EcoLexicon-Corpus`\n",
    "\n",
    "- See the public corpus here: https://www.sketchengine.eu/ecolexicon-corpus/\n",
    "- Manually downloaded from Sketch Engine web interface as CSV files for the `EcoLexicon` corpus for the terms:\n",
    "  - `best system`\n",
    "  - `best method`\n",
    "  - `national system`\n",
    "  - `industry standard`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='best system'\n",
    "corpus_name='ecolexicon'\n",
    "best_system_kwic_ecolexicon = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=ecolexicon_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "best_system_kwic_ecolexicon = {k: v for k, v in best_system_kwic_ecolexicon.items() if v}\n",
    "best_system_total_kwic_ecolexicon = sum(len(v) for v in best_system_kwic_ecolexicon.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='best method'\n",
    "corpus_name='ecolexicon'\n",
    "best_method_kwic_ecolexicon = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=ecolexicon_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "best_method_kwic_ecolexicon = {k: v for k, v in best_method_kwic_ecolexicon.items() if v}\n",
    "best_method_total_kwic_ecolexicon = sum(len(v) for v in best_method_kwic_ecolexicon.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='national system'\n",
    "corpus_name='ecolexicon'\n",
    "national_system_kwic_ecolexicon = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=ecolexicon_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "national_system_kwic_ecolexicon = {k: v for k, v in national_system_kwic_ecolexicon.items() if v}\n",
    "national_system_total_kwic_ecolexicon = sum(len(v) for v in national_system_kwic_ecolexicon.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677046a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='industry standard'\n",
    "corpus_name='ecolexicon'\n",
    "industry_standard_kwic_ecolexicon = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=ecolexicon_corpus,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output='print',\n",
    "                parallel=True,\n",
    "                n_jobs=None\n",
    ")\n",
    "industry_standard_kwic_ecolexicon = {k: v for k, v in industry_standard_kwic_ecolexicon.items() if v}\n",
    "industry_standard_total_kwic_ecolexicon = sum(len(v) for v in industry_standard_kwic_ecolexicon.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de403583",
   "metadata": {},
   "source": [
    "## Create Metadata DataFrame\n",
    "\n",
    "Compile comprehensive statistics for KWIC results including:\n",
    "- **Corpus**: Name of the corpus (COCA/GloWbE)\n",
    "- **Total Genres**: Number of genres/categories in corpus\n",
    "- **Total Word Count**: Total words in entire corpus\n",
    "- **KWIC Genres**: Genres with keyword hits\n",
    "- **KWIC Hits**: Total number of keyword occurrences\n",
    "- **Hits per Million**: Normalized frequency (hits per 1M words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kwic_metadata(corpus_name, keyword_name, corpus_dict, kwic_results, total_word_count):\n",
    "    \"\"\"\n",
    "    Create metadata row for KWIC search results.\n",
    "    \n",
    "    Args:\n",
    "        corpus_name: Name of corpus (e.g., 'COCA', 'GloWbE')\n",
    "        corpus_dict: Full corpus dictionary\n",
    "        kwic_results: KWIC search results dictionary\n",
    "        total_word_count: Total words in corpus\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with metadata statistics\n",
    "    \"\"\"\n",
    "    # Count total genres in corpus\n",
    "    total_genres = len(corpus_dict.keys())\n",
    "    \n",
    "    # Count genres with KWIC hits\n",
    "    kwic_genres = len(kwic_results.keys())\n",
    "    \n",
    "    # Count total KWIC hits\n",
    "    total_kwic_hits = sum(len(v) for v in kwic_results.values())\n",
    "    \n",
    "    # Calculate hits per million words\n",
    "    hits_per_million = (total_kwic_hits / total_word_count) * 1_000_000 if total_word_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Corpus': corpus_name,\n",
    "        'Keyword': keyword_name,\n",
    "        'Total Genres': total_genres,\n",
    "        'Total Word Count': total_word_count,\n",
    "        'KWIC Genres': kwic_genres,\n",
    "        'KWIC Hits': total_kwic_hits,\n",
    "        'Hits per Million': round(hits_per_million, 2)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef198450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata rows for both corpora\n",
    "metadata_rows = []\n",
    "\n",
    "######################################################\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='COCA',\n",
    "    keyword_name='best system',\n",
    "    corpus_dict=coca_corpus,\n",
    "    kwic_results=best_system_kwic_coca,\n",
    "    total_word_count=coca_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='GloWbE',\n",
    "    keyword_name='best system',\n",
    "    corpus_dict=glowbe_corpus,\n",
    "    kwic_results=best_system_kwic_glowbe,\n",
    "    total_word_count=glowbe_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='EcoLexicon',\n",
    "    keyword_name='best system',\n",
    "    corpus_dict=ecolexicon_corpus,\n",
    "    kwic_results=best_system_kwic_ecolexicon,\n",
    "    total_word_count=2310000\n",
    "))\n",
    "\n",
    "######################################################\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='COCA',\n",
    "    keyword_name='best method',\n",
    "    corpus_dict=coca_corpus,\n",
    "    kwic_results=best_method_kwic_coca,\n",
    "    total_word_count=coca_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='GloWbE',\n",
    "    keyword_name='best method',\n",
    "    corpus_dict=glowbe_corpus,\n",
    "    kwic_results=best_method_kwic_glowbe,\n",
    "    total_word_count=glowbe_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='EcoLexicon',\n",
    "    keyword_name='best method',\n",
    "    corpus_dict=ecolexicon_corpus,\n",
    "    kwic_results=best_method_kwic_ecolexicon,\n",
    "    total_word_count=2310000\n",
    "))\n",
    "\n",
    "######################################################\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='COCA',\n",
    "    keyword_name='national system',\n",
    "    corpus_dict=coca_corpus,\n",
    "    kwic_results=national_system_kwic_coca,\n",
    "    total_word_count=coca_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='GloWbE',\n",
    "    keyword_name='national system',\n",
    "    corpus_dict=glowbe_corpus,\n",
    "    kwic_results=national_system_kwic_glowbe,\n",
    "    total_word_count=glowbe_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='EcoLexicon',\n",
    "    keyword_name='national system',\n",
    "    corpus_dict=ecolexicon_corpus,\n",
    "    kwic_results=national_system_kwic_ecolexicon,\n",
    "    total_word_count=2310000\n",
    "))\n",
    "\n",
    "######################################################\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='COCA',\n",
    "    keyword_name='industry standard',\n",
    "    corpus_dict=coca_corpus,\n",
    "    kwic_results=industry_standard_kwic_coca,\n",
    "    total_word_count=coca_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='GloWbE',\n",
    "    keyword_name='industry standard',\n",
    "    corpus_dict=glowbe_corpus,\n",
    "    kwic_results=industry_standard_kwic_glowbe,\n",
    "    total_word_count=glowbe_word_count\n",
    "))\n",
    "\n",
    "metadata_rows.append(create_kwic_metadata(\n",
    "    corpus_name='EcoLexicon',\n",
    "    keyword_name='industry standard',\n",
    "    corpus_dict=ecolexicon_corpus,\n",
    "    kwic_results=industry_standard_kwic_ecolexicon,\n",
    "    total_word_count=2310000\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6456f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata_df = pd.DataFrame(metadata_rows)\n",
    "metadata_df.sort_values(by=['Corpus', 'Keyword'], inplace=True)\n",
    "print(f\"ðŸ“Š Updated Metadata DataFrame created with {len(metadata_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['Total Word Count'] = metadata_df['Total Word Count'].astype(int)\n",
    "metadata_df.style.format({\n",
    "    'Total Word Count': '{:,}',\n",
    "    'KWIC Hits': '{:,}',\n",
    "    'Hits per Million': '{:.2f}'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad414a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_temp = metadata_df[['Corpus', 'Keyword', 'Total Word Count', \n",
    "                                'KWIC Hits', 'Hits per Million']]\n",
    "metadata_df_temp.style.format({\n",
    "    'Total Word Count': '{:,}',\n",
    "    'KWIC Hits': '{:,}',\n",
    "    'Hits per Million': '{:.2f}'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary showing corpus metadata (non-duplicated)\n",
    "corpus_summary = metadata_df.groupby('Corpus').agg({\n",
    "    'Total Genres': 'first',\n",
    "    'Total Word Count': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Corpus Summary (Total Word Counts):\")\n",
    "display(corpus_summary)\n",
    "\n",
    "print(\"\\nKWIC Hits by Keyword and Corpus:\")\n",
    "pivot_hits = metadata_df.pivot(index='Keyword', columns='Corpus', values='KWIC Hits')\n",
    "display(pivot_hits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b493e",
   "metadata": {},
   "source": [
    "___________________________\n",
    "## Export KWIC results and metadata file to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_json('./exports/metadata_11142025_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfdd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as _pd\n",
    "\n",
    "# ensure exports directory exists\n",
    "exports_dir = Path('./exports')\n",
    "exports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _serialize(obj):\n",
    "    \"\"\"Recursively convert common non-JSON-serializable objects to JSON-friendly types.\"\"\"\n",
    "    # numpy scalars / arrays\n",
    "    if isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    # pandas objects (pd imported earlier in the notebook)\n",
    "    try:\n",
    "        if isinstance(obj, _pd.Timestamp):\n",
    "            return obj.isoformat()\n",
    "        if isinstance(obj, _pd.DataFrame):\n",
    "            return obj.to_dict(orient='records')\n",
    "        if isinstance(obj, _pd.Series):\n",
    "            return obj.tolist()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Builtins\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _serialize(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [_serialize(v) for v in obj]\n",
    "    if isinstance(obj, tuple):\n",
    "        return [_serialize(v) for v in obj]\n",
    "    # Fallback to string for unknown types\n",
    "    return obj\n",
    "\n",
    "# Serialize and dump KWIC results for each keyword and corpus combination\n",
    "# COCA exports\n",
    "kwic_coca_best_system = _serialize(best_system_kwic_coca)\n",
    "kwic_coca_best_method = _serialize(best_method_kwic_coca)\n",
    "kwic_coca_national_system = _serialize(national_system_kwic_coca)\n",
    "kwic_coca_industry_standard = _serialize(industry_standard_kwic_coca)\n",
    "\n",
    "with open(exports_dir / 'kwic_coca_best_system.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_coca_best_system, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_coca_best_method.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_coca_best_method, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_coca_national_system.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_coca_national_system, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_coca_industry_standard.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_coca_industry_standard, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# GloWbE exports\n",
    "kwic_glowbe_best_system = _serialize(best_system_kwic_glowbe)\n",
    "kwic_glowbe_best_method = _serialize(best_method_kwic_glowbe)\n",
    "kwic_glowbe_national_system = _serialize(national_system_kwic_glowbe)\n",
    "kwic_glowbe_industry_standard = _serialize(industry_standard_kwic_glowbe)\n",
    "\n",
    "with open(exports_dir / 'kwic_glowbe_best_system.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_glowbe_best_system, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_glowbe_best_method.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_glowbe_best_method, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_glowbe_national_system.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_glowbe_national_system, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_glowbe_industry_standard.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_glowbe_industry_standard, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# EcoLexicon exports\n",
    "kwic_ecolexicon_best_system = _serialize(best_system_kwic_ecolexicon)\n",
    "kwic_ecolexicon_best_method = _serialize(best_method_kwic_ecolexicon)\n",
    "kwic_ecolexicon_national_system = _serialize(national_system_kwic_ecolexicon)\n",
    "kwic_ecolexicon_industry_standard = _serialize(industry_standard_kwic_ecolexicon)\n",
    "\n",
    "with open(exports_dir / 'kwic_ecolexicon_best_system.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_ecolexicon_best_system, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_ecolexicon_best_method.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_ecolexicon_best_method, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_ecolexicon_national_system.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_ecolexicon_national_system, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(exports_dir / 'kwic_ecolexicon_industry_standard.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(kwic_ecolexicon_industry_standard, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Written 12 KWIC JSON files to {exports_dir.resolve()}:\")\n",
    "print(\"   COCA: best_system, best_method, national_system, industry_standard\")\n",
    "print(\"   GloWbE: best_system, best_method, national_system, industry_standard\")\n",
    "print(\"   EcoLexicon: best_system, best_method, national_system, industry_standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5298e60",
   "metadata": {},
   "source": [
    "____________________________\n",
    "\n",
    "### Proceed for Minimal Coding Approach\n",
    "\n",
    "- concordance line annotation\n",
    "- use the `annotator_app/app.py` to annotate concordance lines interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626d739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
