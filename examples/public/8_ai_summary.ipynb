{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89641cfb",
   "metadata": {},
   "source": [
    "## This notebook outlines an outline for using AI tools for text classification and clustering.\n",
    "\n",
    "user supplied info, that we will pass to the AI model includes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "618c22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f66d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_level='high' # low, medium, high\n",
    "corpus_fullname='Corpus of Contemporary American English' # Corpus of Contemporary American English, Glowlbe, EcoLexicon\n",
    "corpus_shortname='COCA' # coca, glowbe, ecolexicon\n",
    "keyword='national system' # best system, best method, national system, industry standard\n",
    "#classifications=['literal','figurative','neither','unclear'] # adjust as needed\n",
    "random_KWIC_sample=100\n",
    "\n",
    "path = \"./kwic_coca_national_system_annotations_export.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce582b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened dataframe shape: (51, 5)\n",
      "Columns: ['genre_id', 'genre_idx', 'text_id', 'context', 'timestamp']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre_idx</th>\n",
       "      <th>text_id</th>\n",
       "      <th>context</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acad_1991</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>147 ) . 16 &lt;p&gt; A rapid diffusion of rural scho...</td>\n",
       "      <td>2025-11-21T21:30:29.339228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acad_1992</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>tariffs for infant industries , and public dev...</td>\n",
       "      <td>2025-11-22T13:52:22.167679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acad_1993</td>\n",
       "      <td>3</td>\n",
       "      <td>386</td>\n",
       "      <td>of social and cultural movements that were rea...</td>\n",
       "      <td>2025-11-21T21:41:53.940823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acad_1993</td>\n",
       "      <td>5</td>\n",
       "      <td>797</td>\n",
       "      <td>healthcare system . &lt;p&gt; A distinguished study ...</td>\n",
       "      <td>2025-11-22T13:53:35.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acad_1996</td>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>quo to continue , over mutual cooperation , wh...</td>\n",
       "      <td>2025-11-22T13:54:24.086793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre_id  genre_idx  text_id  \\\n",
       "0  acad_1991          0      159   \n",
       "1  acad_1992          0       13   \n",
       "2  acad_1993          3      386   \n",
       "3  acad_1993          5      797   \n",
       "4  acad_1996          2      187   \n",
       "\n",
       "                                             context  \\\n",
       "0  147 ) . 16 <p> A rapid diffusion of rural scho...   \n",
       "1  tariffs for infant industries , and public dev...   \n",
       "2  of social and cultural movements that were rea...   \n",
       "3  healthcare system . <p> A distinguished study ...   \n",
       "4  quo to continue , over mutual cooperation , wh...   \n",
       "\n",
       "                    timestamp  \n",
       "0  2025-11-21T21:30:29.339228  \n",
       "1  2025-11-22T13:52:22.167679  \n",
       "2  2025-11-21T21:41:53.940823  \n",
       "3  2025-11-22T13:53:35.114754  \n",
       "4  2025-11-22T13:54:24.086793  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = \"./kwic_coca_industry_standard_annotations_export.json\"\n",
    "#path = \"./kwic_coca_national_system_annotations_export.json\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten the annotations JSON structure into a DataFrame\n",
    "rows = []\n",
    "\n",
    "# The data has 'annotations' as the top-level key\n",
    "annotations = data.get('annotations', {})\n",
    "\n",
    "for genre_id, items_dict in annotations.items():\n",
    "    # items_dict is a dictionary where keys are string indices\n",
    "    for idx_str, item in items_dict.items():\n",
    "        row = {\n",
    "            'genre_id': genre_id,\n",
    "            'genre_idx': int(idx_str),\n",
    "            'text_id': item.get('text_id'),\n",
    "            #'match': item.get('match'),\n",
    "            'context': item.get('context'),\n",
    "            #'full_text': item.get('full_text'),\n",
    "            #'classification': item.get('classification'),\n",
    "            #'notes': item.get('notes'),\n",
    "            'timestamp': item.get('timestamp')\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Create the flattened DataFrame\n",
    "df_flat = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by genre_id and genre_idx for better readability\n",
    "df_flat = df_flat.sort_values(['genre_id', 'genre_idx']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Flattened dataframe shape: {df_flat.shape}\")\n",
    "print(f\"Columns: {list(df_flat.columns)}\")\n",
    "df_flat.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc955f",
   "metadata": {},
   "source": [
    "### Create AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faf0daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AWS Bedrock model initialized: openai.gpt-oss-120b-1:0\n",
      "üî¨ AI Assisted Forensic Linguistics Tool Ready\n"
     ]
    }
   ],
   "source": [
    "# COCA Computational Forensic Linguistics Agent\n",
    "# Adapted from SCOTUS analysis tools for corpus linguistics analysis\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Optional, Type, Dict, Any, Union, List\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize AWS Bedrock model for COCA forensic linguistics analysis\n",
    "model_id = 'openai.gpt-oss-120b-1:0'  # 128K context window\n",
    "max_tokens = 128000\n",
    "\n",
    "model = init_chat_model(\n",
    "    model_id, \n",
    "    model_provider=\"bedrock_converse\",\n",
    "    #model_provider=\"bedrock\",\n",
    "    credentials_profile_name='atn-developer',  # Adjust to your AWS profile (see https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-files.html)\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=0.0,\n",
    "    #temperature=1.0,\n",
    "\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ AWS Bedrock model initialized: {model_id}\")\n",
    "print(f\"üî¨ AI Assisted Forensic Linguistics Tool Ready\")\n",
    "#print(f\"üìä Available COCA genres: {list(coca_corpus.keys())}\")\n",
    "#print(f\"üìä Available GloWbe genres: {list(glowbe_corpus.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d0b39",
   "metadata": {},
   "source": [
    "## Test model connectivity to AWS Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "babddc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'type': 'reasoning_content', 'reasoning_content': {'text': 'The user asks: \"What is the capital of Pennsylvania?\" Straightforward factual question. Answer: Harrisburg. Provide answer.', 'signature': ''}}, {'type': 'text', 'text': 'The capital of Pennsylvania is **Harrisburg**.'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '56655a46-0c37-4115-bf98-e97163131cd1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 24 Nov 2025 15:52:00 GMT', 'content-type': 'application/json', 'content-length': '427', 'connection': 'keep-alive', 'x-amzn-requestid': '56655a46-0c37-4115-bf98-e97163131cd1'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [36346]}, 'model_name': 'openai.gpt-oss-120b-1:0'}, id='run--fbfa85e8-8fb6-4817-a4a6-8d2c64c62f32-0', usage_metadata={'input_tokens': 76, 'output_tokens': 46, 'total_tokens': 122, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('What is the capital of Pennsylvania?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688bb71",
   "metadata": {},
   "source": [
    "### Let's create a base tool class for user supplied corpus analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c2cfd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Optional, Type, Dict, Any, Union, List\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "class KWICAnalysisInput(BaseModel):\n",
    "    \"\"\"Input schema for KWIC analysis tool\"\"\"\n",
    "    reasoning_level: str = Field(default=\"high\", description=\"Reasoning level: 'low', 'medium', or 'high'\")\n",
    "    corpus_fullname: str = Field(description=\"Full corpus name (e.g. 'Corpus of Contemporary American English')\")\n",
    "    corpus_shortname: str = Field(description=\"Short corpus id (e.g. 'COCA')\")\n",
    "    keyword: str = Field(description=\"Search keyword or phrase\")\n",
    "    #classifications: List[str] = Field(description=\"Allowed classification labels\")\n",
    "    random_KWIC_sample: int = Field(default=30, description=\"Number of random KWIC samples to analyze\")\n",
    "    kwic_data: Dict[str, Any] = Field(description=\"KWIC concordance data (JSON structure)\")\n",
    "\n",
    "    \n",
    "class KWICAnalysisTool(BaseTool):\n",
    "    \"\"\"Tool for analyzing KWIC concordance data using AI\"\"\"\n",
    "    name: str = \"kwic_analysis\"\n",
    "    description: str = \"\"\"Analyzes KWIC (Key Word in Context) concordance data from corpus linguistics.\n",
    "    Provides AI-assisted classification and analysis of concordance lines.\"\"\"\n",
    "    args_schema: Type[BaseModel] = KWICAnalysisInput\n",
    "    \n",
    "    # Store model configuration\n",
    "    model: Any = None\n",
    "    \n",
    "    def _run(\n",
    "        self,\n",
    "        reasoning_level: str,\n",
    "        corpus_fullname: str,\n",
    "        corpus_shortname: str,\n",
    "        keyword: str,\n",
    "        #classifications: List[str],\n",
    "        random_KWIC_sample: int,\n",
    "        kwic_data: Dict[str, Any]\n",
    "    ) -> str:\n",
    "        \"\"\"Execute KWIC analysis using Bedrock AI model\"\"\"\n",
    "        \n",
    "        # Prepare corpus metadata\n",
    "        metadata = {\n",
    "            \"corpus_name\": corpus_fullname,\n",
    "            \"corpus_id\": corpus_shortname,\n",
    "            \"keyword\": keyword,\n",
    "            \"reasoning_level\": reasoning_level,\n",
    "            #\"classification_options\": classifications,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Count total concordance lines\n",
    "        total_lines = 0\n",
    "        if 'annotations' in kwic_data:\n",
    "            for genre_id, items in kwic_data['annotations'].items():\n",
    "                total_lines += len(items)\n",
    "        \n",
    "        # take a random sample of concordance lines if specified\n",
    "        if random_KWIC_sample > 0 and total_lines > random_KWIC_sample:\n",
    "            import random\n",
    "            sampled_items = {}\n",
    "            all_items = []\n",
    "            for genre_id, items in kwic_data['annotations'].items():\n",
    "                for idx_str, item in items.items():\n",
    "                    all_items.append((genre_id, idx_str, item))\n",
    "            sampled = random.sample(all_items, random_KWIC_sample)\n",
    "            for genre_id, idx_str, item in sampled:\n",
    "                if genre_id not in sampled_items:\n",
    "                    sampled_items[genre_id] = {}\n",
    "                sampled_items[genre_id][idx_str] = item\n",
    "            kwic_data['annotations'] = sampled_items\n",
    "\n",
    "        # Construct prompt for Bedrock\n",
    "        prompt = f\"\"\"You are a forensic linguistics expert analyzing concordance data from {corpus_fullname} ({corpus_shortname}).\n",
    "\n",
    "                    **Analysis Task:**\n",
    "                    - Reasoning level: {reasoning_level}\n",
    "                    - Corpus Fullname: {corpus_fullname}\n",
    "                    - Corpus Name: {corpus_shortname}\n",
    "                    - Keyword/Phrase: \"{keyword}\"\n",
    "                    - Total concordance lines: {total_lines}\n",
    "                    - Random KWIC sample size: {random_KWIC_sample}\n",
    "\n",
    "                    **Corpus Metadata:**\n",
    "                    {json.dumps(metadata, indent=2)}\n",
    "\n",
    "                    **KWIC Concordance Data:**\n",
    "                    {json.dumps(kwic_data, indent=2)}\n",
    "\n",
    "                    **Instructions:**\n",
    "                    Focus on detailed linguistic analysis of concordance line patterns given the keyword/phrase of interest.\n",
    "                    Do not reference information beyond what is provided in the text, and if you are not certain, indicate uncertainty.\n",
    "                    The question to answer is \"given the context of the full concordance line text provided, in what sense did the speaker mean when they used the keyword/phrase?\"\n",
    "\n",
    "                    1. Collocates\n",
    "                    2. Semantic Prosody\n",
    "                    3. Grammatical Patterns\n",
    "                    4. Semantic Domains\n",
    "                    5. Evaluation/Comparison\n",
    "                    6. Qualification/Mitigation\n",
    "                    7. Speaker/Writer Stance\n",
    "\n",
    "                    Please provide a structured analysis with:\n",
    "                    - Individual line classifications with reasoning\n",
    "                    - Pattern identification\n",
    "                    - Summary statistics\n",
    "                    - Key linguistic insights\n",
    "        \"\"\"\n",
    "        \n",
    "        # Invoke Bedrock model\n",
    "        if self.model is None:\n",
    "            return \"Error: Model not initialized\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke(prompt)\n",
    "            return response.content if hasattr(response, 'content') else str(response)\n",
    "        except Exception as e:\n",
    "            return f\"Error during AI analysis: {str(e)}\"\n",
    "    \n",
    "    async def _arun(self, *args, **kwargs):\n",
    "        \"\"\"Async version not implemented\"\"\"\n",
    "        raise NotImplementedError(\"Async execution not supported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49773640",
   "metadata": {},
   "source": [
    "### Initialize KWIC Analysis Tool with Bedrock Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84053f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ KWIC Analysis Tool initialized\n",
      "üìä Tool name: kwic_analysis\n",
      "üìù Description: Analyzes KWIC (Key Word in Context) concordance data from corpus linguistics.\n",
      "    Provides AI-assisted classification and analysis of concordance lines.\n"
     ]
    }
   ],
   "source": [
    "# Create the KWIC Analysis Tool instance\n",
    "kwic_tool = KWICAnalysisTool()\n",
    "kwic_tool.model = model  # Attach the Bedrock model we initialized earlier\n",
    "\n",
    "print(f\"‚úÖ KWIC Analysis Tool initialized\")\n",
    "print(f\"üìä Tool name: {kwic_tool.name}\")\n",
    "print(f\"üìù Description: {kwic_tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452d8cd",
   "metadata": {},
   "source": [
    "### Run KWIC Analysis with Concordance Data\n",
    "\n",
    "- optionally drop the classifications and notes so AI is just working with concordance hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47efe024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy of data without classification and notes\n",
    "import copy\n",
    "clean_data = copy.deepcopy(data)\n",
    "\n",
    "# Remove classification and notes from all annotations\n",
    "if 'annotations' in clean_data:\n",
    "    for genre_id, items_dict in clean_data['annotations'].items():\n",
    "        for idx_str, item in items_dict.items():\n",
    "            # Remove classification and notes fields if they exist\n",
    "            item.pop('classification', None)\n",
    "            item.pop('notes', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e722d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KWIC ANALYSIS RESULTS\n",
      "================================================================================\n",
      "Error during AI analysis: Read timeout on endpoint URL: \"https://bedrock-runtime.us-east-1.amazonaws.com/model/openai.gpt-oss-120b-1%3A0/converse\"\n"
     ]
    }
   ],
   "source": [
    "# Execute the KWIC analysis by passing the cleaned concordance data\n",
    "result = kwic_tool._run(\n",
    "    reasoning_level=reasoning_level,\n",
    "    corpus_fullname=corpus_fullname,\n",
    "    corpus_shortname=corpus_shortname,\n",
    "    keyword=keyword,\n",
    "    #classifications=classifications,\n",
    "    random_KWIC_sample=50,\n",
    "    kwic_data=clean_data  # Pass the cleaned JSON data\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KWIC ANALYSIS RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b1495",
   "metadata": {},
   "source": [
    "### Optional: Save Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1515d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Markdown report exported to: ./kwic_ai_analysis_COCA_national_system_20251122_174138.md\n",
      "üìÑ Report contains 21022 characters\n",
      "üìä Based on 51 concordance lines\n"
     ]
    }
   ],
   "source": [
    "# Export to a Markdown Report\n",
    "markdown_output_file = f\"./kwic_ai_analysis_{corpus_shortname}_{keyword.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "\n",
    "# Initialize variables\n",
    "reasoning_content = \"\"\n",
    "markdown_content = \"\"\n",
    "\n",
    "# Extract content from the result\n",
    "if isinstance(result, list):\n",
    "    # Parse the response structure\n",
    "    for item in result:\n",
    "        if item.get('type') == 'reasoning_content':\n",
    "            reasoning_data = item.get('reasoning_content', {})\n",
    "            reasoning_content = reasoning_data.get('text', '')\n",
    "        elif item.get('type') == 'text':\n",
    "            markdown_content = item.get('text', '')\n",
    "else:\n",
    "    markdown_content = str(result)\n",
    "\n",
    "# Create the full markdown report\n",
    "full_report = f\"\"\"# KWIC Analysis Report: {keyword}\n",
    "\n",
    "**Corpus:** {corpus_fullname} ({corpus_shortname})  \n",
    "**Keyword/Phrase:** \"{keyword}\"  \n",
    "**Reasoning Level:** {reasoning_level}  \n",
    "**Random Sample Size:** {random_KWIC_sample}\n",
    "**Analysis Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n",
    "**Generated by:** AWS Bedrock AI Model ({model_id})\n",
    "\n",
    "**Reasoning Content:**\n",
    "```text\n",
    "{reasoning_content}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "{markdown_content}\n",
    "\n",
    "---\n",
    "\n",
    "**Report Metadata:**\n",
    "- Total concordance lines analyzed: {len(df_flat)}\n",
    "- Source data file: `{path}`\n",
    "- Analysis tool: KWICAnalysisTool (LangChain + AWS Bedrock)\n",
    "\"\"\"\n",
    "\n",
    "# Write to file\n",
    "with open(markdown_output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(full_report)\n",
    "\n",
    "print(f\"‚úÖ Markdown report exported to: {markdown_output_file}\")\n",
    "print(f\"üìÑ Report contains {len(markdown_content)} characters\")\n",
    "print(f\"üìä Based on {len(df_flat)} concordance lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad548b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
