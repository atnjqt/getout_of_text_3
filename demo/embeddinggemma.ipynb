{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5d84ee",
   "metadata": {},
   "source": [
    "# Embedding Gemma\n",
    "- https://huggingface.co/blog/embeddinggemma#usage\n",
    "- You'll need to accept the model license agreement on Hugging Face in order to access the model, and then login with an API token in the notebook here.\n",
    "- TBD on how this login functinoality will get included on got3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df5668a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51c9c1871714bb3bf84735f28047d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# authenticate with Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688e4d0",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "- this will download some files and display graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e873a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "sentences = [\n",
    "    \"That is a happy person\",\n",
    "    \"That is a happy dog\",\n",
    "    \"That is a very happy person\",\n",
    "    \"Today is a sunny day\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "# [4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745f1462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8078, 0.9839, 0.5595],\n",
       "        [0.8078, 1.0000, 0.7960, 0.5486],\n",
       "        [0.9839, 0.7960, 1.0000, 0.5417],\n",
       "        [0.5595, 0.5486, 0.5417, 1.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e44a1",
   "metadata": {},
   "source": [
    "## Sample Query & Documents\n",
    "- Using transformer and torch to find the most relevant document to a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5755087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) (9, 768)\n",
      "tensor([[0.3376, 0.2881, 0.3313, 0.5894, 0.5091, 0.4406, 0.1767, 0.2805, 0.2955]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ü§ó Hub\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "# Run inference with queries and documents\n",
    "query = \"Which planet is the Red Planet?\"\n",
    "documents = [\n",
    "    \"Mercury is the closest planet to the Sun and has a very thin atmosphere.\",\n",
    "    \"Venus is often called Earth's twin because of its similar size and proximity.\",\n",
    "    \"Earth is the only planet known to support life.\",\n",
    "    \"Mars, known for its reddish appearance, is often referred to as the Red Planet.\",\n",
    "    \"Jupiter, the largest planet in our solar system, has a prominent red spot.\",\n",
    "    \"Saturn is famous for its rings, is sometimes mistaken for the Red Planet.\",\n",
    "    \"Uranus often is depicted with a blue-green color due to methane in its atmosphere.\",\n",
    "    \"Neptune, the enormous distant blue planet with strong winds, is known for its storms.\",\n",
    "    \"Pluto, once considered the ninth planet, is now classified as a dwarf planet.\"\n",
    "]\n",
    "query_embeddings = model.encode_query(query)\n",
    "document_embeddings = model.encode_document(documents)\n",
    "print(query_embeddings.shape, document_embeddings.shape)\n",
    "# (768,) (4, 768)\n",
    "\n",
    "# Compute similarities to determine a ranking\n",
    "similarities = model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarities)\n",
    "# tensor([[0.3011, 0.6359, 0.4930, 0.4889]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26424fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# QUERY ###################\n",
      "query: Which planet is the Red Planet?\n",
      "###########################################\n",
      "\n",
      "Best answer: Mars, known for its reddish appearance, is often referred to as the Red Planet.\n",
      "Worst answer: Uranus often is depicted with a blue-green color due to methane in its atmosphere.\n",
      "\n",
      "1. Mars, known for its reddish appearance, is often referred to as the Red Planet.\n",
      "2. Jupiter, the largest planet in our solar system, has a prominent red spot.\n",
      "3. Saturn is famous for its rings, is sometimes mistaken for the Red Planet.\n",
      "4. Mercury is the closest planet to the Sun and has a very thin atmosphere.\n",
      "5. Earth is the only planet known to support life.\n",
      "6. Pluto, once considered the ninth planet, is now classified as a dwarf planet.\n",
      "7. Venus is often called Earth's twin because of its similar size and proximity.\n",
      "8. Neptune, the enormous distant blue planet with strong winds, is known for its storms.\n",
      "9. Uranus often is depicted with a blue-green color due to methane in its atmosphere.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the index of the most similar document\n",
    "print('################# QUERY ###################')\n",
    "print('query:', query)\n",
    "print('###########################################')\n",
    "print('')\n",
    "\n",
    "\n",
    "best_idx = torch.argmax(similarities)\n",
    "print(\"Best answer:\", documents[best_idx])\n",
    "worst_idx = torch.argmin(similarities)\n",
    "print(\"Worst answer:\", documents[worst_idx])\n",
    "torch.topk(similarities, k=3)\n",
    "\n",
    "torch.argsort(similarities, descending=True)\n",
    "print('')# print the documents in a numbered list\n",
    "# 0 is most habitable, 8 is least habitable\n",
    "for i, idx in enumerate(torch.argsort(similarities, descending=True)[0]):\n",
    "    print(f\"{i+1}. {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ed6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_query = \"Which planet is known as the Red Planet?\"\n",
    "qa_prompt = f\"task: question answering | query: {qa_query}\"\n",
    "qa_embedding = model.encode_query(qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27cf5381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best answer: title: Mars | text: Mars, known for its reddish appearance, is often referred to as the Red Planet.\n"
     ]
    }
   ],
   "source": [
    "# Question Answering with EmbeddingGemma\n",
    "qa_query = 'Which planet is known as the Red Planet?'\n",
    "qa_prompt = f'task: question answering | query: {qa_query}'\n",
    "qa_embedding = model.encode_query(qa_prompt)\n",
    "\n",
    "documents = [\n",
    "    'title: Mars | text: Mars, known for its reddish appearance, is often referred to as the Red Planet.',\n",
    "    'title: Venus | text: Venus is often called Earths twin because of its similar size and proximity.',\n",
    "    'title: Jupiter | text: Jupiter, the largest planet in our solar system, has a prominent red spot.',\n",
    "    'title: Saturn | text: Saturn, famous for its rings, is sometimes mistaken for the Red Planet.'\n",
    "]\n",
    "document_embeddings = model.encode_document(documents)\n",
    "similarities = model.similarity(qa_embedding, document_embeddings)\n",
    "\n",
    "import torch\n",
    "best_idx = torch.argmax(similarities)\n",
    "print('Best answer:', documents[best_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8c589",
   "metadata": {},
   "source": [
    "### Consider how to integrate this into the getout_of_text_3 framework\n",
    "\n",
    "- you might use your corpora to get collocates and concordances around terms of interest from statutory languauge\n",
    "- setup a document collections of the collocates and concordances as a vector space\n",
    "- you can then use retrieval query and question tasks on this document collection\n",
    "- ai llms could the summarize the results\n",
    "\n",
    "- https://huggingface.co/google/embeddinggemma-300m#prompt-instructions\n",
    "    - `task: search result | query: {content}`\n",
    "    - `task: question answering | query: {content}`\n",
    "    - consider how part of speech tagging in the title can be important! also maybe just having one type of classification to avoid multiple words causing confusion\n",
    "    - manually encoding your collocates per the various meanings of an ambiguous term\n",
    "    - to then query a question with the statutory language in question, for a context aware approach\n",
    "    - the getout-of-text3 framework / tool should streamline this workflow to make the process more accessible for folks (i.e. having a term to get collocates in a corpus, then building the document embeddings, then querying the document embeddings with a question or search task -- not as a declarative answer but just one way to surface the 'ordinary' meanings of a term in context).\n",
    "    - lastly, the COCA is genre divided, so you could consider how to use the genre as a filter for the collocates and concordances and then query question answers depending on models.\n",
    "\n",
    "### Another Example\n",
    "\n",
    "- the term 'bank' is often referenced in embedding examples for bert, etc. This performs OK but I've made up the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feb3194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best answer: title: Bank Deposit | text: I went to the bank to deposit my paycheck.\n",
      "All answers ranked:\n",
      "1. title: Bank Deposit | text: I went to the bank to deposit my paycheck.\n",
      "2. title: Making Bank | text: After selling his startup, he is really making bank now.\n",
      "3. title: Bank Loan | text: She applied for a loan at the local bank.\n",
      "4. title: Unit of Items | text: A bank of computers was set up in the server room.\n",
      "5. title: Reserve or Supply | text: The food bank provided meals for those in need\n",
      "6. title: River Bank | text: The children played on the grassy bank of the river.\n",
      "7. title: River Flood | text: The river overflowed its bank after the heavy rain.\n"
     ]
    }
   ],
   "source": [
    "# Question Answering for ambiguous term 'bank' in different contexts\n",
    "qa_query = 'What type of bank is Wells Fargo?'\n",
    "qa_prompt = f'task: question answering | query: {qa_query}'\n",
    "qa_embedding = model.encode_query(qa_prompt)\n",
    "\n",
    "documents = [\n",
    "    'title: Bank Deposit | text: I went to the bank to deposit my paycheck.',\n",
    "    'title: River Bank | text: The children played on the grassy bank of the river.',\n",
    "    'title: Making Bank | text: After selling his startup, he is really making bank now.',\n",
    "    'title: Bank Loan | text: She applied for a loan at the local bank.',\n",
    "    'title: River Flood | text: The river overflowed its bank after the heavy rain.',\n",
    "    'title: Unit of Items | text: A bank of computers was set up in the server room.',\n",
    "    'title: Reserve or Supply | text: The food bank provided meals for those in need',\n",
    "]\n",
    "document_embeddings = model.encode_document(documents)\n",
    "similarities = model.similarity(qa_embedding, document_embeddings)\n",
    "import torch\n",
    "best_idx = torch.argmax(similarities)\n",
    "print('Best answer:', documents[best_idx])\n",
    "print('All answers ranked:')\n",
    "for i, idx in enumerate(torch.argsort(similarities, descending=True)[0]):\n",
    "    print(f'{i+1}. {documents[idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc5e3b",
   "metadata": {},
   "source": [
    "### Outlining the workflow\n",
    "\n",
    "1. get your sample corpus for collocates, spit out as documents\n",
    "2. load your model\n",
    "3. encode the collocates documents for the model\n",
    "4. ask your query, for the statutory language with term `<TOKEN>`\n",
    "\n",
    "```python\n",
    "statutory_language = \"The bank shall maintain sufficient reserves.\"\n",
    "\n",
    "year_enacted = 2024 # for historical reference, if you have a historical corpora \n",
    "\n",
    "ambiguous_term = \"sufficient\" # the term which leads towards confusion or ambiguity\n",
    "\n",
    "query = 'What is the ordinary meaning of the ambiguous term \"{}\" in the context of the following statutory language, \"{}\", enacted in the year {}?'.format(ambiguous_term,statutory_language,year_enacted)\n",
    "\n",
    "query_prompt = f\"task: question answering | query: {query}\"\n",
    "query_embedding = model.encode_query(query_prompt)\n",
    "\n",
    "documents = [\n",
    "    \"title: Adequate | text: Enough to meet a need or requirement; satisfactory.\",\n",
    "    \"title: Ample | text: More than enough in size, scope, or capacity.\",\n",
    "    \"title: Competent | text: Having the necessary ability, knowledge, or skill to do something successfully.\",\n",
    "    \"title: Decent | text: Conforming to standards of propriety, good taste, or morality; acceptable.\",\n",
    "    \"title: Fair | text: In accordance with the rules or standards; legitimate.\",\n",
    "    \"title: Good | text: Having desirable or positive qualities; satisfactory in quality, quantity, or degree.\",\n",
    "    \"title: Plenty | text: A large or sufficient amount or quantity; more than enough.\",\n",
    "    \"title: Reasonable | text: Based on or using good judgment; fair and sensible.\",\n",
    "    \"title: Satisfactory | text: Meeting the requirements or expectations; adequate.\",\n",
    "    \"title: Suitable | text: Appropriate for a particular purpose, person, or occasion.\"\n",
    "]\n",
    "document_embeddings = model.encode_document(documents)\n",
    "similarities = model.similarity(query_embedding, document_embeddings)\n",
    "most_similar_idx = similarities.argmax()\n",
    "most_relevant_document = documents[most_similar_idx]\n",
    "print(\"Most relevant document:\", most_relevant_document)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdba0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# RESULTS ###################\n",
      "\n",
      "statutory_language: The bank shall maintain sufficient reserves.\n",
      "ambiguous_term: sufficient\n",
      "year_enacted: 2024\n",
      "\n",
      "query: What is the ordinary meaning of the ambiguous term \"sufficient\" in the context of the following statutory language, \"The bank shall maintain sufficient reserves.\", enacted in the year 2024?\n",
      "\n",
      "Most relevant document:\n",
      "title: Text 29 | text: , even estimates of Colombian **bank** deposits in the state would\n"
     ]
    }
   ],
   "source": [
    "documents_sample=[\n",
    "    \"title: Text 18 | text: for education and the World **Bank** database for economic indicators .\",\n",
    "    \"title: Text 18 | text: World Development Report ( World **Bank** , 1988 ) . <p>\",\n",
    "    \"title: Text 18 | text: primary schools in the West **Bank** and Gaza , whether public\",\n",
    "    \"title: Text 18 | text: primary schools in the West **Bank** were ordered to close 63\",\n",
    "    \"title: Text 18 | text: much so that the World **Bank** Report on Education in Africa\",\n",
    "    \"title: Text 20 | text: outward investment , the Export-Import **Bank** ( Eximbank ) , a\",\n",
    "    \"title: Text 20 | text: ) , a specialized government **bank** established in 1979 , is\",\n",
    "    \"title: Text 20 | text: supported by the Asian Development **Bank** . 23 In addition ,\",\n",
    "    \"title: Text 20 | text: 1991 to the Central American **Bank** for Economic Integration to help\",\n",
    "    \"title: Text 20 | text: As a result , the **bank** revised its charter to allow\",\n",
    "    \"title: Text 20 | text: channeled aid through the European **Bank** for Reconstruction and Development by\",\n",
    "    \"title: Text 20 | text: not qualified to join the **bank** because it is a non-European\",\n",
    "    \"title: Text 20 | text: regional banks -- the European **Bank** for Reconstruction and Development ,\",\n",
    "    \"title: Text 20 | text: Development , the Asian Development **Bank** , and the Central American\",\n",
    "    \"title: Text 20 | text: , and the Central American **Bank** -- totaled $32.5 million ,\",\n",
    "    \"title: Text 20 | text: president of Taiwan 's Central **Bank** , estimated that Taiwan 's\",\n",
    "    \"title: Text 20 | text: industrialized states , the World **Bank** , and the International Monetary\",\n",
    "    \"title: Text 20 | text: GATT , IMF , World **Bank** , or even the United\",\n",
    "    \"title: Text 21 | text: . Last year the central **bank** once refused to hire a\",\n",
    "    \"title: Text 21 | text: and been assigned to the **bank** . Another time it refused\",\n",
    "    \"title: Text 21 | text: membership exam of the central **bank** . Recently , the dispute\",\n",
    "    \"title: Text 29 | text: to obtain for the foreign **bank** agencies in Florida , and\",\n",
    "    \"title: Text 29 | text: , even estimates of Colombian **bank** deposits in the state would\",\n",
    "    \"title: Text 29 | text: Florida via calculations of Colombian **bank** deposits there or via efforts\",\n",
    "    \"title: Text 32 | text: figures , ' including World **Bank** President James Wolfensohn ( al-Ahram\",\n",
    "    \"title: Text 32 | text: gracious sanctuary on the west **bank** of the Nile , with\",\n",
    "    \"title: Text 558 | text: checking account at the conspiracy **bank** . There 's only $1.58\",\n",
    "    \"title: Text 558 | text: check ) to a local **bank** or @ @ @ \",\n",
    "    \"title: Text 558 | text: days , the bigger the **bank** , the more reason to\",\n",
    "    \"title: Text 558 | text: I actually did close my **Bank** of America account long ago\",\n",
    "    \"title: Text 558 | text: should point out that US **Bank** is one of the better\",\n",
    "    \"title: Text 571 | text: Reuters about the current food **bank** situation in these United States\",\n",
    "    \"title: Text 574 | text: ( across from the Berkshire **Bank** ) <p> In closing I\",\n",
    "    \"title: Text 579 | text: which also draw directly on **bank** deposits , is zero .\",\n",
    "    \"title: Text 581 | text: day that they charged my **bank** card , and provided them\",\n",
    "    \"title: Text 609 | text: an unprecedented spending bill for **bank** bailouts , Detroit rescues ,\",\n",
    "    \"title: Text 618 | text: there exists nothing fishy with **bank** accounts . <p> Do n't\",\n",
    "    \"title: Text 629 | text: were given to the national **bank** by the minister of finance\",\n",
    "    \"title: Text 629 | text: EBRD or the Africa Development **Bank** . ' <p> Philippe Doizelet\",\n",
    "    \"title: Text 639 | text: carlzimmer.com <p> ' The Tangled **Bank** is the best written and\",\n",
    "    \"title: Text 662 | text: dealer 's collection of old **bank** notes caught my eye\",\n",
    "    \"title: Text 672 | text: Cayman Islands or a Swiss **bank** account . He 's one\",\n",
    "    \"title: Text 697 | text: to Work <p> The World **Bank** has just released its 2013\",\n",
    "    \"title: Text 702 | text: because someone raided the piggy **bank** to pay for tax cuts\",\n",
    "    \"title: Text 722 | text: by Monsanto , the World **Bank** and USAID , and Burkina\",\n",
    "    \"title: Text 752 | text: A source in the Deutsche **Bank** claims that in 2008 our\",\n",
    "    \"title: Text 752 | text: law . <p> The Deutsche **Bank** informant says that the cause\",\n",
    "    \"title: Text 759 | text: of Aswan on the east **bank** . <h> 20 . Bazaruto\",\n",
    "    \"title: Text 771 | text: time , with the State **Bank** printing almost Rs. 1 trillion\",\n",
    "    \"title: Text 782 | text: a new job as a **bank** teller . He had gotten\"\n",
    "]\n",
    "\n",
    "\n",
    "statutory_language = \"The bank shall maintain sufficient reserves.\"\n",
    "\n",
    "year_enacted = 2024 # for historical reference, if you have a historical corpora \n",
    "\n",
    "ambiguous_term = \"sufficient\" # the term which leads towards confusion or ambiguity\n",
    "\n",
    "query = 'What is the ordinary meaning of the ambiguous term \"{}\" in the context of the following statutory language, \"{}\", enacted in the year {}?'.format(ambiguous_term,statutory_language,year_enacted)\n",
    "\n",
    "query_prompt = f\"task: question answering | query: {query}\"\n",
    "query_embedding = model.encode_query(query_prompt)\n",
    "\n",
    "#print('documents:', documents_sample)\n",
    "\n",
    "document_embeddings = model.encode_document(documents_sample)\n",
    "\n",
    "similarities = model.similarity(query_embedding, document_embeddings)\n",
    "most_similar_idx = similarities.argmax()\n",
    "most_relevant_document = documents_sample[most_similar_idx]\n",
    "print('################# RESULTS ###################')\n",
    "print('')\n",
    "print('statutory_language:', statutory_language)\n",
    "print('ambiguous_term:', ambiguous_term)\n",
    "print('year_enacted:', year_enacted)\n",
    "print('')\n",
    "print('query:', query)\n",
    "print('')\n",
    "print(\"Most relevant document:\")\n",
    "print(most_relevant_document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45777d",
   "metadata": {},
   "source": [
    "______________\n",
    "## ‚≠êÔ∏è Using `got3` for EmbeddingGemma on keywords from the COCA sample.\n",
    "\n",
    "- I still need to figure out how embedding most meaningfully fits into this process! I suspect I should be coding content in the title or something...\n",
    "- reviewing classic examples of 'bank' along with 'modify`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc30fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getout_of_text_3 as got3\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be5d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loading my_legal_corpus corpus from ../coca-samples-text/\n",
      "============================================================\n",
      "üìÇ Processing acad...\n",
      "  ‚úÖ text_acad.txt: (265, 1)\n",
      "üìÇ Processing blog...\n",
      "  ‚úÖ text_blog.txt: (991, 1)\n",
      "üìÇ Processing fic...\n",
      "  ‚úÖ text_fic.txt: (273, 1)\n",
      "üìÇ Processing mag...\n",
      "  ‚úÖ text_mag.txt: (948, 1)\n",
      "üìÇ Processing news...\n",
      "  ‚úÖ text_news.txt: (871, 1)\n",
      "üìÇ Processing spok...\n",
      "  ‚úÖ text_spok.txt: (263, 1)\n",
      "üìÇ Processing tvm...\n",
      "  ‚úÖ text_tvm.txt: (233, 1)\n",
      "üìÇ Processing web...\n",
      "  ‚úÖ text_web.txt: (892, 1)\n",
      "\n",
      "üéØ SUMMARY:\n",
      "   - my_legal_corpus: 8 genres loaded\n",
      "   - Total corpora in collection: 1\n"
     ]
    }
   ],
   "source": [
    "corpus_data = got3.read_corpora(\"../coca-samples-text/\", \"my_legal_corpus\")\n",
    "\n",
    "# 2. Search for legal terms with context\n",
    "results = got3.search_keyword_corpus(\n",
    "    keyword=\"modify\",\n",
    "    db_dict=corpus_data,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=10,\n",
    "    output=\"json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4be775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'modify': 70\n",
      "--------------------------------\n",
      "acad: 10 hits\n",
      "blog: 12 hits\n",
      "mag: 10 hits\n",
      "news: 19 hits\n",
      "spok: 3 hits\n",
      "tvm: 4 hits\n",
      "web: 12 hits\n"
     ]
    }
   ],
   "source": [
    "# how many hits across the genre keys\n",
    "total_hits = sum(len(v) for v in results.values())\n",
    "print(f\"Total hits for 'modify': {total_hits}\")\n",
    "# per key genre\n",
    "print('--------------------------------')\n",
    "for genre, hits in results.items():\n",
    "    print(f\"{genre}: {len(hits)} hits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615c2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take got3 json output and format as documents for embeddinggemma\n",
    "document_sample_keywords=[]\n",
    "for key in results:\n",
    "    genre_hits = list(results[key].values())\n",
    "    for snippet in genre_hits:\n",
    "        document_sample_keywords.append(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d74b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# RESULTS ###################\n",
      "\n",
      "statutory_language: The agency may modify the requirements as necessary to ensure compliance.\n",
      "ambiguous_term: modify\n",
      "year_enacted: 2001\n",
      "query_task: task: search result | query: What does modify mean in the following statement 'The agency may modify the requirements as necessary to ensure compliance.'?\n",
      "\n",
      "Most relevant document 64:\n",
      "standards : <p> Use existing Multi-Modal Level-of-Service indicators , and **modify** them to reflect the needs of a particular situation .\n",
      "\n",
      "All answers ranked:\n",
      "1. Document 64: 0.4391\n",
      "2. Document 14: 0.4290\n",
      "3. Document 63: 0.3993\n",
      "4. Document 32: 0.3931\n",
      "5. Document 51: 0.3845\n",
      "6. Document 0: 0.3808\n",
      "7. Document 33: 0.3708\n",
      "8. Document 15: 0.3556\n",
      "9. Document 21: 0.3455\n",
      "10. Document 12: 0.3437\n",
      "11. Document 41: 0.3424\n",
      "12. Document 55: 0.3407\n",
      "13. Document 16: 0.3378\n",
      "14. Document 28: 0.3358\n",
      "15. Document 20: 0.3344\n",
      "16. Document 19: 0.3330\n",
      "17. Document 34: 0.3261\n",
      "18. Document 13: 0.3251\n",
      "19. Document 65: 0.3240\n",
      "20. Document 42: 0.3233\n",
      "21. Document 50: 0.3211\n",
      "22. Document 24: 0.3207\n",
      "23. Document 17: 0.3177\n",
      "24. Document 8: 0.3169\n",
      "25. Document 4: 0.3161\n",
      "26. Document 43: 0.3142\n",
      "27. Document 67: 0.3135\n",
      "28. Document 18: 0.3067\n",
      "29. Document 35: 0.3067\n",
      "30. Document 36: 0.2985\n",
      "31. Document 58: 0.2945\n",
      "32. Document 44: 0.2938\n",
      "33. Document 29: 0.2929\n",
      "34. Document 11: 0.2906\n",
      "35. Document 1: 0.2901\n",
      "36. Document 68: 0.2887\n",
      "37. Document 38: 0.2876\n",
      "38. Document 25: 0.2870\n",
      "39. Document 31: 0.2849\n",
      "40. Document 53: 0.2783\n",
      "41. Document 66: 0.2781\n",
      "42. Document 47: 0.2776\n",
      "43. Document 52: 0.2756\n",
      "44. Document 54: 0.2745\n",
      "45. Document 37: 0.2745\n",
      "46. Document 39: 0.2704\n",
      "47. Document 5: 0.2678\n",
      "48. Document 62: 0.2673\n",
      "49. Document 45: 0.2665\n",
      "50. Document 6: 0.2650\n",
      "51. Document 9: 0.2539\n",
      "52. Document 27: 0.2523\n",
      "53. Document 26: 0.2518\n",
      "54. Document 56: 0.2514\n",
      "55. Document 30: 0.2512\n",
      "56. Document 57: 0.2452\n",
      "57. Document 40: 0.2438\n",
      "58. Document 60: 0.2419\n",
      "59. Document 61: 0.2360\n",
      "60. Document 23: 0.2335\n",
      "61. Document 10: 0.2334\n",
      "62. Document 46: 0.2312\n",
      "63. Document 69: 0.2254\n",
      "64. Document 22: 0.2125\n",
      "65. Document 3: 0.2044\n",
      "66. Document 59: 0.2008\n",
      "67. Document 7: 0.1983\n",
      "68. Document 2: 0.1607\n",
      "69. Document 48: 0.1366\n",
      "70. Document 49: 0.1237\n"
     ]
    }
   ],
   "source": [
    "statutory_language = \"The agency may modify the requirements as necessary to ensure compliance.\"\n",
    "ambiguous_term = \"modify\"\n",
    "year_enacted = 2001 # for historical reference, if you have a historical corpora \n",
    "#ambiguous_term = \"sufficient\" # the term which leads towards confusion or ambiguity\n",
    "query=\"What does {} mean in the following statement '{}'?\".format(ambiguous_term,statutory_language)\n",
    "#query = 'What is the ordinary meaning of the ambiguous term \"{}\" in the context of the following statutory language, \"{}\", enacted in the year {}?'.format(ambiguous_term,statutory_language,year_enacted)\n",
    "\n",
    "\n",
    "query_prompt = f\"task: search result | query: {query}\"\n",
    "query_embedding = model.encode_query(query_prompt)\n",
    "#print('documents:', document_sample_keywords)\n",
    "document_embeddings = model.encode_document(document_sample_keywords)\n",
    "similarities = model.similarity(query_embedding, document_embeddings)\n",
    "most_similar_idx = similarities.argmax()\n",
    "most_relevant_document = document_sample_keywords[most_similar_idx]\n",
    "\n",
    "print('################# RESULTS ###################')\n",
    "print('')\n",
    "print('statutory_language:', statutory_language)\n",
    "print('ambiguous_term:', ambiguous_term)\n",
    "print('year_enacted:', year_enacted)\n",
    "print('query_task:', query_prompt)\n",
    "print('')\n",
    "print(\"Most relevant document {}:\".format(most_similar_idx))\n",
    "print(most_relevant_document)\n",
    "print('')\n",
    "print('All answers ranked:')\n",
    "\n",
    "# similarities is a 2D tensor with shape [1, N], so we flatten it\n",
    "sim_values = similarities.flatten()\n",
    "for rank, idx in enumerate(sim_values.argsort(descending=True)):\n",
    "    print(f\"{rank+1}. Document {idx.item()}: {sim_values[idx].item():.4f}\")\n",
    "    #print(document_sample_keywords[idx.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f4523",
   "metadata": {},
   "source": [
    "### Using got3.embedding.gemma with search results\n",
    "\n",
    "Now we can use the new `got3.embedding.gemma.gemma()` function that accepts the JSON search results directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4de4c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Using pre-computed search results for 'bovine'\n",
      "üìö Found 5 context examples across 4 genres\n",
      "ü§ñ Loading model: google/embeddinggemma-300m\n",
      "\n",
      "üéØ RESULTS:\n",
      "\n",
      "Most relevant context from blog (score: 0.2334)\n",
      "Context: his mouth , I commented loudly on the quantity of **bovine** excrement spewing from it . \" That 's fucking bullshit\n",
      "\n",
      "üéØ Top 3 most relevant contexts:\n",
      "1. Genre: blog, Score: 0.2334\n",
      "   Context: his mouth , I commented loudly on the quantity of **bovine** excrement spewing from it . \" That 's f...\n",
      "\n",
      "2. Genre: blog, Score: 0.2244\n",
      "   Context: \" Brown told TheDC . <p> This is not merely **bovine** excrement , it 's delusional . Once you under...\n",
      "\n",
      "3. Genre: fic, Score: 0.2222\n",
      "   Context: his intelligence , and merely having to look at that **bovine** lump of clichs brought his blood to ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the new got3.embedding.gemma function with search results\n",
    "statutory_language = \"Establishing a system for the identification and registration of [MASK] animals and regarding the labelling of beef and beef products.\"\n",
    "ambiguous_term=\"bovine\"\n",
    "year_enacted = 2001 # for historical reference, if you have a historical corpora\n",
    "\n",
    "keyword_results = got3.search_keyword_corpus(\n",
    "    keyword=ambiguous_term,\n",
    "    db_dict=corpus_data,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=10,\n",
    "    output=\"json\"\n",
    ")\n",
    "\n",
    "\n",
    "result = got3.embedding.gemma.task(\n",
    "    statutory_language=statutory_language,\n",
    "    ambiguous_term=ambiguous_term,\n",
    "    year_enacted=year_enacted,\n",
    "    search_results=keyword_results, # Pass the JSON results from search_keyword_corpus\n",
    "    model=\"google/embeddinggemma-300m\"\n",
    ")\n",
    "print('')\n",
    "print(\"üéØ Top 3 most relevant contexts:\")\n",
    "for i, item in enumerate(result['all_ranked'][:3]):\n",
    "    print(f\"{i+1}. Genre: {item['genre']}, Score: {item['score']:.4f}\")\n",
    "    print(f\"   Context: {item['context'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd31f5a",
   "metadata": {},
   "source": [
    "_____________\n",
    "### Analysis of results\n",
    "\n",
    "#### Most Similar\n",
    "\n",
    "- In this case it is refering more directly to how a cow eats!\n",
    "- `...his mouth , I commented loudly on the quantity of **bovine** excrement spewing from it . \" That 's f...`\n",
    "\n",
    "#### Least Similar\n",
    "\n",
    "- In this case, it's using bovine as an adjective meaning dull or boring, not so much literally as a cow!\n",
    "- 1997 film L.A. Confidential. and that is a quote from the film: `...and merely having to look at that **bovine** lump of clichs brought his blood to...`\n",
    "  - ![https://a.ltrbxd.com/resized/sm/upload/3n/0w/ax/pt/rIXzJCAvyd3Ci8ipylDQ5wUKqwh-0-230-0-345-crop.jpg?v=40685f4e4e](https://a.ltrbxd.com/resized/sm/upload/3n/0w/ax/pt/rIXzJCAvyd3Ci8ipylDQ5wUKqwh-0-230-0-345-crop.jpg?v=40685f4e4e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
