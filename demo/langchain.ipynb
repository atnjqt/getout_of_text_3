{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2282fd",
   "metadata": {},
   "source": [
    "## Langchain Demo: AI Agents on AWS Bedrock\n",
    "\n",
    "- thinking about an agent AI that integrates with the toolset\n",
    "- see the reference documentation here: https://python.langchain.com/docs/tutorials/agents/\n",
    "- in this case, using AWS Bedrock for DeepSeek model access using my named profile in `~/.aws/credentials` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd30d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your AWS credentials are configured\n",
    "import langchain\n",
    "from langchain.chat_models import init_chat_model\n",
    "import pandas as pd\n",
    "import getout_of_text_3 as got3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc07369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id='us.deepseek.r1-v1:0' # does not work with tools implementation\n",
    "model_id='openai.gpt-oss-120b-1:0'\n",
    "max_tokens=128000 # for openai.gpt-oss-120b-1:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d5ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model_id, \n",
    "                        model_provider=\"bedrock_converse\",\n",
    "                        credentials_profile_name='atn-developer',\n",
    "                        max_tokens='128000' # maximum for bedrock converse\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d95f8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Portugal is **Lisbon**.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hi! What is the capital of Portugal?\"\n",
    "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "response.text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f7429",
   "metadata": {},
   "source": [
    "## DIY SCOTUS Corpus Query Tool & Example\n",
    "\n",
    "- Using `got3` to filter on keywords in a DIY SCOTUS Corpus, via extracting text in PDFs downloaded from **Library of Congress** collection on the [United States Reports](https://www.loc.gov/collections/united-states-reports/).\n",
    "- Corpus is stored as a **dictionary** of **dataframes**, where each key is a **volume number** and each dataframe contains the cases in that volume.\n",
    "    - the `case_id` is a concatenated volume and page number (i.e. `329001` is volume 329, page 1). This is also a schema for saving PDF downloads locally. See details at [the U.S. Report page](https://www.supremecourt.gov/opinions/USReports.aspx).\n",
    "\n",
    "        ```json\n",
    "        {\"329\": {DataFrame}, \n",
    "        \"330\": {DataFrame}, ..., \n",
    "        \"570\": {DataFrame}\n",
    "        }\n",
    "        ```\n",
    "        ```text\n",
    "        case_id\ttext\n",
    "        0\t570729\tOCTOBER \\nTERM, 2012 \\n729 \\nSyllabus \\nSEKHAR...\n",
    "        1\t570338\t338 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nUNIVER...\n",
    "        2\t570099\tOCTOBER \\nTERM, 2012 \\n99 \\nSyllabus \\nALLEYNE...\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36df068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pdf scotus files\n",
    "df = pd.read_json(\"loc_gov.json\", lines=True)\n",
    "\n",
    "df['key'] = df['filename'].apply(lambda x: x.split('usrep')[1][:3])\n",
    "df['subkey'] = df['filename'].apply(lambda x: x.split('usrep')[1].split('.pdf')[0])\n",
    "\n",
    "# Create a dictionary to hold the DataFrame contents\n",
    "df_dict = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if row['key'] not in df_dict:\n",
    "        df_dict[row['key']] = {}\n",
    "    df_dict[row['key']][row['subkey']] = row['content']\n",
    "\n",
    "# format scotus data for getout_of_text_3, similar to COCA keyword results\n",
    "db_dict_formatted = {}\n",
    "for volume, cases in df_dict.items():\n",
    "    # Create a DataFrame for each volume with case text\n",
    "    case_data = []\n",
    "    for case_id, case_text in cases.items():\n",
    "        case_data.append({'case_id': case_id, 'text': case_text})\n",
    "    db_dict_formatted[volume] = pd.DataFrame(case_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60d6a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(db_dict_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9688caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOLUMES 329 - 570\n"
     ]
    }
   ],
   "source": [
    "# PRINT LOWEST AND HIGHEST VOLUME NUMBERS\n",
    "sorted_keys = sorted(db_dict_formatted.keys(), key=lambda x: int(x), reverse=False)\n",
    "print('VOLUMES', sorted_keys[0], '-', sorted_keys[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbae1f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570729</td>\n",
       "      <td>OCTOBER \\nTERM, 2012 \\n729 \\nSyllabus \\nSEKHAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570338</td>\n",
       "      <td>338 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nUNIVER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570099</td>\n",
       "      <td>OCTOBER \\nTERM, 2012 \\n99 \\nSyllabus \\nALLEYNE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570529</td>\n",
       "      <td>OCTOBER \\nTERM, 2012 \\n529 \\nSyllabus \\nSHELBY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570048</td>\n",
       "      <td>48 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nMARACIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id                                               text\n",
       "0  570729  OCTOBER \\nTERM, 2012 \\n729 \\nSyllabus \\nSEKHAR...\n",
       "1  570338  338 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nUNIVER...\n",
       "2  570099  OCTOBER \\nTERM, 2012 \\n99 \\nSyllabus \\nALLEYNE...\n",
       "3  570529  OCTOBER \\nTERM, 2012 \\n529 \\nSyllabus \\nSHELBY...\n",
       "4  570048  48 \\nOCTOBER \\nTERM, 2012 \\nSyllabus \\nMARACIC..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_keys = sorted(db_dict_formatted.keys(), key=lambda x: int(x), reverse=False)\n",
    "print(sorted_keys)\n",
    "db_dict_formatted['570'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1087ed2",
   "metadata": {},
   "source": [
    "## SCOTUS Analysis Tools (LangChain + `getout_of_text_3`)\n",
    "\n",
    "This section documents two complementary LangChain Tool implementations for exploratory forensic / statutory‐interpretation analysis over a locally prepared SCOTUS corpus.\n",
    "\n",
    "### 1. Purpose\n",
    "You can (a) execute an on‑the‑fly keyword search + AI analysis, or (b) feed in *already filtered* JSON results for reproducible, cost‑controlled, deterministic re‑analysis with AI tools. This is for exploratory and demonstrative purposes only; do **NOT** rely on these tools for authoritative legal research or advice.\n",
    "\n",
    "### 2. Tool Inventory\n",
    "| Tool Name | Class | Performs Corpus Search? | Input Content Source | Best For | Cost / Token Control | Notes |\n",
    "|-----------|-------|-------------------------|----------------------|----------|----------------------|-------|\n",
    "| `scotus_analysis` | `ScotusAnalysisTool` | YES (internal `got3.search_keyword_corpus`) | Raw SCOTUS corpus dict (`db_dict_formatted`) | Quick ad‑hoc exploration, first look | Lower control (dynamic result size) | Returns free‑form model text. Not suited for strict reproducibility. |\n",
    "| `scotus_filtered_analysis` | `ScotusFilteredAnalysisTool` | NO (analysis only) | Pre‑filtered JSON (already produced elsewhere) | Stable reports, batching, auditing, caching | High control (you decide slice + cap contexts) | Optional structured JSON output (`return_json=True`). |\n",
    "\n",
    "### 3. Input Schemas (Pydantic)\n",
    "1. `ScotusAnalysisInput`:\n",
    "   - `keyword: str` – term/phrase to search.\n",
    "   - `analysis_focus: str = 'general'` – one of: `general`, `evolution`, `judicial_philosophy`, `custom`.\n",
    "2. `ScotusFilteredAnalysisInput`:\n",
    "   - `keyword: str` – label only (no searching performed).\n",
    "   - `results_json: str | dict` – JSON/dict from a *previous* `got3.search_keyword_corpus` call (after any manual filtering).\n",
    "   - `analysis_focus: str = 'general'` – same options as above.\n",
    "   - `max_contexts: int = 60` – hard cap on sampled context snippets injected into the prompt (prevents runaway token bills).\n",
    "   - `return_json: bool = False` – if `True` the prompt instructs the model to emit **strict JSON** (post‑validated / auto‑repaired if malformed).\n",
    "\n",
    "### 4. Typical Workflow Patterns\n",
    "| Scenario | Recommended Flow |\n",
    "|----------|------------------|\n",
    "| Rapid hypothesis check | Use `scotus_analysis` with a single keyword, review summary. |\n",
    "| Iterative refinement / human curation | Run raw search once, manually prune / cluster results, then pass curated JSON to `scotus_filtered_analysis`. |\n",
    "| Batch reporting (multiple keywords) | Precompute & persist each keyword’s JSON → loop over `scotus_filtered_analysis` with `return_json=True`. |\n",
    "| Cost‑sensitive environment | Always pre‑filter & throttle with `max_contexts` (e.g. 40–80). |\n",
    "| Need structured downstream ingestion | Use `return_json=True` and parse validated keys (`reasoning_content`, `summary`, etc.). |\n",
    "\n",
    "### 5. Prompt Design Overview\n",
    "Both tools:\n",
    "- Enforce an “ONLY use supplied contexts” constraint (mitigates hallucination beyond current slice).\n",
    "- Provide distribution metadata (volumes, counts, occurrence sample) to steer higher‑level synthesis.\n",
    "- Offer `analysis_focus` to narrow stylistic / topical emphasis.\n",
    "\n",
    "`scotus_analysis` additionally:\n",
    "- Embeds a truncated JSON of search hits (first N characters) directly after retrieval.\n",
    "\n",
    "`scotus_filtered_analysis` adds:\n",
    "- Multi‑shape normalization for result structures: strings, lists, objects with `context`/`text` fields.\n",
    "- Safe context sampling + length clipping (`[:240]` chars each) to control token pressure.\n",
    "- Optional strict JSON response contract.\n",
    "\n",
    "### 6. Output Shapes\n",
    "| Mode | Example (abridged) |\n",
    "|------|--------------------|\n",
    "| `scotus_analysis` (text) | \"Usage Summary... Contextual Patterns...\" |\n",
    "| `scotus_filtered_analysis` (`return_json=False`) | Same narrative section headings as above. |\n",
    "| `scotus_filtered_analysis` (`return_json=True`) | `{ \"keyword\": \"ordinary meaning\", \"total_contexts\": 217, \"occurrences_summary\": \"217 snippet(s)...\", \"reasoning_content\": [\"...\"], \"summary\": \"...\", \"limitations\": \"...\" }` |\n",
    "\n",
    "### 7. Reliability & Error Handling\n",
    "- Async safety: attempts event‑loop reuse; falls back to sync if needed.\n",
    "- JSON robustness: if model returns malformed JSON, a salvage regex pass wraps content into a valid fallback structure.\n",
    "- Single‑occurrence safeguard: explicitly flags low‑evidence situations (e.g., only 1 context) to prevent over‑extrapolation.\n",
    "\n",
    "### 8. Performance & Cost Notes\n",
    "| Driver | Effect | Mitigation |\n",
    "|--------|--------|------------|\n",
    "| Large keyword result sets | Longer prompt → higher tokens | Pre‑filter & lower `max_contexts` |\n",
    "| Very common terms (e.g., \"the\", functional words) | Noise / inflated contexts | Encourage user to refine / phrase search |\n",
    "| High `max_contexts` + JSON mode | Larger instructions + response | Tune to 30–80; rarely need >100 contexts |\n",
    "| Duplicate or near‑duplicate contexts | Redundant token usage | Consider de‑dupe preprocessing before passing JSON |\n",
    "\n",
    "### 9. When NOT to Use These Tools\n",
    "- You need full‑text semantic retrieval (vector / embedding) across the corpus → integrate an embedding + retriever pipeline instead.\n",
    "- You require authoritative legal interpretation beyond provided snippets → domain attorney review required.\n",
    "- You want cross‑corpus comparative linguistics (e.g., COCA vs SCOTUS) in one call → design a composite prompt / multi‑tool pipeline.\n",
    "\n",
    "### 10. Minimal Usage Examples\n",
    "Live search (exploratory):\n",
    "```python\n",
    "result_text = scotus_tool._run(keyword=\"textualism\", analysis_focus=\"judicial_philosophy\")\n",
    "print(result_text[:800])\n",
    "```\n",
    "Pre‑filtered (deterministic):\n",
    "```python\n",
    "raw_results = got3.search_keyword_corpus(\n",
    "    keyword=\"ordinary meaning\",\n",
    "    db_dict=db_dict_formatted,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=30,\n",
    "    output=\"json\"\n",
    ")\n",
    "filtered = {k: v for k, v in raw_results.items() if v}  # prune empties\n",
    "json_str = json.dumps(filtered)\n",
    "analysis = filtered_scotus_tool._run(\n",
    "    keyword=\"ordinary meaning\",\n",
    "    results_json=json_str,\n",
    "    analysis_focus=\"general\",\n",
    "    max_contexts=50,\n",
    "    return_json=True\n",
    ")\n",
    "analysis[\"summary\"][:500]\n",
    "```\n",
    "\n",
    "### 11. Interpreting Structured JSON (Key Semantics)\n",
    "| Key | Meaning | Typical Consumer Action |\n",
    "|-----|---------|-------------------------|\n",
    "| `keyword` | Echo label for downstream grouping | Index in dataframe / vector store |\n",
    "| `total_contexts` | Sampled context count (post‑cap) | Assess evidence density |\n",
    "| `occurrences_summary` | Human‑readable distribution summary | Display directly in UI |\n",
    "| `reasoning_content` | Stepwise internal analysis (chain‑of‑thought lite) | Optional trust / audit pane |\n",
    "| `summary` | Main synthesized narrative | Persist / compare across keywords |\n",
    "| `limitations` | Self‑reported caveats (and JSON salvage note if any) | Flag for review / quality scoring |\n",
    "\n",
    "### 12. Extension Ideas (Future Work)\n",
    "- Add semantic clustering (MiniLM embeddings) before sampling to maximize diversity.\n",
    "- Integrate rate limiting & token accounting dashboards.\n",
    "- Provide a deterministic hash of the input JSON slice for reproducibility tracking.\n",
    "- Optional KWIC alignment / colorized keyword highlighting inside samples.\n",
    "\n",
    "### 13. Quick Decision Guide\n",
    "> If you can already see and trust the filtered JSON you want analyzed, **use `scotus_filtered_analysis`**. Otherwise, start with `scotus_analysis` to discover whether the keyword is even worth a curated run.\n",
    "\n",
    "---\n",
    "**Reminder:** Both tools operate strictly over *your supplied corpus slice*. They intentionally do **NOT** fetch external case law or enrich with outside doctrinal knowledge. This keeps analyses auditable and grounded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a5e48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, Type, Dict, Any, Union\n",
    "import json\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "# ============================================================================\n",
    "# ORIGINAL live-search tool (kept for reference but description warns users)\n",
    "# ============================================================================\n",
    "class ScotusAnalysisInput(BaseModel):\n",
    "    \"\"\"Input for SCOTUS case analysis tool (performs a fresh keyword search).\"\"\"\n",
    "    keyword: str = Field(description=\"The keyword to search for and analyze in SCOTUS cases\")\n",
    "    analysis_focus: Optional[str] = Field(\n",
    "        default=\"general\", \n",
    "        description=\"Focus of analysis: 'general', 'evolution', 'judicial_philosophy', or 'custom'\"\n",
    "    )\n",
    "\n",
    "class ScotusAnalysisTool(BaseTool):\n",
    "    \"\"\"Tool that SEARCHES the SCOTUS corpus then analyzes.\n",
    "    NOTE: For pre-filtered JSON results, use ScotusFilteredAnalysisTool instead.\n",
    "    \"\"\"\n",
    "    name: str = \"scotus_analysis\"\n",
    "    description: str = (\n",
    "        \"Analyzes SCOTUS cases for a given keyword after performing an internal search. \"\n",
    "        \"Do NOT provide pre-filtered results to this tool.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ScotusAnalysisInput\n",
    "    model: Any = Field(exclude=True)\n",
    "    db_dict_formatted: Any = Field(exclude=True)\n",
    "    \n",
    "    def __init__(self, model, db_dict_formatted, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "        self.db_dict_formatted = db_dict_formatted\n",
    "    \n",
    "    def _run(self, keyword: str, analysis_focus: str = \"general\") -> str:  # noqa: D401\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "                return asyncio.run(self._arun(keyword, analysis_focus))\n",
    "        except Exception:\n",
    "            pass\n",
    "        return self._sync_run(keyword, analysis_focus)\n",
    "    \n",
    "    def _sync_run(self, keyword: str, analysis_focus: str = \"general\") -> str:\n",
    "        try:\n",
    "            print(f\"🔍 TOOL(search): Searching SCOTUS database for keyword: '{keyword}'\")\n",
    "            import getout_of_text_3 as got3\n",
    "            search_results = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=self.db_dict_formatted,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output=\"json\"\n",
    "            )\n",
    "            results_dict = {k: v for k, v in sorted(search_results.items(), key=lambda item: int(item[0])) if v}\n",
    "            if not results_dict:\n",
    "                return f\"No results found for keyword '{keyword}' in the SCOTUS database.\"\n",
    "            total_cases = sum(len(cases) for cases in results_dict.values())\n",
    "            volumes = list(results_dict.keys())\n",
    "            print(f\"📊 TOOL(search): Found {total_cases} cases across {len(volumes)} volumes\")\n",
    "            prompt = self._build_prompt(results_dict, keyword, analysis_focus, volumes, total_cases)\n",
    "            print(f\"🤖 TOOL(search): Sending {len(prompt)} characters to AI model for analysis\")\n",
    "            if len(prompt) > max_tokens:\n",
    "                print(\"⚠️ TOOL(search): Prompt exceeds {} characters, which may cause issues with some models.\".format(max_tokens))\n",
    "            response = self.model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "            print(f\"✅ TOOL(search): Analysis complete, returning {len(getattr(response,'content', str(response)))} characters\")\n",
    "            return getattr(response, 'content', str(response))\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error analyzing SCOTUS results: {str(e)}\"\n",
    "            print(f\"❌ TOOL(search): {error_msg}\")\n",
    "            return error_msg\n",
    "\n",
    "    async def _arun(self, keyword: str, analysis_focus: str = \"general\") -> str:\n",
    "        try:\n",
    "            print(f\"🔍 TOOL(search-async): Searching SCOTUS database for keyword: '{keyword}'\")\n",
    "            import getout_of_text_3 as got3\n",
    "            search_results = got3.search_keyword_corpus(\n",
    "                keyword=keyword,\n",
    "                db_dict=self.db_dict_formatted,\n",
    "                case_sensitive=False,\n",
    "                show_context=True,\n",
    "                context_words=20,\n",
    "                output=\"json\"\n",
    "            )\n",
    "            results_dict = {k: v for k, v in sorted(search_results.items(), key=lambda item: int(item[0])) if v}\n",
    "            if not results_dict:\n",
    "                return f\"No results found for keyword '{keyword}' in the SCOTUS database.\"\n",
    "            total_cases = sum(len(cases) for cases in results_dict.values())\n",
    "            volumes = list(results_dict.keys())\n",
    "            print(f\"📊 TOOL(search-async): Found {total_cases} cases across {len(volumes)} volumes\")\n",
    "            prompt = self._build_prompt(results_dict, keyword, analysis_focus, volumes, total_cases)\n",
    "            print(f\"🤖 TOOL(search-async): Sending {len(prompt)} characters to AI model for analysis\")\n",
    "            if len(prompt) > max_tokens:\n",
    "                print(\"⚠️ TOOL(search): Prompt exceeds {} characters, which may cause issues with some models.\".format(max_tokens))\n",
    "                prompt = prompt[:max_tokens]\n",
    "                print(f\"🤖 TOOL(search-async): Truncated prompt to {len(prompt)} characters\")\n",
    "            response = await self.model.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "            print(f\"✅ TOOL(search-async): Analysis complete, returning {len(getattr(response,'content', str(response)))} characters\")\n",
    "            return getattr(response, 'content', str(response))\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error analyzing SCOTUS results: {str(e)}\"\n",
    "            print(f\"❌ TOOL(search-async): {error_msg}\")\n",
    "            return error_msg\n",
    "\n",
    "    def _build_prompt(self, results_dict, keyword, analysis_focus, volumes, total_cases) -> str:\n",
    "        analysis_prompts = {\n",
    "            \"general\": f\"\"\"\n",
    "            Instructions:\n",
    "            You are an AI Agent inside the open-source forensic linguistic tool `getout_of_text_3`.\n",
    "            Analyze these SCOTUS case search results for the keyword \\\"{keyword}\\\" ONLY using the provided data.\n",
    "            Data summary:\n",
    "            - Volumes: {', '.join(sorted(volumes, key=int))}\n",
    "            - Total case occurrences: {total_cases}\n",
    "            Provide insights on:\n",
    "            1. Temporal evolution\n",
    "            2. Contextual variation\n",
    "            3. Notable intra-dataset patterns (do NOT import outside knowledge)\n",
    "            4. Interpretive themes relevant to ordinary meaning\n",
    "            Results (truncated JSON): {json.dumps(results_dict, indent=2)}...\n",
    "            \"\"\",\n",
    "            \"evolution\": f\"Focus on change over volumes for '{keyword}'.\\nData: {json.dumps(results_dict, indent=2)}...\",\n",
    "            \"judicial_philosophy\": f\"Assess patterns of usage that may hint at differing interpretive approaches for '{keyword}'. Use ONLY provided texts. Data: {json.dumps(results_dict, indent=2)}...\",\n",
    "            \"custom\": f\"Comprehensive analysis for '{keyword}'. Use ONLY provided dataset. Data: {json.dumps(results_dict, indent=2)}...\"\n",
    "        }\n",
    "\n",
    "        return analysis_prompts.get(analysis_focus, analysis_prompts[\"general\"]).strip()\n",
    "\n",
    "# ============================================================================\n",
    "# NEW: Pre-filtered JSON analysis tool (does NOT perform search)\n",
    "# ============================================================================\n",
    "class ScotusFilteredAnalysisInput(BaseModel):\n",
    "    \"\"\"Input for analyzing an already-filtered SCOTUS keyword JSON result set.\"\"\"\n",
    "    keyword: str = Field(description=\"Keyword being analyzed (for labeling only, not for searching).\")\n",
    "    results_json: Union[str, Dict[str, Any]] = Field(\n",
    "        description=\"Pre-filtered JSON (or dict) output from got3.search_keyword_corpus AFTER user filtering.\"\n",
    "    )\n",
    "    analysis_focus: Optional[str] = Field(\n",
    "        default=\"general\", description=\"'general', 'evolution', 'judicial_philosophy', or 'custom'\"\n",
    "    )\n",
    "    max_contexts: int = Field(\n",
    "        default=60, description=\"Max number of context snippets to sample for prompt (avoid overruns).\"\n",
    "    )\n",
    "    return_json: bool = Field(\n",
    "        default=False, description=\"If True, attempt to return structured JSON with reasoning_content, summary, etc.\"\n",
    "    )\n",
    "\n",
    "class ScotusFilteredAnalysisTool(BaseTool):\n",
    "    \"\"\"Analyze ONLY the supplied pre-filtered SCOTUS keyword result JSON.\n",
    "\n",
    "    IMPORTANT CONSTRAINTS:\n",
    "    - MUST NOT perform new searches.\n",
    "    - MUST NOT reference or speculate about cases outside the provided JSON.\n",
    "    - All observations must derive strictly from the given result set.\n",
    "    Supports flexible input structures, including:\n",
    "      {volume: {case_id: context_string}}\n",
    "      {volume: {case_id: [context_string, ...]}}\n",
    "      {volume: {case_id: [ {\"context\": str}, {\"context\": str} ] }}\n",
    "    When return_json=True, the model is instructed to emit valid JSON.\n",
    "    \"\"\"\n",
    "    name: str = \"scotus_filtered_analysis\"\n",
    "    description: str = (\n",
    "        \"Analyzes pre-filtered SCOTUS keyword search JSON (from got3) without performing any new retrieval.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ScotusFilteredAnalysisInput\n",
    "    model: Any = Field(exclude=True)\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    # --------------- Normalization helper ---------------\n",
    "    def _normalize_model_content(self, raw: Any) -> str:\n",
    "        \"\"\"Convert diverse model.content shapes (list/dict/blocks) into a plain string.\"\"\"\n",
    "        if isinstance(raw, str):\n",
    "            return raw\n",
    "        if isinstance(raw, list):\n",
    "            parts = []\n",
    "            for block in raw:\n",
    "                if isinstance(block, str):\n",
    "                    parts.append(block)\n",
    "                elif isinstance(block, dict):\n",
    "                    # Common text keys\n",
    "                    for key in (\"text\", \"content\", \"value\", \"message\"):\n",
    "                        val = block.get(key)\n",
    "                        if isinstance(val, str):\n",
    "                            parts.append(val)\n",
    "                            break\n",
    "                    else:\n",
    "                        parts.append(str(block))\n",
    "                else:\n",
    "                    parts.append(str(block))\n",
    "            return \"\\n\".join(parts)\n",
    "        if isinstance(raw, dict):\n",
    "            # Try typical key\n",
    "            for key in (\"text\", \"content\", \"value\"):\n",
    "                if key in raw and isinstance(raw[key], str):\n",
    "                    return raw[key]\n",
    "            return json.dumps(raw)\n",
    "        # Fallback\n",
    "        return str(raw)\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"general\",\n",
    "        max_contexts: int = 60,\n",
    "        return_json: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "                return asyncio.run(\n",
    "                    self._arun(keyword=keyword, results_json=results_json, analysis_focus=analysis_focus, max_contexts=max_contexts, return_json=return_json)\n",
    "                )\n",
    "        except Exception:\n",
    "            pass\n",
    "        return self._sync_run(keyword, results_json, analysis_focus, max_contexts, return_json)\n",
    "\n",
    "    def _sync_run(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"general\",\n",
    "        max_contexts: int = 60,\n",
    "        return_json: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        try:\n",
    "            results_dict = self._coerce_results(results_json)\n",
    "            stats = self._compute_stats(results_dict, keyword)\n",
    "            prompt = self._build_prompt(keyword, results_dict, stats, analysis_focus, max_contexts, return_json)\n",
    "            print(f\"🤖 TOOL(filtered): Sending {len(prompt)} chars to model (contexts: {stats['total_contexts']}) | return_json={return_json}\")\n",
    "            response = self.model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "            # Normalize content early\n",
    "            raw = getattr(response, 'content', None)\n",
    "            if raw is None and hasattr(response, 'text'):\n",
    "                try:\n",
    "                    raw = response.text()\n",
    "                except Exception:\n",
    "                    raw = response.text\n",
    "            content = self._normalize_model_content(raw)\n",
    "            if return_json:\n",
    "                return self._postprocess_json(content, results_dict, stats)\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            msg = f\"Error (filtered analysis): {e}\"\n",
    "            print(msg)\n",
    "            return {\"error\": msg} if return_json else msg\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_json: Union[str, Dict[str, Any]],\n",
    "        analysis_focus: str = \"general\",\n",
    "        max_contexts: int = 60,\n",
    "        return_json: bool = False,\n",
    "    ) -> Union[str, Dict[str, Any]]:\n",
    "        try:\n",
    "            results_dict = self._coerce_results(results_json)\n",
    "            stats = self._compute_stats(results_dict, keyword)\n",
    "            prompt = self._build_prompt(keyword, results_dict, stats, analysis_focus, max_contexts, return_json)\n",
    "            print(f\"🤖 TOOL(filtered-async): Sending {len(prompt)} chars to model (contexts: {stats['total_contexts']}) | return_json={return_json}\")\n",
    "            response = await self.model.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "            raw = getattr(response, 'content', None)\n",
    "            if raw is None and hasattr(response, 'text'):\n",
    "                try:\n",
    "                    raw = response.text()\n",
    "                except Exception:\n",
    "                    raw = response.text\n",
    "            content = self._normalize_model_content(raw)\n",
    "            if return_json:\n",
    "                return self._postprocess_json(content, results_dict, stats)\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            msg = f\"Error (filtered analysis async): {e}\"\n",
    "            print(msg)\n",
    "            return {\"error\": msg} if return_json else msg\n",
    "\n",
    "    # ---------------- Internal helpers ----------------\n",
    "    def _coerce_results(self, results_json: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        if isinstance(results_json, str):\n",
    "            results_dict = json.loads(results_json)\n",
    "        else:\n",
    "            results_dict = results_json\n",
    "        if not isinstance(results_dict, dict) or not results_dict:\n",
    "            raise ValueError(\"results_json must be a non-empty dict or JSON string\")\n",
    "        return results_dict\n",
    "\n",
    "    def _extract_contexts_from_case(self, occs) -> list:\n",
    "        \"\"\"Return list of context strings from flexible case structures.\"\"\"\n",
    "        contexts = []\n",
    "        if isinstance(occs, str):\n",
    "            contexts.append(occs)\n",
    "        elif isinstance(occs, dict):\n",
    "            for k in (\"context\", \"text\", \"snippet\", \"kwic\"):\n",
    "                if k in occs and isinstance(occs[k], str):\n",
    "                    contexts.append(occs[k])\n",
    "                    break\n",
    "        elif isinstance(occs, list):\n",
    "            for o in occs:\n",
    "                contexts.extend(self._extract_contexts_from_case(o))\n",
    "        return contexts\n",
    "\n",
    "    def _compute_stats(self, results_dict: Dict[str, Any], keyword: str) -> Dict[str, Any]:\n",
    "        volumes = sorted(results_dict.keys(), key=lambda x: int(x) if str(x).isdigit() else str(x))\n",
    "        case_counts = {}\n",
    "        total_contexts = 0\n",
    "        occurrences_per_case = []\n",
    "        for vol, cases in results_dict.items():\n",
    "            if not isinstance(cases, dict):\n",
    "                continue\n",
    "            case_counts[vol] = len(cases)\n",
    "            for case_id, occs in cases.items():\n",
    "                contexts = self._extract_contexts_from_case(occs)\n",
    "                occ_count = len(contexts)\n",
    "                total_contexts += occ_count\n",
    "                occurrences_per_case.append({\"volume\": vol, \"case_id\": case_id, \"occurrences\": occ_count})\n",
    "        return {\n",
    "            \"volumes\": volumes,\n",
    "            \"case_counts\": case_counts,\n",
    "            \"total_cases\": sum(case_counts.values()),\n",
    "            \"total_contexts\": total_contexts,\n",
    "            \"occurrences_per_case\": occurrences_per_case,\n",
    "            \"keyword\": keyword,\n",
    "        }\n",
    "\n",
    "    def _sample_contexts(self, results_dict: Dict[str, Any], max_contexts: int) -> list:\n",
    "        samples = []\n",
    "        for vol in sorted(results_dict.keys(), key=lambda x: int(x) if str(x).isdigit() else str(x)):\n",
    "            cases = results_dict[vol]\n",
    "            if not isinstance(cases, dict):\n",
    "                continue\n",
    "            for case_id, occs in cases.items():\n",
    "                contexts = self._extract_contexts_from_case(occs)\n",
    "                for ctx in contexts:\n",
    "                    cleaned = \" \".join(ctx.split())[:240]\n",
    "                    samples.append(f\"[{vol}:{case_id}] {cleaned}\")\n",
    "                    if len(samples) >= max_contexts:\n",
    "                        return samples\n",
    "        return samples\n",
    "\n",
    "    def _build_prompt(\n",
    "        self,\n",
    "        keyword: str,\n",
    "        results_dict: Dict[str, Any],\n",
    "        stats: Dict[str, Any],\n",
    "        analysis_focus: str,\n",
    "        max_contexts: int,\n",
    "        return_json: bool,\n",
    "    ) -> str:\n",
    "        sample_contexts = self._sample_contexts(results_dict, max_contexts)\n",
    "        focus_instructions = {\n",
    "            \"general\": \"Provide an overview of usage patterns, semantic ranges, and any interpretive variability.\",\n",
    "            \"evolution\": \"Describe shifts across volumes (treat volume ordering as temporal proxy if applicable).\",\n",
    "            \"judicial_philosophy\": \"Identify internal patterns that might hint at differing interpretive strategies (ONLY within provided data).\",\n",
    "            \"custom\": \"Provide a comprehensive structured analysis (frequency, contextual clusters, potential senses).\",\n",
    "        }\n",
    "        occ_lines = sorted(\n",
    "            [f\"{o['volume']}:{o['case_id']}={o['occurrences']}\" for o in stats[\"occurrences_per_case\"]],\n",
    "            key=lambda x: x\n",
    "        )[:80]\n",
    "        if not sample_contexts:\n",
    "            sample_contexts = [\"(No context strings extracted — verify input JSON structure)\"]\n",
    "        base = f\"\"\"\n",
    "            You are an AI analysis component of `getout_of_text_3`.\n",
    "            STRICT RULE: Use ONLY the provided JSON contexts. DO NOT introduce external cases, doctrines, or speculative references.\n",
    "            Keyword: \"{keyword}\"\n",
    "            Volumes: {', '.join(stats['volumes'])}\n",
    "            Total Cases: {stats['total_cases']} | Total Context Snippets: {stats['total_contexts']}\n",
    "            Occurrences Per Case (sample): {'; '.join(occ_lines)}\n",
    "            Analysis Focus: {analysis_focus} → {focus_instructions.get(analysis_focus, focus_instructions['general'])}\n",
    "            Sample Contexts ({len(sample_contexts)}):\n",
    "            ---\n",
    "            \"\"\" + \"\\n\".join(sample_contexts) + \"\\n---\\n\"\n",
    "        if return_json:\n",
    "            base += (\n",
    "                \"Return ONLY valid JSON with this exact top-level structure (no extra prose):\\n\"\n",
    "                \"{\\n\"\n",
    "                \"  \\\"keyword\\\": string,\\n\"\n",
    "                \"  \\\"total_contexts\\\": number,\\n\"\n",
    "                \"  \\\"occurrences_summary\\\": string,\\n\"\n",
    "                \"  \\\"reasoning_content\\\": [string, ...],\\n\"\n",
    "                \"  \\\"summary\\\": string,\\n\"\n",
    "                \"  \\\"limitations\\\": string\\n\"\n",
    "                \"}\\n\"\n",
    "                \"Populate reasoning_content with a short step-by-step (3-6 bullets).\\n\"\n",
    "                \"If only one occurrence, reasoning_content should note insufficient data for variation.\"\n",
    "            )\n",
    "        else:\n",
    "            base += (\n",
    "                \"Required Output Sections:\\n1. Usage Summary\\n2. Contextual Patterns / Proto-senses\\n3. Frequency & Distribution Observations\\n4. Interpretability Notes (ordinary meaning indicators)\\n5. Open Questions / Ambiguities\\nGround all claims ONLY in the contexts above.\"\n",
    "            )\n",
    "        if stats['total_contexts'] == 1:\n",
    "            base += \"\\nNOTE: Only one occurrence detected.\"\n",
    "        return base.strip()\n",
    "\n",
    "    def _postprocess_json(self, content: str, results_dict: Dict[str, Any], stats: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Try direct parse\n",
    "        parsed = None\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "        except Exception:\n",
    "            # Attempt to extract JSON substring\n",
    "            if isinstance(content, str):\n",
    "                match = re.search(r'{[\\s\\S]*}', content)\n",
    "                if match:\n",
    "                    try:\n",
    "                        parsed = json.loads(match.group(0))\n",
    "                    except Exception:\n",
    "                        parsed = None\n",
    "        if not isinstance(parsed, dict):\n",
    "            parsed = {\n",
    "                \"keyword\": stats['keyword'],\n",
    "                \"total_contexts\": stats['total_contexts'],\n",
    "                \"occurrences_summary\": f\"{stats['total_contexts']} context snippet(s) across {stats['total_cases']} case(s)\",\n",
    "                \"reasoning_content\": [\n",
    "                    \"Model did not return valid JSON; wrapped raw text.\",\n",
    "                    \"Single occurrence limits distributional inference.\" if stats['total_contexts']==1 else \"Multiple contexts allow limited comparative analysis.\"\n",
    "                ],\n",
    "                \"summary\": content[:4000] if isinstance(content, str) else str(content)[:4000],\n",
    "                \"limitations\": \"Auto-wrapped due to invalid JSON from model.\"\n",
    "            }\n",
    "        # Ensure required keys\n",
    "        for k, default in [\n",
    "            (\"reasoning_content\", []),\n",
    "            (\"summary\", \"\"),\n",
    "            (\"occurrences_summary\", f\"{stats['total_contexts']} snippet(s) across {stats['total_cases']} case(s)\"),\n",
    "            (\"limitations\", \"\")\n",
    "        ]:\n",
    "            if k not in parsed:\n",
    "                parsed[k] = default\n",
    "        return parsed\n",
    "\n",
    "# Helper: format result so reasoning_content appears LAST under a heading\n",
    "def format_result_output(result):\n",
    "    \"\"\"Return a single string with main answer first and reasoning_content appended at end.\n",
    "    Format:\n",
    "    <answer text>\n",
    "\n",
    "    ## reasoning content\n",
    "    ```text\n",
    "    <reasoning>\n",
    "    ```\n",
    "    Handles several possible shapes returned by Bedrock / LangChain tool binding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If it's already a plain string\n",
    "        if isinstance(result, str):\n",
    "            return result\n",
    "\n",
    "        # If it's a dict coming from filtered tool with JSON mode\n",
    "        if isinstance(result, dict):\n",
    "            reasoning = []\n",
    "            # reasoning_content may be list or str\n",
    "            rc = result.get(\"reasoning_content\")\n",
    "            if isinstance(rc, list):\n",
    "                reasoning.append(\"\\n\".join(str(x) for x in rc))\n",
    "            elif isinstance(rc, str):\n",
    "                reasoning.append(rc)\n",
    "            elif isinstance(rc, dict) and \"text\" in rc:\n",
    "                reasoning.append(rc[\"text\"])\n",
    "            # The main narrative may live in 'summary' or elsewhere\n",
    "            main_parts = []\n",
    "            for key in (\"summary\", \"text\", \"content\"):\n",
    "                if key in result and isinstance(result[key], str):\n",
    "                    main_parts.append(result[key])\n",
    "            main_text = \"\\n\\n\".join(p for p in main_parts if p and p.strip())\n",
    "            reasoning_text = \"\\n\\n\".join(r for r in reasoning if r and r.strip())\n",
    "            if reasoning_text:\n",
    "                return f\"{main_text}\\n\\n## reasoning content\\n```text\\n{reasoning_text}\\n```\" if main_text else f\"## reasoning content\\n```text\\n{reasoning_text}\\n```\"\n",
    "            return main_text or str(result)\n",
    "\n",
    "        # If it's a list of message blocks\n",
    "        if isinstance(result, list):\n",
    "            reasoning_segments = []\n",
    "            answer_segments = []\n",
    "            for block in result:\n",
    "                if not isinstance(block, dict):\n",
    "                    continue\n",
    "                # Some providers put reasoning in block['reasoning_content']['text']\n",
    "                rc = block.get(\"reasoning_content\")\n",
    "                if isinstance(rc, dict) and \"text\" in rc and rc[\"text\"].strip():\n",
    "                    reasoning_segments.append(rc[\"text\"].strip())\n",
    "                elif isinstance(rc, str) and rc.strip():\n",
    "                    reasoning_segments.append(rc.strip())\n",
    "                # Capture normal text content\n",
    "                if \"text\" in block and isinstance(block[\"text\"], str) and block[\"text\"].strip():\n",
    "                    answer_segments.append(block[\"text\"].strip())\n",
    "            # Heuristic: treat the LAST text block as the main answer if multiple present\n",
    "            if answer_segments:\n",
    "                main_answer = \"\\n\\n\".join(answer_segments)\n",
    "            else:\n",
    "                main_answer = \"\"\n",
    "            reasoning_text = \"\\n\\n\".join(reasoning_segments)\n",
    "            if reasoning_text:\n",
    "                return f\"{main_answer}\\n\\n## reasoning content\\n```text\\n{reasoning_text}\\n```\" if main_answer else f\"## reasoning content\\n```text\\n{reasoning_text}\\n```\"\n",
    "            return main_answer or str(result)\n",
    "        # Fallback\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"(Formatting error: {e})\\n{result}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365cfdfd",
   "metadata": {},
   "source": [
    "## Create the agent by binging the tools and the model together\n",
    "\n",
    "Updated: We now have two tools bound:\n",
    "1. `scotus_analysis` performs an internal search.\n",
    "2. `scotus_filtered_analysis` ONLY analyzes pre-filtered JSON you already produced (no new search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22099eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined: ScotusAnalysisTool (searching) & ScotusFilteredAnalysisTool (pre-filtered with flexible parsing + optional JSON mode, normalized content)\n",
      " ✅ Tools bound to model: ['scotus_analysis', 'scotus_filtered_analysis']\n",
      " 👨‍⚖️ SCOTUS database has 242 volumes\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tools\n",
    "scotus_tool = ScotusAnalysisTool(model=model, db_dict_formatted=db_dict_formatted)\n",
    "filtered_scotus_tool = ScotusFilteredAnalysisTool(model=model)\n",
    "\n",
    "tools = [scotus_tool, filtered_scotus_tool]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "print(\"Defined: ScotusAnalysisTool (searching) & ScotusFilteredAnalysisTool (pre-filtered with flexible parsing + optional JSON mode, normalized content)\")\n",
    "print(f\" ✅ Tools bound to model: {[tool.name for tool in tools]}\")\n",
    "print(f\" 👨‍⚖️ SCOTUS database has {len(db_dict_formatted)} volumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc087c",
   "metadata": {},
   "source": [
    "## 1st tool: AI will search the corpus for you and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword=\"bovine\"\n",
    "keyword=\"dictionary\"\n",
    "#keyword=\"etienne\"\n",
    "#keyword=\"ordinary meaning\"\n",
    "#keyword=\"bank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b99f71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEMO] Running scotus_analysis (live search) for keyword='bank' focus='general'\n",
      "🔍 TOOL(search-async): Searching SCOTUS database for keyword: 'bank'\n",
      "📊 TOOL(search-async): Found 1964 cases across 242 volumes\n",
      "🤖 TOOL(search-async): Sending 502989 characters to AI model for analysis\n",
      "⚠️ TOOL(search): Prompt exceeds 128000 characters, which may cause issues with some models.\n",
      "🤖 TOOL(search-async): Truncated prompt to 128000 characters\n",
      "✅ TOOL(search-async): Analysis complete, returning 2 characters\n",
      "\n",
      "[DEMO] Runtime: 101.60s | Raw result type: list\n",
      "\n",
      "=== FORMATTED OUTPUT (reasoning at end) ===\n",
      "\n",
      "**SCOTUS SEARCH‑RESULTS FOR “BANK” (VOL. 329‑390) – FORTH‑LEVEL LINGUISTIC ANALYSIS**  \n",
      "\n",
      "Below is a compact, data‑only b\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "search_keyword = keyword  # reuse previous, or set explicitly like: search_keyword = \"dictionary\"\n",
    "analysis_focus = \"general\"  # options: general | evolution | judicial_philosophy | custom\n",
    "\n",
    "print(f\"[DEMO] Running scotus_analysis (live search) for keyword='{search_keyword}' focus='{analysis_focus}'\")\n",
    "start_time = time()\n",
    "result_text = scotus_tool._run(keyword=search_keyword, analysis_focus=analysis_focus)\n",
    "elapsed = time() - start_time\n",
    "\n",
    "print(f\"\\n[DEMO] Runtime: {elapsed:.2f}s | Raw result type: {type(result_text).__name__}\")\n",
    "\n",
    "# Unified formatted output (reasoning last)\n",
    "formatted = format_result_output(result_text)\n",
    "print(\"\\n=== FORMATTED OUTPUT (reasoning at end) ===\\n\")\n",
    "print(formatted[:120])  # safety slice to avoid flooding notebook; adjust if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cc781",
   "metadata": {},
   "source": [
    "### Preview Markdown Report of AI summary\n",
    "\n",
    "saved as `{keyword}.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40118887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote combined analysis + reasoning to bank.md (length=17748 chars)\n"
     ]
    }
   ],
   "source": [
    "# Export unified analysis (answer + reasoning content at end) to ONE markdown file\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we have a result; if not, user can re-run the analysis cell first\n",
    "try:\n",
    "    _ = result_text  # noqa: F841\n",
    "except NameError:\n",
    "    raise RuntimeError(\"result_text not defined yet. Run the analysis cell first.\")\n",
    "\n",
    "safe_keyword = \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in keyword.strip()) or \"analysis_output\"\n",
    "formatted_output = format_result_output(result_text)\n",
    "outfile = f\"{safe_keyword}.md\"\n",
    "with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(formatted_output)\n",
    "print(f\"Wrote combined analysis + reasoning to {outfile} (length={len(formatted_output)} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851cce1",
   "metadata": {},
   "source": [
    "## 2nd tool: Passing pre-filtered JSON results to the filtered analysis tool\n",
    "\n",
    "- for greater control on the keyword samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6027102",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='ordinary meaning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46eb8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 TOOL(filtered-async): Sending 12182 chars to model (contexts: 217) | return_json=False\n"
     ]
    }
   ],
   "source": [
    "loc_results = got3.search_keyword_corpus(\n",
    "    keyword=keyword,\n",
    "    db_dict=db_dict_formatted,\n",
    "    case_sensitive=False,\n",
    "    show_context=True,\n",
    "    context_words=30,\n",
    "    output=\"json\"\n",
    ")\n",
    "# Drop keys with empty dicts and sort by keys (as integers)\n",
    "filtered_sorted_results = {k: v for k, v in sorted(loc_results.items(), key=lambda item: int(item[0])) if v}\n",
    "#filtered_sorted_results\n",
    "# print length of \n",
    "#print(len(filtered_sorted_results))\n",
    "\n",
    "if 'filtered_sorted_results' in globals() and filtered_sorted_results:\n",
    "    filtered_json_str = json.dumps(filtered_sorted_results)\n",
    "    # Plain text (narrative) mode\n",
    "    filtered_result_text = filtered_scotus_tool._run(\n",
    "        keyword=keyword,\n",
    "        results_json=filtered_json_str,\n",
    "        analysis_focus='general',\n",
    "        max_contexts=40,\n",
    "        return_json=False\n",
    "    )\n",
    "    print(filtered_result_text)\n",
    "else:\n",
    "    print(\"No pre-filtered results available to demonstrate filtered analysis tool.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc19b4e",
   "metadata": {},
   "source": [
    "______________________\n",
    "\n",
    "## Conclusion 🐄 🐍 🧑‍⚖️\n",
    "\n",
    "### AWS Bedrock + LangChain + `got3` + SCOTUS Corpus Analysis\n",
    "\n",
    "This demo illustrated how to build custom AI‑powered analysis tools over a specialized legal text corpus using LangChain and AWS Bedrock. By combining dynamic keyword search with focused AI synthesis, we can rapidly explore judicial reasoning patterns in Supreme Court opinions.\n",
    "\n",
    "### AWS Cost Explorer -- Monitoring Bedrock Costs\n",
    "\n",
    "Useful `jq` filters for your AWS Cost Explorer output:\n",
    "\n",
    "> notably costs won't show up immediately, so you may need to wait a day or two after incurring costs to see them reflected in Cost Explorer.\n",
    "\n",
    "```bash\n",
    "# Filter for Bedrock services specifically from all services with costs\n",
    "named_profile=atn-developer\n",
    "region=us-east-1\n",
    "start_date=2025-10-01\n",
    "end_date=2025-10-04\n",
    "\n",
    "aws ce get-cost-and-usage --time-period Start=$start_date,End=$end_date --granularity DAILY --metrics \"BlendedCost\" --group-by Type=DIMENSION,Key=SERVICE --region $region --profile=$named_profile | jq '.ResultsByTime[].Groups[] | select(.Keys[0] | test(\"Bedrock\"; \"i\")) | {service: .Keys[0], cost: .Metrics.BlendedCost.Amount}'\n",
    "```\n",
    "\n",
    "#### Cost of AWS Bedrock\n",
    "\n",
    "- on 10/01/2025 this was: `\"cost\": \"0.03760425\"` -- check tomorrow to see the costs from my testing runs today.\n",
    "- okay various runs cost just about $0.10 `  \"cost\": \"0.10061025\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7d6c9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.10061025\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.04100085\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"service\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Amazon Bedrock\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"cost\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"0.03763545\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Filter for Bedrock services specifically from all services with costs\n",
    "!aws ce get-cost-and-usage --time-period Start=2025-09-30,End=2025-10-05 --granularity DAILY --metrics \"BlendedCost\" --group-by Type=DIMENSION,Key=SERVICE --region us-east-1 --profile=atn-developer | jq '.ResultsByTime[].Groups[] | select(.Keys[0] | test(\"Bedrock\"; \"i\")) | {service: .Keys[0], cost: .Metrics.BlendedCost.Amount}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
