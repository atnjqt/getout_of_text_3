{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c737ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c071679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_mag_1993.txt', 'text_mag_1992.txt', 'text_mag_1990.txt', 'text_mag_1991.txt', 'text_mag_1995.txt', 'text_mag_1994.txt', 'text_mag_1996.txt', 'text_mag_1997.txt', 'text_mag_2008.txt', 'text_mag_2009.txt', 'text_mag_2019.txt', 'text_mag_2018.txt', 'text_mag_2002.txt', 'text_mag_2016.txt', 'text_mag_2017.txt', 'text_mag_2003.txt', 'text_mag_2015.txt', 'text_mag_2001.txt', 'text_mag_2000.txt', 'text_mag_2014.txt', 'text_mag_2010.txt', 'text_mag_2004.txt', 'text_mag_2005.txt', 'text_mag_2011.txt', 'text_mag_2007.txt', 'text_mag_2013.txt', 'text_mag_2012.txt', 'text_mag_2006.txt', 'text_mag_1999.txt', 'text_mag_1998.txt']\n",
      "['text_web_13.txt', 'text_web_07.txt', 'text_web_06.txt', 'text_web_12.txt', 'text_web_04.txt', 'text_web_10.txt', 'text_web_11.txt', 'text_web_05.txt', 'text_web_29.txt', 'text_web_01.txt', 'text_web_15.txt', 'text_web_14.txt', 'text_web_28.txt', 'text_web_16.txt', 'text_web_02.txt', 'text_web_03.txt', 'text_web_17.txt', 'text_web_32.txt', 'text_web_26.txt', 'text_web_27.txt', 'text_web_33.txt', 'text_web_25.txt', 'text_web_31.txt', 'text_web_19.txt', 'text_web_18.txt', 'text_web_30.txt', 'text_web_24.txt', 'text_web_08.txt', 'text_web_20.txt', 'text_web_34.txt', 'text_web_21.txt', 'text_web_09.txt', 'text_web_23.txt', 'text_web_22.txt']\n",
      "['text_acad_2013.txt', 'text_acad_2007.txt', 'text_acad_2006.txt', 'text_acad_2012.txt', 'text_acad_2004.txt', 'text_acad_2010.txt', 'text_acad_2011.txt', 'text_acad_2005.txt', 'text_acad_2001.txt', 'text_acad_2015.txt', 'text_acad_2014.txt', 'text_acad_2000.txt', 'text_acad_2016.txt', 'text_acad_2002.txt', 'text_acad_2003.txt', 'text_acad_2017.txt', 'text_acad_1999.txt', 'text_acad_1998.txt', 'text_acad_1996.txt', 'text_acad_1997.txt', 'text_acad_1995.txt', 'text_acad_1994.txt', 'text_acad_1990.txt', 'text_acad_1991.txt', 'text_acad_1993.txt', 'text_acad_1992.txt', 'text_acad_2019.txt', 'text_acad_2018.txt', 'text_acad_2008.txt', 'text_acad_2009.txt']\n",
      "['text_news_2018.txt', 'text_news_2019.txt', 'text_news_2009.txt', 'text_news_2008.txt', 'text_news_1994.txt', 'text_news_1995.txt', 'text_news_1997.txt', 'text_news_1996.txt', 'text_news_1992.txt', 'text_news_1993.txt', 'text_news_1991.txt', 'text_news_1990.txt', 'text_news_1998.txt', 'text_news_1999.txt', 'text_news_2011.txt', 'text_news_2005.txt', 'text_news_2004.txt', 'text_news_2010.txt', 'text_news_2006.txt', 'text_news_2012.txt', 'text_news_2013.txt', 'text_news_2007.txt', 'text_news_2003.txt', 'text_news_2017.txt', 'text_news_2016.txt', 'text_news_2002.txt', 'text_news_2014.txt', 'text_news_2000.txt', 'text_news_2001.txt', 'text_news_2015.txt']\n",
      "['text_spok_1995.txt', 'text_spok_1994.txt', 'text_spok_1996.txt', 'text_spok_1997.txt', 'text_spok_1993.txt', 'text_spok_1992.txt', 'text_spok_1990.txt', 'text_spok_1991.txt', 'text_spok_2019.txt', 'text_spok_2018.txt', 'text_spok_2008.txt', 'text_spok_2009.txt', 'text_spok_2004.txt', 'text_spok_2010.txt', 'text_spok_2011.txt', 'text_spok_2005.txt', 'text_spok_2013.txt', 'text_spok_2007.txt', 'text_spok_2006.txt', 'text_spok_2012.txt', 'text_spok_2016.txt', 'text_spok_2002.txt', 'text_spok_2003.txt', 'text_spok_2017.txt', 'text_spok_2001.txt', 'text_spok_2015.txt', 'text_spok_2014.txt', 'text_spok_2000.txt', 'text_spok_1999.txt', 'text_spok_1998.txt']\n",
      "['text_blog_26.txt', 'text_blog_32.txt', 'text_blog_33.txt', 'text_blog_27.txt', 'text_blog_19.txt', 'text_blog_31.txt', 'text_blog_25.txt', 'text_blog_24.txt', 'text_blog_30.txt', 'text_blog_18.txt', 'text_blog_34.txt', 'text_blog_20.txt', 'text_blog_08.txt', 'text_blog_09.txt', 'text_blog_21.txt', 'text_blog_23.txt', 'text_blog_22.txt', 'text_blog_07.txt', 'text_blog_13.txt', 'text_blog_12.txt', 'text_blog_06.txt', 'text_blog_10.txt', 'text_blog_04.txt', 'text_blog_05.txt', 'text_blog_11.txt', 'text_blog_15.txt', 'text_blog_01.txt', 'text_blog_29.txt', 'text_blog_28.txt', 'text_blog_14.txt', 'text_blog_02.txt', 'text_blog_16.txt', 'text_blog_17.txt', 'text_blog_03.txt']\n",
      "['text_fic_1998.txt', 'text_fic_1999.txt', 'text_fic_2011.txt', 'text_fic_2005.txt', 'text_fic_2004.txt', 'text_fic_2010.txt', 'text_fic_2006.txt', 'text_fic_2012.txt', 'text_fic_2013.txt', 'text_fic_2007.txt', 'text_fic_2003.txt', 'text_fic_2017.txt', 'text_fic_2016.txt', 'text_fic_2002.txt', 'text_fic_2014.txt', 'text_fic_2000.txt', 'text_fic_2001.txt', 'text_fic_2015.txt', 'text_fic_2018.txt', 'text_fic_2019.txt', 'text_fic_2009.txt', 'text_fic_2008.txt', 'text_fic_1994.txt', 'text_fic_1995.txt', 'text_fic_1997.txt', 'text_fic_1996.txt', 'text_fic_1992.txt', 'text_fic_1993.txt', 'text_fic_1991.txt', 'text_fic_1990.txt']\n",
      "['text_tvm_1999.txt', 'text_tvm_1998.txt', 'text_tvm_2010.txt', 'text_tvm_2004.txt', 'text_tvm_2005.txt', 'text_tvm_2011.txt', 'text_tvm_2007.txt', 'text_tvm_2013.txt', 'text_tvm_2012.txt', 'text_tvm_2006.txt', 'text_tvm_2002.txt', 'text_tvm_2016.txt', 'text_tvm_2017.txt', 'text_tvm_2003.txt', 'text_tvm_2015.txt', 'text_tvm_2001.txt', 'text_tvm_2000.txt', 'text_tvm_2014.txt', 'text_tvm_2019.txt', 'text_tvm_2018.txt', 'text_tvm_2008.txt', 'text_tvm_2009.txt', 'text_tvm_1995.txt', 'text_tvm_1994.txt', 'text_tvm_1996.txt', 'text_tvm_1997.txt', 'text_tvm_1993.txt', 'text_tvm_1992.txt', 'text_tvm_1990.txt', 'text_tvm_1991.txt']\n"
     ]
    }
   ],
   "source": [
    "for item in [item for item in os.listdir('../coca-text/') if not item.endswith('.zip')]:\n",
    "    print(os.listdir(f'../coca-text/{item}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c93b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "coca_dir='../coca-text/'\n",
    "\n",
    "def build_coca_dict(coca_dir='../coca-text/'):\n",
    "    coca_dict = {}\n",
    "    # Loop through genre folders\n",
    "    for genre_folder in [f for f in os.listdir(coca_dir) if f.startswith('text_')]:\n",
    "        genre = genre_folder.split('_')[1] # Extract genre from folder name like 'text_acad_isi'\n",
    "        print(f'Processing genre: {genre}')\n",
    "        genre_path = os.path.join(coca_dir, genre_folder)\n",
    "        # Loop through files in genre folder\n",
    "        for filename in os.listdir(genre_path):\n",
    "            if filename.startswith('text_') and filename.endswith('.txt'):\n",
    "                #print(f'  Processing file: {filename}')\n",
    "                year_match = re.search(r'_(\\d{4})\\.txt$', filename)\n",
    "                \n",
    "                with open(os.path.join(genre_path, filename), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    #print(f'    Reading file: {filename}')\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        if line.startswith('@@'):\n",
    "                            parts = line.split(' ', 1)\n",
    "                            if len(parts) == 2:\n",
    "                                id_part = parts[0][3:]  # Remove '#@@'\n",
    "                                text_part = parts[1]\n",
    "                                \n",
    "                                if year_match:\n",
    "                                    year = int(year_match.group(1))\n",
    "                                    #print(f'    Year: {year}')\n",
    "                                    # Build nested dict: genre -> year -> id -> text\n",
    "                                    coca_dict.setdefault(genre, {}).setdefault(year, {})[id_part] = text_part\n",
    "                                elif genre in ['web', 'blog']:\n",
    "                                    file_num_match = re.search(r'_(\\d+)\\.txt$', filename)\n",
    "                                    if file_num_match:\n",
    "                                        file_num = file_num_match.group(1)\n",
    "                                        # Build nested dict: genre -> file_num -> id -> text\n",
    "                                        coca_dict.setdefault(genre, {}).setdefault(file_num, {})[id_part] = text_part\n",
    "    return coca_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61a526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: mag\n",
      "Processing genre: web\n",
      "Processing genre: acad\n",
      "Processing genre: news\n",
      "Processing genre: spok\n",
      "Processing genre: blog\n",
      "Processing genre: fic\n",
      "Processing genre: tvm\n"
     ]
    }
   ],
   "source": [
    "coca_dict = build_coca_dict('../coca-text/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee6894a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mag', 'web', 'acad', 'news', 'spok', 'blog', 'fic', 'tvm'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "060e48fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1993, 1992, 1990, 1991, 1995, 1994, 1996, 1997, 2008, 2009, 2019, 2018, 2002, 2016, 2017, 2003, 2015, 2001, 2000, 2014, 2010, 2004, 2005, 2011, 2007, 2013, 2012, 2006, 1999, 1998])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_dict['mag'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f510404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['13', '07', '06', '12', '04', '10', '11', '05', '29', '01', '15', '14', '28', '16', '02', '03', '17', '32', '26', '27', '33', '25', '31', '19', '18', '30', '24', '08', '20', '34', '21', '09', '23', '22'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_dict['web'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc84e7e",
   "metadata": {},
   "source": [
    "## Trying for got3 read of full corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3e4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getout_of_text_3 as got3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d0cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.25'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fa6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:   0%|          | 0/8 [00:00<?, ?genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: mag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  12%|█▎        | 1/8 [00:00<00:06,  1.12genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: mag (total captured lines: 105280)\n",
      "Processing genre: web\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  25%|██▌       | 2/8 [00:01<00:05,  1.14genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: web (total captured lines: 89052)\n",
      "Processing genre: acad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  38%|███▊      | 3/8 [00:02<00:04,  1.12genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: acad (total captured lines: 26144)\n",
      "Processing genre: news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  50%|█████     | 4/8 [00:03<00:03,  1.12genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: news (total captured lines: 89729)\n",
      "Processing genre: spok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  62%|██████▎   | 5/8 [00:04<00:02,  1.10genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: spok (total captured lines: 44857)\n",
      "Processing genre: blog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  75%|███████▌  | 6/8 [00:05<00:01,  1.09genre/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: blog (total captured lines: 98788)\n",
      "Processing genre: fic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres:  88%|████████▊ | 7/8 [00:06<00:01,  1.04s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: fic (total captured lines: 25987)\n",
      "Processing genre: tvm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genres: 100%|██████████| 8/8 [00:08<00:00,  1.01s/genre]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished genre: tvm (total captured lines: 23925)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test = got3.read_corpus('../coca-text/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721457ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mag', 'web', 'acad', 'news', 'spok', 'blog', 'fic', 'tvm'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad123577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1993, 1992, 1990, 1991, 1995, 1994, 1996, 1997, 2008, 2009, 2019, 2018, 2002, 2016, 2017, 2003, 2015, 2001, 2000, 2014, 2010, 2004, 2005, 2011, 2007, 2013, 2012, 2006, 1999, 1998])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['mag'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795aa428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['13', '07', '06', '12', '04', '10', '11', '05', '29', '01', '15', '14', '28', '16', '02', '03', '17', '32', '26', '27', '33', '25', '31', '19', '18', '30', '24', '08', '20', '34', '21', '09', '23', '22'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['web'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79223a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
